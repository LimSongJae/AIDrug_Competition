{"cells":[{"cell_type":"code","execution_count":null,"id":"86cd3349","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10508,"status":"ok","timestamp":1692884941233,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"86cd3349","outputId":"d009fa68-9629-4c0a-8cd6-5b33cd5810fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}],"source":["import random\n","import os\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import missingno\n","\n","# device 설정\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print (device)\n","\n","seed = 42 # seed 값 설정\n","random.seed(seed) # 파이썬 난수 생성기\n","os.environ['PYTHONHASHSEED'] = str(seed) # 해시 시크릿값 고정\n","np.random.seed(seed) # 넘파이 난수 생성기\n","\n","torch.manual_seed(seed) # 파이토치 CPU 난수 생성기\n","torch.backends.cudnn.deterministic = True # 확정적 연산 사용 설정\n","torch.backends.cudnn.benchmark = False   # 벤치마크 기능 사용 해제\n","torch.backends.cudnn.enabled = False        # cudnn 기능 사용 해제\n","\n","if device == 'cuda':\n","    torch.cuda.manual_seed(seed) # 파이토치 GPU 난수 생성기\n","    torch.cuda.manual_seed_all(seed) # 파이토치 멀티 GPU 난수 생성기"]},{"cell_type":"code","execution_count":null,"id":"5a30f491","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39798,"status":"ok","timestamp":1692884981024,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"5a30f491","outputId":"b9615e28-e0a4-4aa7-84f9-749d2e45a3ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"a2911bd2","metadata":{"id":"a2911bd2"},"outputs":[],"source":["train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AIDrug_Competition/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AIDrug_Competition/data/test.csv')"]},{"cell_type":"code","execution_count":null,"id":"d784f776","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1692888199175,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"d784f776","outputId":"5b7b033a-7200-41a0-d7ba-c0e087dbf304"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["              id                                             SMILES     MLM  \\\n","0     TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC  26.010   \n","1     TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1  29.270   \n","2     TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   5.586   \n","3     TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   5.710   \n","4     TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2  93.270   \n","...          ...                                                ...     ...   \n","3493  TRAIN_3493     Cn1nc(CNC(=O)Cn2nc(C(F)(F)F)c3c2CCC3)c(Cl)c1Cl   1.556   \n","3494  TRAIN_3494  CCn1[nH]cc/c1=N\\C(=O)c1nn(-c2ccccc2)c(=O)c2ccc...  35.560   \n","3495  TRAIN_3495                       CCOC(=O)CCCc1nc2cc(N)ccc2n1C  56.150   \n","3496  TRAIN_3496                     Nc1cc(C(=O)OCCC2CCOC2=O)cnc1Cl   0.030   \n","3497  TRAIN_3497                   COc1ccc(-c2nc(Cc3ccccc3)sc2C)cc1   0.450   \n","\n","         HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n","0     50.680  3.259           400.495                5             2   \n","1     50.590  2.169           301.407                2             1   \n","2     80.892  1.593           297.358                5             0   \n","3      2.000  4.771           494.652                6             0   \n","4     99.990  2.335           268.310                3             0   \n","...      ...    ...               ...              ...           ...   \n","3493   3.079  3.409           396.195                3             1   \n","3494  47.630  1.912           359.381                4             1   \n","3495   1.790  1.941           261.320                3             1   \n","3496   2.770  0.989           284.696                5             1   \n","3497   2.650  4.321           295.399                2             0   \n","\n","      Num_RotatableBonds   LogD  Molecular_PolarSurfaceArea  \n","0                      8  3.259                      117.37  \n","1                      2  2.172                       73.47  \n","2                      3  1.585                       62.45  \n","3                      5  3.475                       92.60  \n","4                      1  2.337                       42.43  \n","...                  ...    ...                         ...  \n","3493                   5  3.409                       64.74  \n","3494                   3  1.844                       77.37  \n","3495                   6  2.124                       70.14  \n","3496                   5  0.989                       91.51  \n","3497                   4  4.321                       50.36  \n","\n","[3498 rows x 11 columns]"],"text/html":["\n","  <div id=\"df-54c333d9-1960-4694-841b-5aa94f5fce15\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>SMILES</th>\n","      <th>MLM</th>\n","      <th>HLM</th>\n","      <th>AlogP</th>\n","      <th>Molecular_Weight</th>\n","      <th>Num_H_Acceptors</th>\n","      <th>Num_H_Donors</th>\n","      <th>Num_RotatableBonds</th>\n","      <th>LogD</th>\n","      <th>Molecular_PolarSurfaceArea</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_0000</td>\n","      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n","      <td>26.010</td>\n","      <td>50.680</td>\n","      <td>3.259</td>\n","      <td>400.495</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>3.259</td>\n","      <td>117.37</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_0001</td>\n","      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n","      <td>29.270</td>\n","      <td>50.590</td>\n","      <td>2.169</td>\n","      <td>301.407</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2.172</td>\n","      <td>73.47</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_0002</td>\n","      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n","      <td>5.586</td>\n","      <td>80.892</td>\n","      <td>1.593</td>\n","      <td>297.358</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1.585</td>\n","      <td>62.45</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_0003</td>\n","      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n","      <td>5.710</td>\n","      <td>2.000</td>\n","      <td>4.771</td>\n","      <td>494.652</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>3.475</td>\n","      <td>92.60</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_0004</td>\n","      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n","      <td>93.270</td>\n","      <td>99.990</td>\n","      <td>2.335</td>\n","      <td>268.310</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2.337</td>\n","      <td>42.43</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3493</th>\n","      <td>TRAIN_3493</td>\n","      <td>Cn1nc(CNC(=O)Cn2nc(C(F)(F)F)c3c2CCC3)c(Cl)c1Cl</td>\n","      <td>1.556</td>\n","      <td>3.079</td>\n","      <td>3.409</td>\n","      <td>396.195</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>3.409</td>\n","      <td>64.74</td>\n","    </tr>\n","    <tr>\n","      <th>3494</th>\n","      <td>TRAIN_3494</td>\n","      <td>CCn1[nH]cc/c1=N\\C(=O)c1nn(-c2ccccc2)c(=O)c2ccc...</td>\n","      <td>35.560</td>\n","      <td>47.630</td>\n","      <td>1.912</td>\n","      <td>359.381</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1.844</td>\n","      <td>77.37</td>\n","    </tr>\n","    <tr>\n","      <th>3495</th>\n","      <td>TRAIN_3495</td>\n","      <td>CCOC(=O)CCCc1nc2cc(N)ccc2n1C</td>\n","      <td>56.150</td>\n","      <td>1.790</td>\n","      <td>1.941</td>\n","      <td>261.320</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>2.124</td>\n","      <td>70.14</td>\n","    </tr>\n","    <tr>\n","      <th>3496</th>\n","      <td>TRAIN_3496</td>\n","      <td>Nc1cc(C(=O)OCCC2CCOC2=O)cnc1Cl</td>\n","      <td>0.030</td>\n","      <td>2.770</td>\n","      <td>0.989</td>\n","      <td>284.696</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0.989</td>\n","      <td>91.51</td>\n","    </tr>\n","    <tr>\n","      <th>3497</th>\n","      <td>TRAIN_3497</td>\n","      <td>COc1ccc(-c2nc(Cc3ccccc3)sc2C)cc1</td>\n","      <td>0.450</td>\n","      <td>2.650</td>\n","      <td>4.321</td>\n","      <td>295.399</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>4.321</td>\n","      <td>50.36</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3498 rows × 11 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54c333d9-1960-4694-841b-5aa94f5fce15')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-54c333d9-1960-4694-841b-5aa94f5fce15 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-54c333d9-1960-4694-841b-5aa94f5fce15');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-11694791-17af-4169-a0a7-43e4019c28be\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11694791-17af-4169-a0a7-43e4019c28be')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-11694791-17af-4169-a0a7-43e4019c28be button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":78}],"source":["train"]},{"cell_type":"code","execution_count":null,"id":"6e6800c9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5802,"status":"ok","timestamp":1692888204972,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"6e6800c9","outputId":"94493e54-3ceb-4d8d-b63f-5455630d1155"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (2022.9.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n"]}],"source":["!pip install rdkit-pypi"]},{"cell_type":"code","execution_count":null,"id":"3c2cda0b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"elapsed":15850,"status":"ok","timestamp":1692888221416,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"3c2cda0b","outputId":"bc0fe72e-288e-4fb3-bde8-95064139cb47"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["              id                                             SMILES     MLM  \\\n","0     TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC  26.010   \n","1     TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1  29.270   \n","2     TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   5.586   \n","3     TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   5.710   \n","4     TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2  93.270   \n","...          ...                                                ...     ...   \n","3493  TRAIN_3493     Cn1nc(CNC(=O)Cn2nc(C(F)(F)F)c3c2CCC3)c(Cl)c1Cl   1.556   \n","3494  TRAIN_3494  CCn1[nH]cc/c1=N\\C(=O)c1nn(-c2ccccc2)c(=O)c2ccc...  35.560   \n","3495  TRAIN_3495                       CCOC(=O)CCCc1nc2cc(N)ccc2n1C  56.150   \n","3496  TRAIN_3496                     Nc1cc(C(=O)OCCC2CCOC2=O)cnc1Cl   0.030   \n","3497  TRAIN_3497                   COc1ccc(-c2nc(Cc3ccccc3)sc2C)cc1   0.450   \n","\n","         HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n","0     50.680  3.259           400.495                5             2   \n","1     50.590  2.169           301.407                2             1   \n","2     80.892  1.593           297.358                5             0   \n","3      2.000  4.771           494.652                6             0   \n","4     99.990  2.335           268.310                3             0   \n","...      ...    ...               ...              ...           ...   \n","3493   3.079  3.409           396.195                3             1   \n","3494  47.630  1.912           359.381                4             1   \n","3495   1.790  1.941           261.320                3             1   \n","3496   2.770  0.989           284.696                5             1   \n","3497   2.650  4.321           295.399                2             0   \n","\n","      Num_RotatableBonds   LogD  Molecular_PolarSurfaceArea     logP  \\\n","0                      8  3.259                      117.37  3.87744   \n","1                      2  2.172                       73.47  3.35474   \n","2                      3  1.585                       62.45  1.20450   \n","3                      5  3.475                       92.60  3.89356   \n","4                      1  2.337                       42.43  2.81772   \n","...                  ...    ...                         ...      ...   \n","3493                   5  3.409                       64.74  2.74730   \n","3494                   3  1.844                       77.37  2.27630   \n","3495                   6  2.124                       70.14  2.04130   \n","3496                   5  0.989                       91.51  1.42720   \n","3497                   4  4.321                       50.36  4.71792   \n","\n","      num_rotatable_bonds  num_heteroatoms  num_hydrogen_acceptors  \\\n","0                       8                8                       6   \n","1                       2                5                       4   \n","2                       3                7                       7   \n","3                       5                9                       7   \n","4                       1                4                       3   \n","...                   ...              ...                     ...   \n","3493                    4               11                       5   \n","3494                    3                7                       5   \n","3495                    5                5                       5   \n","3496                    4                7                       6   \n","3497                    4                3                       3   \n","\n","      num_hydrogen_donors                                 morgan_fingerprint  \\\n","0                       2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","1                       1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","2                       0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","3                       0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","4                       0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","...                   ...                                                ...   \n","3493                    1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","3494                    1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","3495                    1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","3496                    1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n","3497                    0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","\n","      aromatic_rings   tpsa  \n","0                  3  89.13  \n","1                  3  45.23  \n","2                  4  62.45  \n","3                  5  84.22  \n","4                  3  42.43  \n","...              ...    ...  \n","3493               3  64.74  \n","3494               4  85.04  \n","3495               2  70.14  \n","3496               2  91.51  \n","3497               3  22.12  \n","\n","[3498 rows x 19 columns]"],"text/html":["\n","  <div id=\"df-e2dd8088-190d-4e92-aec3-0c603c181125\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>SMILES</th>\n","      <th>MLM</th>\n","      <th>HLM</th>\n","      <th>AlogP</th>\n","      <th>Molecular_Weight</th>\n","      <th>Num_H_Acceptors</th>\n","      <th>Num_H_Donors</th>\n","      <th>Num_RotatableBonds</th>\n","      <th>LogD</th>\n","      <th>Molecular_PolarSurfaceArea</th>\n","      <th>logP</th>\n","      <th>num_rotatable_bonds</th>\n","      <th>num_heteroatoms</th>\n","      <th>num_hydrogen_acceptors</th>\n","      <th>num_hydrogen_donors</th>\n","      <th>morgan_fingerprint</th>\n","      <th>aromatic_rings</th>\n","      <th>tpsa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TRAIN_0000</td>\n","      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n","      <td>26.010</td>\n","      <td>50.680</td>\n","      <td>3.259</td>\n","      <td>400.495</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>3.259</td>\n","      <td>117.37</td>\n","      <td>3.87744</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>3</td>\n","      <td>89.13</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TRAIN_0001</td>\n","      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n","      <td>29.270</td>\n","      <td>50.590</td>\n","      <td>2.169</td>\n","      <td>301.407</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2.172</td>\n","      <td>73.47</td>\n","      <td>3.35474</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>3</td>\n","      <td>45.23</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TRAIN_0002</td>\n","      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n","      <td>5.586</td>\n","      <td>80.892</td>\n","      <td>1.593</td>\n","      <td>297.358</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1.585</td>\n","      <td>62.45</td>\n","      <td>1.20450</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>4</td>\n","      <td>62.45</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TRAIN_0003</td>\n","      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n","      <td>5.710</td>\n","      <td>2.000</td>\n","      <td>4.771</td>\n","      <td>494.652</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>3.475</td>\n","      <td>92.60</td>\n","      <td>3.89356</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>5</td>\n","      <td>84.22</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TRAIN_0004</td>\n","      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n","      <td>93.270</td>\n","      <td>99.990</td>\n","      <td>2.335</td>\n","      <td>268.310</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2.337</td>\n","      <td>42.43</td>\n","      <td>2.81772</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>3</td>\n","      <td>42.43</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3493</th>\n","      <td>TRAIN_3493</td>\n","      <td>Cn1nc(CNC(=O)Cn2nc(C(F)(F)F)c3c2CCC3)c(Cl)c1Cl</td>\n","      <td>1.556</td>\n","      <td>3.079</td>\n","      <td>3.409</td>\n","      <td>396.195</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>3.409</td>\n","      <td>64.74</td>\n","      <td>2.74730</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>3</td>\n","      <td>64.74</td>\n","    </tr>\n","    <tr>\n","      <th>3494</th>\n","      <td>TRAIN_3494</td>\n","      <td>CCn1[nH]cc/c1=N\\C(=O)c1nn(-c2ccccc2)c(=O)c2ccc...</td>\n","      <td>35.560</td>\n","      <td>47.630</td>\n","      <td>1.912</td>\n","      <td>359.381</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1.844</td>\n","      <td>77.37</td>\n","      <td>2.27630</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>4</td>\n","      <td>85.04</td>\n","    </tr>\n","    <tr>\n","      <th>3495</th>\n","      <td>TRAIN_3495</td>\n","      <td>CCOC(=O)CCCc1nc2cc(N)ccc2n1C</td>\n","      <td>56.150</td>\n","      <td>1.790</td>\n","      <td>1.941</td>\n","      <td>261.320</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>2.124</td>\n","      <td>70.14</td>\n","      <td>2.04130</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>2</td>\n","      <td>70.14</td>\n","    </tr>\n","    <tr>\n","      <th>3496</th>\n","      <td>TRAIN_3496</td>\n","      <td>Nc1cc(C(=O)OCCC2CCOC2=O)cnc1Cl</td>\n","      <td>0.030</td>\n","      <td>2.770</td>\n","      <td>0.989</td>\n","      <td>284.696</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0.989</td>\n","      <td>91.51</td>\n","      <td>1.42720</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n","      <td>2</td>\n","      <td>91.51</td>\n","    </tr>\n","    <tr>\n","      <th>3497</th>\n","      <td>TRAIN_3497</td>\n","      <td>COc1ccc(-c2nc(Cc3ccccc3)sc2C)cc1</td>\n","      <td>0.450</td>\n","      <td>2.650</td>\n","      <td>4.321</td>\n","      <td>295.399</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>4.321</td>\n","      <td>50.36</td>\n","      <td>4.71792</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>3</td>\n","      <td>22.12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3498 rows × 19 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2dd8088-190d-4e92-aec3-0c603c181125')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e2dd8088-190d-4e92-aec3-0c603c181125 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e2dd8088-190d-4e92-aec3-0c603c181125');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-acb92033-9eaa-4869-b905-7e8b8373b916\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acb92033-9eaa-4869-b905-7e8b8373b916')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-acb92033-9eaa-4869-b905-7e8b8373b916 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":80}],"source":["import pandas as pd\n","import numpy as np\n","from rdkit import Chem, DataStructs\n","from rdkit.Chem import AllChem, Descriptors\n","\n","def calculate_metabolic_stability_descriptors(smiles):\n","    mol = Chem.MolFromSmiles(smiles)\n","    logP = Descriptors.MolLogP(mol)\n","    num_rotatable_bonds = Descriptors.NumRotatableBonds(mol)\n","    num_heteroatoms = Descriptors.NumHeteroatoms(mol)\n","    num_hydrogen_acceptors = Descriptors.NumHAcceptors(mol)\n","    num_hydrogen_donors = Descriptors.NumHDonors(mol)\n","    morgan_fingerprint = AllChem.GetHashedMorganFingerprint(mol, 6, nBits=4096)\n","    # morgan_fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n","    morgan_array = np.zeros((1,), dtype=np.int8)\n","    DataStructs.ConvertToNumpyArray(morgan_fingerprint, morgan_array)\n","    aromatic_rings = mol.GetRingInfo().NumRings()\n","    tpsa = Descriptors.TPSA(mol)\n","\n","    return logP, num_rotatable_bonds, num_heteroatoms, num_hydrogen_acceptors, num_hydrogen_donors, morgan_array, aromatic_rings, tpsa\n","\n","train[[\n","    'logP', 'num_rotatable_bonds', 'num_heteroatoms',\n","    'num_hydrogen_acceptors', 'num_hydrogen_donors', 'morgan_fingerprint', 'aromatic_rings',\n","    'tpsa'\n","]] = train['SMILES'].apply(calculate_metabolic_stability_descriptors).apply(pd.Series)\n","\n","test[[\n","    'logP', 'num_rotatable_bonds', 'num_heteroatoms',\n","    'num_hydrogen_acceptors', 'num_hydrogen_donors', 'morgan_fingerprint', 'aromatic_rings',\n","    'tpsa'\n","]] = test['SMILES'].apply(calculate_metabolic_stability_descriptors).apply(pd.Series)\n","\n","train\n"]},{"cell_type":"code","execution_count":null,"id":"M84FfbMS-Ttt","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1692888221417,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"M84FfbMS-Ttt","outputId":"aaedac1e-0d4a-45e3-90d9-8326b9916f2d"},"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"f0c6e332-6258-4740-905a-75188f4fff2b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f0c6e332-6258-4740-905a-75188f4fff2b\")) {                    Plotly.newPlot(                        \"f0c6e332-6258-4740-905a-75188f4fff2b\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"MLM\",\"HLM\",\"AlogP\",\"Molecular_Weight\",\"Num_H_Acceptors\",\"Num_H_Donors\",\"Num_RotatableBonds\",\"LogD\",\"Molecular_PolarSurfaceArea\",\"logP\",\"num_rotatable_bonds\",\"num_heteroatoms\",\"num_hydrogen_acceptors\",\"num_hydrogen_donors\",\"aromatic_rings\",\"tpsa\"],\"y\":[\"MLM\",\"HLM\",\"AlogP\",\"Molecular_Weight\",\"Num_H_Acceptors\",\"Num_H_Donors\",\"Num_RotatableBonds\",\"LogD\",\"Molecular_PolarSurfaceArea\",\"logP\",\"num_rotatable_bonds\",\"num_heteroatoms\",\"num_hydrogen_acceptors\",\"num_hydrogen_donors\",\"aromatic_rings\",\"tpsa\"],\"z\":[[1.0,0.7067251024878,-0.3300826499827315,-0.08123913966297934,0.16450975744691224,0.21083588810096493,-0.09256266192711304,-0.35014591323933564,0.184849785645308,-0.30734844288027663,-0.091376903443668,0.16492651941443726,0.09172953254568401,0.21699615393852822,-0.09963152920798025,0.24515470819411164],[0.7067251024878,1.0,-0.346022143896057,-0.1751168230755293,0.09231267579874262,0.176549393873596,-0.13226256314849838,-0.3574559486898405,0.09432262585644133,-0.32336264361777783,-0.12488780668276511,0.07547112050553692,0.047136218752318174,0.18451167849848712,-0.12765099511513398,0.1639901820063082],[-0.3300826499827315,-0.346022143896057,1.0,0.38975964987189593,-0.2844153878193624,-0.17222215929788845,0.11184434754920093,0.9576111642662698,-0.29819398553681126,0.887321738681376,0.11781285831289552,-0.18659173454852074,-0.1745781382871405,-0.134278934773394,0.4227633753985136,-0.31678902797177],[-0.08123913966297934,-0.1751168230755293,0.38975964987189593,1.0,0.4718137354590274,0.11618610965521532,0.5837107521276598,0.3694619827451061,0.43911413238619246,0.4720392677274182,0.5568283393004163,0.6073252705999541,0.4198237003386296,0.07694871788140818,0.49521309517668816,0.4013606273200654],[0.16450975744691224,0.09231267579874262,-0.2844153878193624,0.4718137354590274,1.0,0.20843323791440715,0.47401156367726943,-0.30550596770408145,0.7143154321060738,-0.25194266971571516,0.4252297922299244,0.6927861820128884,0.7672830328823523,0.1437639792156416,0.07950296473804068,0.7215103503867097],[0.21083588810096493,0.176549393873596,-0.17222215929788845,0.11618610965521532,0.20843323791440715,1.0,0.17687113618402622,-0.2120824238069809,0.4746141029761259,-0.12459914602412905,0.1583734948530644,0.2077131492322306,0.028964026386888563,0.970630453907293,-0.09877009230664784,0.5039146014424158],[-0.09256266192711304,-0.13226256314849838,0.11184434754920093,0.5837107521276598,0.47401156367726943,0.17687113618402622,1.0,0.07165891227719459,0.37157351825140145,0.15201701989735578,0.9643034440905066,0.4031651047866803,0.32139602201763856,0.1350720686291281,-0.13945467666421293,0.35517668006301045],[-0.35014591323933564,-0.3574559486898405,0.9576111642662698,0.3694619827451061,-0.30550596770408145,-0.2120824238069809,0.07165891227719459,1.0,-0.29467045023768507,0.861420986900028,0.07331173280230192,-0.16958030574710356,-0.15808933540525358,-0.17256720832818515,0.42685197019243637,-0.3086164552144978],[0.184849785645308,0.09432262585644133,-0.29819398553681126,0.43911413238619246,0.7143154321060738,0.4746141029761259,0.37157351825140145,-0.29467045023768507,1.0,-0.24883685207476436,0.33954477203408295,0.7668731242309601,0.650884590114377,0.4339986806749017,0.03502422648588062,0.851825614321054],[-0.30734844288027663,-0.32336264361777783,0.887321738681376,0.4720392677274182,-0.25194266971571516,-0.12459914602412905,0.15201701989735578,0.861420986900028,-0.24883685207476436,1.0,0.1404972188868642,-0.20127172722392092,-0.2184982441286418,-0.1343242783562854,0.47475970101998427,-0.3422394167868573],[-0.091376903443668,-0.12488780668276511,0.11781285831289552,0.5568283393004163,0.4252297922299244,0.1583734948530644,0.9643034440905066,0.07331173280230192,0.33954477203408295,0.1404972188868642,1.0,0.3957234965282207,0.31681357775173913,0.14435990413835367,-0.10740475189637556,0.3491851122141997],[0.16492651941443726,0.07547112050553692,-0.18659173454852074,0.6073252705999541,0.6927861820128884,0.2077131492322306,0.4031651047866803,-0.16958030574710356,0.7668731242309601,-0.20127172722392092,0.3957234965282207,1.0,0.7420191961494077,0.22367547933123424,0.12056890950418651,0.8015314418735465],[0.09172953254568401,0.047136218752318174,-0.1745781382871405,0.4198237003386296,0.7672830328823523,0.028964026386888563,0.32139602201763856,-0.15808933540525358,0.650884590114377,-0.2184982441286418,0.31681357775173913,0.7420191961494077,1.0,0.034616786492217576,0.26300692410428494,0.6822235644831942],[0.21699615393852822,0.18451167849848712,-0.134278934773394,0.07694871788140818,0.1437639792156416,0.970630453907293,0.1350720686291281,-0.17256720832818515,0.4339986806749017,-0.1343242783562854,0.14435990413835367,0.22367547933123424,0.034616786492217576,1.0,-0.09937935152599432,0.5337087717529465],[-0.09963152920798025,-0.12765099511513398,0.4227633753985136,0.49521309517668816,0.07950296473804068,-0.09877009230664784,-0.13945467666421293,0.42685197019243637,0.03502422648588062,0.47475970101998427,-0.10740475189637556,0.12056890950418651,0.26300692410428494,-0.09937935152599432,1.0,0.03498972403986415],[0.24515470819411164,0.1639901820063082,-0.31678902797177,0.4013606273200654,0.7215103503867097,0.5039146014424158,0.35517668006301045,-0.3086164552144978,0.851825614321054,-0.3422394167868573,0.3491851122141997,0.8015314418735465,0.6822235644831942,0.5337087717529465,0.03498972403986415,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(255,255,204)\"],[0.125,\"rgb(255,237,160)\"],[0.25,\"rgb(254,217,118)\"],[0.375,\"rgb(254,178,76)\"],[0.5,\"rgb(253,141,60)\"],[0.625,\"rgb(252,78,42)\"],[0.75,\"rgb(227,26,28)\"],[0.875,\"rgb(189,0,38)\"],[1.0,\"rgb(128,0,38)\"]]},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('f0c6e332-6258-4740-905a-75188f4fff2b');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}],"source":["import plotly.express as px\n","\n","correlation_matrix = train.corr(numeric_only=True)\n","\n","fig = px.imshow(correlation_matrix, color_continuous_scale='YlOrRd')\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"id":"oi2XGXTX1kV_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1692888221833,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"oi2XGXTX1kV_","outputId":"1b09f74e-2573-409b-c6bd-78c836ad5e3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 3498 entries, 0 to 3497\n","Data columns (total 19 columns):\n"," #   Column                      Non-Null Count  Dtype  \n","---  ------                      --------------  -----  \n"," 0   id                          3498 non-null   object \n"," 1   SMILES                      3498 non-null   object \n"," 2   MLM                         3498 non-null   float64\n"," 3   HLM                         3498 non-null   float64\n"," 4   AlogP                       3496 non-null   float64\n"," 5   Molecular_Weight            3498 non-null   float64\n"," 6   Num_H_Acceptors             3498 non-null   int64  \n"," 7   Num_H_Donors                3498 non-null   int64  \n"," 8   Num_RotatableBonds          3498 non-null   int64  \n"," 9   LogD                        3498 non-null   float64\n"," 10  Molecular_PolarSurfaceArea  3498 non-null   float64\n"," 11  logP                        3498 non-null   float64\n"," 12  num_rotatable_bonds         3498 non-null   int64  \n"," 13  num_heteroatoms             3498 non-null   int64  \n"," 14  num_hydrogen_acceptors      3498 non-null   int64  \n"," 15  num_hydrogen_donors         3498 non-null   int64  \n"," 16  morgan_fingerprint          3498 non-null   object \n"," 17  aromatic_rings              3498 non-null   int64  \n"," 18  tpsa                        3498 non-null   float64\n","dtypes: float64(8), int64(8), object(3)\n","memory usage: 519.4+ KB\n"]}],"source":["train.info()"]},{"cell_type":"code","execution_count":null,"id":"b8592a22","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1692888221833,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"b8592a22","outputId":"d9def3b0-3835-4bbc-b498-54a703dfe851"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 3498 entries, 0 to 3497\n","Data columns (total 16 columns):\n"," #   Column                      Non-Null Count  Dtype  \n","---  ------                      --------------  -----  \n"," 0   MLM                         3498 non-null   float64\n"," 1   HLM                         3498 non-null   float64\n"," 2   AlogP                       3496 non-null   float64\n"," 3   Molecular_Weight            3498 non-null   float64\n"," 4   Num_H_Acceptors             3498 non-null   int64  \n"," 5   Num_H_Donors                3498 non-null   int64  \n"," 6   Num_RotatableBonds          3498 non-null   int64  \n"," 7   LogD                        3498 non-null   float64\n"," 8   Molecular_PolarSurfaceArea  3498 non-null   float64\n"," 9   logP                        3498 non-null   float64\n"," 10  num_rotatable_bonds         3498 non-null   int64  \n"," 11  num_heteroatoms             3498 non-null   int64  \n"," 12  num_hydrogen_acceptors      3498 non-null   int64  \n"," 13  num_hydrogen_donors         3498 non-null   int64  \n"," 14  aromatic_rings              3498 non-null   int64  \n"," 15  tpsa                        3498 non-null   float64\n","dtypes: float64(8), int64(8)\n","memory usage: 437.4 KB\n"]}],"source":["train.drop(['id','SMILES','morgan_fingerprint'], axis=1).info() # (3496, 15)"]},{"cell_type":"code","execution_count":null,"id":"WNrp5UFLnVnQ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692888221833,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"WNrp5UFLnVnQ","outputId":"a1bf749b-2c14-4b0a-f26c-c14574ab3853"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 483 entries, 0 to 482\n","Data columns (total 17 columns):\n"," #   Column                      Non-Null Count  Dtype  \n","---  ------                      --------------  -----  \n"," 0   id                          483 non-null    object \n"," 1   SMILES                      483 non-null    object \n"," 2   AlogP                       482 non-null    float64\n"," 3   Molecular_Weight            483 non-null    float64\n"," 4   Num_H_Acceptors             483 non-null    int64  \n"," 5   Num_H_Donors                483 non-null    int64  \n"," 6   Num_RotatableBonds          483 non-null    int64  \n"," 7   LogD                        483 non-null    float64\n"," 8   Molecular_PolarSurfaceArea  483 non-null    float64\n"," 9   logP                        483 non-null    float64\n"," 10  num_rotatable_bonds         483 non-null    int64  \n"," 11  num_heteroatoms             483 non-null    int64  \n"," 12  num_hydrogen_acceptors      483 non-null    int64  \n"," 13  num_hydrogen_donors         483 non-null    int64  \n"," 14  morgan_fingerprint          483 non-null    object \n"," 15  aromatic_rings              483 non-null    int64  \n"," 16  tpsa                        483 non-null    float64\n","dtypes: float64(6), int64(8), object(3)\n","memory usage: 64.3+ KB\n"]}],"source":["test.info()"]},{"cell_type":"code","execution_count":null,"id":"c72ec77f","metadata":{"id":"c72ec77f"},"outputs":[],"source":["train['AlogP'].fillna(train['AlogP'].median(), inplace=True)\n","test['AlogP'].fillna(test['AlogP'].median(), inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"CyrKl5mXTYFG","metadata":{"id":"CyrKl5mXTYFG"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data, target_col=None, transform=None, is_test=False):\n","        self.is_test = is_test\n","        self.transform = transform\n","        self.is_test = is_test\n","\n","        if not self.is_test:\n","            self.data = self.transform.fit_transform(np.stack(data['morgan_fingerprint']))\n","        else: # test\n","            self.data = self.transform.transform(np.stack(data['morgan_fingerprint']))\n","\n","        if target_col is not None and not self.is_test:\n","            self.target = data[target_col]\n","\n","    def __getitem__(self, index):\n","        features = self.data[index]\n","\n","        if hasattr(self, 'target'):\n","            target = self.target[index]\n","            return torch.tensor(features).to(device).float(), torch.tensor(target).to(device).float().unsqueeze(dim=-1)\n","        else:\n","            return torch.tensor(features).to(device).float()\n","\n","    def __len__(self):\n","        return len(self.data)\n"]},{"cell_type":"code","execution_count":null,"id":"a5dfdf8b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1213,"status":"ok","timestamp":1692888223044,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"a5dfdf8b","outputId":"bf3c6bff-41fa-4f74-eb80-53987f1a101e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["251"]},"metadata":{},"execution_count":87}],"source":["transform = VarianceThreshold(threshold=0.05)\n","\n","train_MLM = CustomDataset(train, target_col='MLM', transform=transform, is_test=False)\n","train_HLM = CustomDataset(train, target_col='HLM', transform=transform, is_test=False)\n","\n","input_size = train_MLM.data.shape[1]\n","input_size"]},{"cell_type":"code","execution_count":null,"id":"e46c90d2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1692888223045,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"e46c90d2","outputId":"50b50309-a9d3-407b-a9ea-8d2446441adc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3498, 251)"]},"metadata":{},"execution_count":88}],"source":["train_HLM.data.shape"]},{"cell_type":"code","execution_count":null,"id":"78a83026","metadata":{"id":"78a83026"},"outputs":[],"source":["# train,valid split\n","train_MLM_dataset, valid_MLM_dataset = train_test_split(train_MLM, test_size=0.2, random_state=42)\n","train_HLM_dataset, valid_HLM_dataset = train_test_split(train_HLM, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"b15bd4f4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1692888224318,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"b15bd4f4","outputId":"6ea387cd-b5e7-4c6a-d29e-df95cc6b190b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([251]), torch.Size([1]))"]},"metadata":{},"execution_count":90}],"source":["torch.tensor(train_MLM.data[1]).shape, torch.tensor(train['MLM'][1]).float().unsqueeze(dim=-1).shape"]},{"cell_type":"code","execution_count":null,"id":"d73f8af6","metadata":{"id":"d73f8af6"},"outputs":[],"source":["# Hyperparameter\n","CFG = {'BATCH_SIZE': 256, # 200 과적합일 시에 낮추기\n","       'EPOCHS': 10000,\n","       'INPUT_SIZE': input_size,\n","       'HIDDEN_SIZE': 1280,\n","       'OUTPUT_SIZE': 1,\n","       'DROPOUT_RATE': 0.5, # 0.8 과적합일 시에 높이기\n","       'LEARNING_RATE': 1e-5}"]},{"cell_type":"code","execution_count":null,"id":"f328f1d7","metadata":{"id":"f328f1d7"},"outputs":[],"source":["train_MLM_loader = DataLoader(dataset=train_MLM_dataset,\n","                              batch_size=CFG['BATCH_SIZE'],\n","                              shuffle=True)\n","\n","valid_MLM_loader = DataLoader(dataset=valid_MLM_dataset,\n","                              batch_size=CFG['BATCH_SIZE'],\n","                              shuffle=False)\n","\n","\n","train_HLM_loader = DataLoader(dataset=train_HLM_dataset,\n","                              batch_size=CFG['BATCH_SIZE'],\n","                              shuffle=True)\n","\n","valid_HLM_loader = DataLoader(dataset=valid_HLM_dataset,\n","                              batch_size=CFG['BATCH_SIZE'],\n","                              shuffle=False)"]},{"cell_type":"code","execution_count":null,"id":"7f29fcb9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692890999798,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"7f29fcb9","outputId":"355f75fe-6210-41d1-8457-40e953214fd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([256, 251]) torch.Size([256, 1])\n"]}],"source":["X_train, y_train = next(iter(train_MLM_loader))\n","print (X_train.shape, y_train.shape)"]},{"cell_type":"code","execution_count":null,"id":"bfd4adf6","metadata":{"id":"bfd4adf6"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self, input_size, hidden_size, dropout_rate, out_size):\n","        super(Net, self).__init__()\n","\n","        self.fc_layers = nn.Sequential(\n","            nn.Linear(input_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.LeakyReLU(),\n","            nn.Dropout(dropout_rate),\n","\n","            nn.Linear(256, 128),\n","            nn.BatchNorm1d(128),\n","            nn.LeakyReLU(),\n","            nn.Dropout(dropout_rate),\n","\n","            nn.Linear(128, 64),\n","            nn.BatchNorm1d(64),\n","            nn.LeakyReLU(),\n","            nn.Dropout(dropout_rate),\n","        )\n","\n","        self.fc_out = nn.Linear(64, out_size)\n","\n","    def forward(self, x):\n","        out = self.fc_layers(x)\n","        out = self.fc_out(out)\n","        return out\n"]},{"cell_type":"code","execution_count":null,"id":"ab4fd7ce","metadata":{"id":"ab4fd7ce"},"outputs":[],"source":["model_MLM = Net(CFG['INPUT_SIZE'],CFG['HIDDEN_SIZE'],CFG['DROPOUT_RATE'],CFG['OUTPUT_SIZE'])\n","model_HLM = Net(CFG['INPUT_SIZE'],CFG['HIDDEN_SIZE'],CFG['DROPOUT_RATE'],CFG['OUTPUT_SIZE'])"]},{"cell_type":"code","execution_count":null,"id":"941a230e","metadata":{"id":"941a230e"},"outputs":[],"source":["import torch.nn as nn\n","\n","class RMSELoss(nn.Module):\n","    def __init__(self):\n","        super(RMSELoss, self).__init__()\n","        self.mse = nn.MSELoss()  # 기존의 MSELoss 함수 사용\n","\n","    def forward(self, output, target):\n","        mse_loss = self.mse(output, target)  # 기존의 MSELoss를 계산\n","        rmse_loss = torch.sqrt(mse_loss)  # MSE에 제곱근 씌워 RMSE 계산\n","        return rmse_loss\n","\n","criterion = RMSELoss()\n","optimizer_MLM = torch.optim.Adam(model_MLM.parameters(), lr=CFG['LEARNING_RATE'])\n","optimizer_HLM = torch.optim.Adam(model_HLM.parameters(), lr=CFG['LEARNING_RATE'])\n"]},{"cell_type":"code","execution_count":null,"id":"c8c50632","metadata":{"id":"c8c50632"},"outputs":[],"source":["def train(train_loader, valid_loader, model, criterion, optimizer, epochs, patience=100):\n","    best_valid_loss = float('inf')\n","    no_improvement_count = 0\n","\n","    for epoch in range(epochs):\n","        model.train()  # 모델을 훈련 모드로 설정\n","        running_loss = 0\n","        for inputs, targets in train_loader:\n","            optimizer.zero_grad()\n","\n","            output = model(inputs)\n","            loss = criterion(output, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        model.eval()  # 모델을 검증 모드로 설정\n","        valid_loss = 0\n","        with torch.no_grad():\n","          for inputs, targets in valid_loader:\n","            output = model(inputs)\n","            loss = criterion(output, targets)\n","            valid_loss += loss.item()\n","\n","        avg_train_loss = running_loss / len(train_loader)\n","        avg_valid_loss = valid_loss / len(valid_loader)\n","        print(f'Epoch: {epoch}/{epochs}, Train Loss: {avg_train_loss}, Valid Loss: {avg_valid_loss}')\n","\n","        if avg_valid_loss < best_valid_loss:\n","          best_valid_loss = avg_valid_loss\n","          no_improvement_count = 0\n","          best_model_state = model.state_dict()\n","        else:\n","          no_improvement_count += 1\n","          if no_improvement_count >= patience:\n","            print(f'얼리 스토핑: {patience} 에포크 동안 검증 손실이 향상되지 않음. 에포크 {epoch}에서 훈련 중단.')\n","            break\n","\n","    # 최적의 모델 상태 불러오기\n","    model.load_state_dict(best_model_state)\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"7bf20b4b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1343434,"status":"ok","timestamp":1692892347028,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"7bf20b4b","outputId":"872e611b-435e-4682-e872-c9208bd9d97d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","Epoch: 1473/10000, Train Loss: 59.582219210538, Valid Loss: 60.284996032714844\n","Epoch: 1474/10000, Train Loss: 59.563293803821914, Valid Loss: 60.28731028238932\n","Epoch: 1475/10000, Train Loss: 59.51677842573686, Valid Loss: 60.26874796549479\n","Epoch: 1476/10000, Train Loss: 59.49861040982333, Valid Loss: 60.285430908203125\n","Epoch: 1477/10000, Train Loss: 59.52472825483842, Valid Loss: 60.32758331298828\n","Epoch: 1478/10000, Train Loss: 59.58949106389826, Valid Loss: 60.29895146687826\n","Epoch: 1479/10000, Train Loss: 59.60484938188033, Valid Loss: 60.233526865641274\n","Epoch: 1480/10000, Train Loss: 59.51445111361417, Valid Loss: 60.255574544270836\n","Epoch: 1481/10000, Train Loss: 59.54997253417969, Valid Loss: 60.216253916422524\n","Epoch: 1482/10000, Train Loss: 59.472693009810015, Valid Loss: 60.25843048095703\n","Epoch: 1483/10000, Train Loss: 59.37907409667969, Valid Loss: 60.24999745686849\n","Epoch: 1484/10000, Train Loss: 59.50044146451083, Valid Loss: 60.228048960367836\n","Epoch: 1485/10000, Train Loss: 59.56687441739169, Valid Loss: 60.23433049519857\n","Epoch: 1486/10000, Train Loss: 59.47682814164595, Valid Loss: 60.1922861735026\n","Epoch: 1487/10000, Train Loss: 59.59825550426137, Valid Loss: 60.23959096272787\n","Epoch: 1488/10000, Train Loss: 59.37351573597301, Valid Loss: 60.22294235229492\n","Epoch: 1489/10000, Train Loss: 59.39299288662997, Valid Loss: 60.24651590983073\n","Epoch: 1490/10000, Train Loss: 59.39970432628285, Valid Loss: 60.23617680867513\n","Epoch: 1491/10000, Train Loss: 59.47992082075639, Valid Loss: 60.2455202738444\n","Epoch: 1492/10000, Train Loss: 59.43490427190607, Valid Loss: 60.15202204386393\n","Epoch: 1493/10000, Train Loss: 59.43363155018199, Valid Loss: 60.25871912638346\n","Epoch: 1494/10000, Train Loss: 59.366784529252485, Valid Loss: 60.217124938964844\n","Epoch: 1495/10000, Train Loss: 59.36124108054421, Valid Loss: 60.225616455078125\n","Epoch: 1496/10000, Train Loss: 59.443297993053086, Valid Loss: 60.2712516784668\n","Epoch: 1497/10000, Train Loss: 59.33789652044123, Valid Loss: 60.2397346496582\n","Epoch: 1498/10000, Train Loss: 59.26064751364968, Valid Loss: 60.22564951578776\n","Epoch: 1499/10000, Train Loss: 59.4619175304066, Valid Loss: 60.23165512084961\n","Epoch: 1500/10000, Train Loss: 59.44842321222479, Valid Loss: 60.24599583943685\n","Epoch: 1501/10000, Train Loss: 59.39607100053267, Valid Loss: 60.199273427327476\n","Epoch: 1502/10000, Train Loss: 59.33362440629439, Valid Loss: 60.190748850504555\n","Epoch: 1503/10000, Train Loss: 59.39916784113104, Valid Loss: 60.26208750406901\n","Epoch: 1504/10000, Train Loss: 59.38327130404386, Valid Loss: 60.22053782145182\n","Epoch: 1505/10000, Train Loss: 59.396842609752305, Valid Loss: 60.21155802408854\n","Epoch: 1506/10000, Train Loss: 59.33041555231268, Valid Loss: 60.239566802978516\n","Epoch: 1507/10000, Train Loss: 59.45340763438832, Valid Loss: 60.190539042154946\n","Epoch: 1508/10000, Train Loss: 59.48672728105025, Valid Loss: 60.23164494832357\n","Epoch: 1509/10000, Train Loss: 59.46134705977006, Valid Loss: 60.12255859375\n","Epoch: 1510/10000, Train Loss: 59.33109352805398, Valid Loss: 60.141361236572266\n","Epoch: 1511/10000, Train Loss: 59.46198584816673, Valid Loss: 60.09604517618815\n","Epoch: 1512/10000, Train Loss: 59.279429002241656, Valid Loss: 60.12294133504232\n","Epoch: 1513/10000, Train Loss: 59.3406535061923, Valid Loss: 60.16559855143229\n","Epoch: 1514/10000, Train Loss: 59.413841941139914, Valid Loss: 60.145538330078125\n","Epoch: 1515/10000, Train Loss: 59.30076148293235, Valid Loss: 60.15975570678711\n","Epoch: 1516/10000, Train Loss: 59.42159860784357, Valid Loss: 60.13277943929037\n","Epoch: 1517/10000, Train Loss: 59.3858888799494, Valid Loss: 60.15932591756185\n","Epoch: 1518/10000, Train Loss: 59.32717444679954, Valid Loss: 60.16963322957357\n","Epoch: 1519/10000, Train Loss: 59.34477858109908, Valid Loss: 60.09675598144531\n","Epoch: 1520/10000, Train Loss: 59.38093532215465, Valid Loss: 60.11056264241537\n","Epoch: 1521/10000, Train Loss: 59.30207581953569, Valid Loss: 60.14084116617838\n","Epoch: 1522/10000, Train Loss: 59.338835282759234, Valid Loss: 60.13404846191406\n","Epoch: 1523/10000, Train Loss: 59.41352705522017, Valid Loss: 60.09625244140625\n","Epoch: 1524/10000, Train Loss: 59.36478528109464, Valid Loss: 60.13398361206055\n","Epoch: 1525/10000, Train Loss: 59.354884754527696, Valid Loss: 60.126946767171226\n","Epoch: 1526/10000, Train Loss: 59.30519762906161, Valid Loss: 60.07229232788086\n","Epoch: 1527/10000, Train Loss: 59.24929289384322, Valid Loss: 60.166760762532554\n","Epoch: 1528/10000, Train Loss: 59.227284864945844, Valid Loss: 60.09658177693685\n","Epoch: 1529/10000, Train Loss: 59.42308391224254, Valid Loss: 60.101183573404946\n","Epoch: 1530/10000, Train Loss: 59.28048255226829, Valid Loss: 60.129215240478516\n","Epoch: 1531/10000, Train Loss: 59.2041542746804, Valid Loss: 60.06562296549479\n","Epoch: 1532/10000, Train Loss: 59.23152958263051, Valid Loss: 60.10919443766276\n","Epoch: 1533/10000, Train Loss: 59.32305214621804, Valid Loss: 60.0623410542806\n","Epoch: 1534/10000, Train Loss: 59.24073964899237, Valid Loss: 60.11371612548828\n","Epoch: 1535/10000, Train Loss: 59.229677720503375, Valid Loss: 60.1084353129069\n","Epoch: 1536/10000, Train Loss: 59.31721357865767, Valid Loss: 60.123046875\n","Epoch: 1537/10000, Train Loss: 59.12981830943715, Valid Loss: 60.10323842366537\n","Epoch: 1538/10000, Train Loss: 59.31854525479403, Valid Loss: 60.053253173828125\n","Epoch: 1539/10000, Train Loss: 59.25402901389382, Valid Loss: 60.11387252807617\n","Epoch: 1540/10000, Train Loss: 59.180141102183946, Valid Loss: 60.08831024169922\n","Epoch: 1541/10000, Train Loss: 59.29860999367454, Valid Loss: 60.10769399007162\n","Epoch: 1542/10000, Train Loss: 59.18888681585138, Valid Loss: 60.10834503173828\n","Epoch: 1543/10000, Train Loss: 59.31541442871094, Valid Loss: 60.02314885457357\n","Epoch: 1544/10000, Train Loss: 59.0954440723766, Valid Loss: 60.070149739583336\n","Epoch: 1545/10000, Train Loss: 59.121766870672054, Valid Loss: 60.08808390299479\n","Epoch: 1546/10000, Train Loss: 59.110578363591976, Valid Loss: 60.04826354980469\n","Epoch: 1547/10000, Train Loss: 59.23589047518644, Valid Loss: 60.028741200764976\n","Epoch: 1548/10000, Train Loss: 59.26054590398615, Valid Loss: 60.02064768473307\n","Epoch: 1549/10000, Train Loss: 59.135208476673476, Valid Loss: 60.04185231526693\n","Epoch: 1550/10000, Train Loss: 59.21866018121893, Valid Loss: 60.03636042277018\n","Epoch: 1551/10000, Train Loss: 59.19850713556463, Valid Loss: 60.07510121663412\n","Epoch: 1552/10000, Train Loss: 59.260648554021664, Valid Loss: 60.08975728352865\n","Epoch: 1553/10000, Train Loss: 59.22023461081765, Valid Loss: 60.05935033162435\n","Epoch: 1554/10000, Train Loss: 59.170216993852094, Valid Loss: 60.03857549031576\n","Epoch: 1555/10000, Train Loss: 59.12199505892667, Valid Loss: 60.03140640258789\n","Epoch: 1556/10000, Train Loss: 59.24962338534269, Valid Loss: 60.0360959370931\n","Epoch: 1557/10000, Train Loss: 59.26066207885742, Valid Loss: 60.06899642944336\n","Epoch: 1558/10000, Train Loss: 59.201087951660156, Valid Loss: 60.07871627807617\n","Epoch: 1559/10000, Train Loss: 59.13915183327415, Valid Loss: 60.029492696126304\n","Epoch: 1560/10000, Train Loss: 59.13242686878551, Valid Loss: 60.010233561197914\n","Epoch: 1561/10000, Train Loss: 59.09491521661932, Valid Loss: 60.044812520345054\n","Epoch: 1562/10000, Train Loss: 59.142975547096945, Valid Loss: 60.06548817952474\n","Epoch: 1563/10000, Train Loss: 59.09500018033114, Valid Loss: 60.04979578653971\n","Epoch: 1564/10000, Train Loss: 59.1643479087136, Valid Loss: 59.962354024251304\n","Epoch: 1565/10000, Train Loss: 59.16641963611949, Valid Loss: 59.999603271484375\n","Epoch: 1566/10000, Train Loss: 59.108495538884945, Valid Loss: 60.03133646647135\n","Epoch: 1567/10000, Train Loss: 59.131759296764024, Valid Loss: 59.971753438313804\n","Epoch: 1568/10000, Train Loss: 59.00282183560458, Valid Loss: 59.96943918863932\n","Epoch: 1569/10000, Train Loss: 59.078743327747695, Valid Loss: 60.04036966959635\n","Epoch: 1570/10000, Train Loss: 59.138884110884234, Valid Loss: 60.02124786376953\n","Epoch: 1571/10000, Train Loss: 59.14293254505504, Valid Loss: 59.99191411336263\n","Epoch: 1572/10000, Train Loss: 59.168237859552555, Valid Loss: 59.94225819905599\n","Epoch: 1573/10000, Train Loss: 59.09302451393821, Valid Loss: 59.972391764322914\n","Epoch: 1574/10000, Train Loss: 59.18421450528231, Valid Loss: 59.96926752726237\n","Epoch: 1575/10000, Train Loss: 59.07164556329901, Valid Loss: 59.97046025594076\n","Epoch: 1576/10000, Train Loss: 59.11784362792969, Valid Loss: 59.9753303527832\n","Epoch: 1577/10000, Train Loss: 59.075537248091265, Valid Loss: 60.03251647949219\n","Epoch: 1578/10000, Train Loss: 59.06485574895685, Valid Loss: 60.01937484741211\n","Epoch: 1579/10000, Train Loss: 58.964040929620914, Valid Loss: 60.034586588541664\n","Epoch: 1580/10000, Train Loss: 58.95273486050692, Valid Loss: 59.96166483561198\n","Epoch: 1581/10000, Train Loss: 59.143266851251774, Valid Loss: 59.93302917480469\n","Epoch: 1582/10000, Train Loss: 59.05073512684215, Valid Loss: 59.966102600097656\n","Epoch: 1583/10000, Train Loss: 59.10563486272638, Valid Loss: 59.92249425252279\n","Epoch: 1584/10000, Train Loss: 58.987514149058946, Valid Loss: 59.97683461507162\n","Epoch: 1585/10000, Train Loss: 58.87428040937944, Valid Loss: 59.946720123291016\n","Epoch: 1586/10000, Train Loss: 59.14320026744496, Valid Loss: 59.917765299479164\n","Epoch: 1587/10000, Train Loss: 58.981082916259766, Valid Loss: 59.92281850179037\n","Epoch: 1588/10000, Train Loss: 59.03199698708274, Valid Loss: 59.925760904947914\n","Epoch: 1589/10000, Train Loss: 59.115906802090734, Valid Loss: 59.948795318603516\n","Epoch: 1590/10000, Train Loss: 59.03675287420099, Valid Loss: 59.92482376098633\n","Epoch: 1591/10000, Train Loss: 58.94085277210582, Valid Loss: 59.879695892333984\n","Epoch: 1592/10000, Train Loss: 58.93060996315696, Valid Loss: 59.916184743245445\n","Epoch: 1593/10000, Train Loss: 59.0730507590554, Valid Loss: 59.908929189046226\n","Epoch: 1594/10000, Train Loss: 59.00284784490412, Valid Loss: 59.93628184000651\n","Epoch: 1595/10000, Train Loss: 59.07293631813743, Valid Loss: 59.895432790120445\n","Epoch: 1596/10000, Train Loss: 58.9631760337136, Valid Loss: 59.92576471964518\n","Epoch: 1597/10000, Train Loss: 58.949767026034266, Valid Loss: 59.90638732910156\n","Epoch: 1598/10000, Train Loss: 58.879776347767226, Valid Loss: 59.91891098022461\n","Epoch: 1599/10000, Train Loss: 59.02030702070756, Valid Loss: 59.86168670654297\n","Epoch: 1600/10000, Train Loss: 58.92613462968306, Valid Loss: 59.900193532307945\n","Epoch: 1601/10000, Train Loss: 58.82606957175515, Valid Loss: 59.84192148844401\n","Epoch: 1602/10000, Train Loss: 58.97440026023171, Valid Loss: 59.84540685017904\n","Epoch: 1603/10000, Train Loss: 58.88951249556108, Valid Loss: 59.89667638142904\n","Epoch: 1604/10000, Train Loss: 58.90303421020508, Valid Loss: 59.93221918741862\n","Epoch: 1605/10000, Train Loss: 58.95362056385387, Valid Loss: 59.90169143676758\n","Epoch: 1606/10000, Train Loss: 58.81030550870028, Valid Loss: 59.88012822469076\n","Epoch: 1607/10000, Train Loss: 58.91175530173562, Valid Loss: 59.842978159586586\n","Epoch: 1608/10000, Train Loss: 58.99235361272638, Valid Loss: 59.835304260253906\n","Epoch: 1609/10000, Train Loss: 58.96138069846413, Valid Loss: 59.86907704671224\n","Epoch: 1610/10000, Train Loss: 59.025090304288, Valid Loss: 59.86090977986654\n","Epoch: 1611/10000, Train Loss: 58.90502236106179, Valid Loss: 59.88722483317057\n","Epoch: 1612/10000, Train Loss: 58.82822799682617, Valid Loss: 59.89578501383463\n","Epoch: 1613/10000, Train Loss: 58.843714627352625, Valid Loss: 59.821587880452476\n","Epoch: 1614/10000, Train Loss: 58.67205186323686, Valid Loss: 59.81612777709961\n","Epoch: 1615/10000, Train Loss: 58.96537711403587, Valid Loss: 59.81277592976888\n","Epoch: 1616/10000, Train Loss: 58.75965985384855, Valid Loss: 59.81524403889974\n","Epoch: 1617/10000, Train Loss: 58.77265860817649, Valid Loss: 59.852282206217446\n","Epoch: 1618/10000, Train Loss: 58.800110210071914, Valid Loss: 59.81397247314453\n","Epoch: 1619/10000, Train Loss: 58.853062716397375, Valid Loss: 59.8637949625651\n","Epoch: 1620/10000, Train Loss: 58.816831068559125, Valid Loss: 59.81197992960612\n","Epoch: 1621/10000, Train Loss: 58.82141668146307, Valid Loss: 59.89069747924805\n","Epoch: 1622/10000, Train Loss: 58.84609257091176, Valid Loss: 59.84959284464518\n","Epoch: 1623/10000, Train Loss: 58.808110670609906, Valid Loss: 59.842428843180336\n","Epoch: 1624/10000, Train Loss: 58.79849693991921, Valid Loss: 59.85280100504557\n","Epoch: 1625/10000, Train Loss: 58.91664678400213, Valid Loss: 59.8289909362793\n","Epoch: 1626/10000, Train Loss: 58.79691557450728, Valid Loss: 59.84805806477865\n","Epoch: 1627/10000, Train Loss: 58.7772331237793, Valid Loss: 59.78142293294271\n","Epoch: 1628/10000, Train Loss: 58.86920512806285, Valid Loss: 59.84305191040039\n","Epoch: 1629/10000, Train Loss: 58.81647803566673, Valid Loss: 59.821475982666016\n","Epoch: 1630/10000, Train Loss: 58.71590076793324, Valid Loss: 59.732269287109375\n","Epoch: 1631/10000, Train Loss: 58.81418124112216, Valid Loss: 59.79229990641276\n","Epoch: 1632/10000, Train Loss: 58.76505661010742, Valid Loss: 59.81109873453776\n","Epoch: 1633/10000, Train Loss: 58.699702522971414, Valid Loss: 59.86352284749349\n","Epoch: 1634/10000, Train Loss: 58.84996379505504, Valid Loss: 59.75872802734375\n","Epoch: 1635/10000, Train Loss: 58.84855929287997, Valid Loss: 59.769266764322914\n","Epoch: 1636/10000, Train Loss: 58.68518968061967, Valid Loss: 59.776885986328125\n","Epoch: 1637/10000, Train Loss: 58.840941342440516, Valid Loss: 59.78738021850586\n","Epoch: 1638/10000, Train Loss: 58.881792241876774, Valid Loss: 59.734124501546226\n","Epoch: 1639/10000, Train Loss: 58.63192402232777, Valid Loss: 59.731030782063804\n","Epoch: 1640/10000, Train Loss: 58.76294014670632, Valid Loss: 59.68517176310221\n","Epoch: 1641/10000, Train Loss: 58.71315626664595, Valid Loss: 59.777200063069664\n","Epoch: 1642/10000, Train Loss: 58.635289972478695, Valid Loss: 59.76308822631836\n","Epoch: 1643/10000, Train Loss: 58.810049923983485, Valid Loss: 59.71304066975912\n","Epoch: 1644/10000, Train Loss: 58.67756618152965, Valid Loss: 59.72914250691732\n","Epoch: 1645/10000, Train Loss: 58.75737207586115, Valid Loss: 59.694679260253906\n","Epoch: 1646/10000, Train Loss: 58.83613829179244, Valid Loss: 59.767523447672524\n","Epoch: 1647/10000, Train Loss: 58.6570500460538, Valid Loss: 59.700303395589195\n","Epoch: 1648/10000, Train Loss: 58.680462230335586, Valid Loss: 59.69163513183594\n","Epoch: 1649/10000, Train Loss: 58.54823858087713, Valid Loss: 59.69252014160156\n","Epoch: 1650/10000, Train Loss: 58.686796014959164, Valid Loss: 59.69578552246094\n","Epoch: 1651/10000, Train Loss: 58.76512770219283, Valid Loss: 59.70845413208008\n","Epoch: 1652/10000, Train Loss: 58.712437022816054, Valid Loss: 59.72971852620443\n","Epoch: 1653/10000, Train Loss: 58.79585959694602, Valid Loss: 59.63148880004883\n","Epoch: 1654/10000, Train Loss: 58.697944987903945, Valid Loss: 59.65423075358073\n","Epoch: 1655/10000, Train Loss: 58.604380174116656, Valid Loss: 59.724114735921226\n","Epoch: 1656/10000, Train Loss: 58.56498475508256, Valid Loss: 59.687844594319664\n","Epoch: 1657/10000, Train Loss: 58.664304906671696, Valid Loss: 59.68038431803385\n","Epoch: 1658/10000, Train Loss: 58.76314163208008, Valid Loss: 59.67723719278971\n","Epoch: 1659/10000, Train Loss: 58.72479178688743, Valid Loss: 59.65904108683268\n","Epoch: 1660/10000, Train Loss: 58.71934821388938, Valid Loss: 59.673407236735024\n","Epoch: 1661/10000, Train Loss: 58.693446766246446, Valid Loss: 59.65508143107096\n","Epoch: 1662/10000, Train Loss: 58.60518438165838, Valid Loss: 59.63014348347982\n","Epoch: 1663/10000, Train Loss: 58.80158060247248, Valid Loss: 59.630690256754555\n","Epoch: 1664/10000, Train Loss: 58.68972466208718, Valid Loss: 59.66786448160807\n","Epoch: 1665/10000, Train Loss: 58.647817091508344, Valid Loss: 59.703636169433594\n","Epoch: 1666/10000, Train Loss: 58.6286787553267, Valid Loss: 59.65834426879883\n","Epoch: 1667/10000, Train Loss: 58.68381812355735, Valid Loss: 59.691168467203774\n","Epoch: 1668/10000, Train Loss: 58.57768596302379, Valid Loss: 59.7009162902832\n","Epoch: 1669/10000, Train Loss: 58.63115865534002, Valid Loss: 59.694985707600914\n","Epoch: 1670/10000, Train Loss: 58.56190213290128, Valid Loss: 59.608282725016274\n","Epoch: 1671/10000, Train Loss: 58.677520751953125, Valid Loss: 59.597957611083984\n","Epoch: 1672/10000, Train Loss: 58.77401351928711, Valid Loss: 59.65082550048828\n","Epoch: 1673/10000, Train Loss: 58.61137424815785, Valid Loss: 59.60053634643555\n","Epoch: 1674/10000, Train Loss: 58.62292549826882, Valid Loss: 59.561363220214844\n","Epoch: 1675/10000, Train Loss: 58.52537952769887, Valid Loss: 59.620782216389976\n","Epoch: 1676/10000, Train Loss: 58.64823115955699, Valid Loss: 59.62764104207357\n","Epoch: 1677/10000, Train Loss: 58.77688633311879, Valid Loss: 59.64265060424805\n","Epoch: 1678/10000, Train Loss: 58.662810585715555, Valid Loss: 59.66746393839518\n","Epoch: 1679/10000, Train Loss: 58.58530876853249, Valid Loss: 59.6622200012207\n","Epoch: 1680/10000, Train Loss: 58.50858202847567, Valid Loss: 59.59015401204427\n","Epoch: 1681/10000, Train Loss: 58.6340217590332, Valid Loss: 59.62079620361328\n","Epoch: 1682/10000, Train Loss: 58.49654908613725, Valid Loss: 59.582977294921875\n","Epoch: 1683/10000, Train Loss: 58.50998202237216, Valid Loss: 59.523504892985024\n","Epoch: 1684/10000, Train Loss: 58.591379685835406, Valid Loss: 59.60647328694662\n","Epoch: 1685/10000, Train Loss: 58.558561845259234, Valid Loss: 59.58398183186849\n","Epoch: 1686/10000, Train Loss: 58.637372103604406, Valid Loss: 59.54049301147461\n","Epoch: 1687/10000, Train Loss: 58.48368176546964, Valid Loss: 59.585577646891274\n","Epoch: 1688/10000, Train Loss: 58.53973388671875, Valid Loss: 59.62250900268555\n","Epoch: 1689/10000, Train Loss: 58.40849546952681, Valid Loss: 59.486944834391274\n","Epoch: 1690/10000, Train Loss: 58.511473569003016, Valid Loss: 59.525543212890625\n","Epoch: 1691/10000, Train Loss: 58.51727711070668, Valid Loss: 59.48277282714844\n","Epoch: 1692/10000, Train Loss: 58.32516306096857, Valid Loss: 59.51867167154948\n","Epoch: 1693/10000, Train Loss: 58.55416141856801, Valid Loss: 59.52848561604818\n","Epoch: 1694/10000, Train Loss: 58.489385084672406, Valid Loss: 59.60508346557617\n","Epoch: 1695/10000, Train Loss: 58.45685924183238, Valid Loss: 59.556575775146484\n","Epoch: 1696/10000, Train Loss: 58.54545281150124, Valid Loss: 59.56679153442383\n","Epoch: 1697/10000, Train Loss: 58.46721267700195, Valid Loss: 59.52074305216471\n","Epoch: 1698/10000, Train Loss: 58.46914984963157, Valid Loss: 59.57485707600912\n","Epoch: 1699/10000, Train Loss: 58.433992559259586, Valid Loss: 59.51447296142578\n","Epoch: 1700/10000, Train Loss: 58.45739017833363, Valid Loss: 59.57059860229492\n","Epoch: 1701/10000, Train Loss: 58.476641568270594, Valid Loss: 59.530722300211586\n","Epoch: 1702/10000, Train Loss: 58.486386039040305, Valid Loss: 59.55465443929037\n","Epoch: 1703/10000, Train Loss: 58.4588772166859, Valid Loss: 59.59387715657552\n","Epoch: 1704/10000, Train Loss: 58.39103213223544, Valid Loss: 59.540974934895836\n","Epoch: 1705/10000, Train Loss: 58.52596664428711, Valid Loss: 59.492557525634766\n","Epoch: 1706/10000, Train Loss: 58.46306332674894, Valid Loss: 59.39737447102865\n","Epoch: 1707/10000, Train Loss: 58.57408835671165, Valid Loss: 59.45000457763672\n","Epoch: 1708/10000, Train Loss: 58.49031552401456, Valid Loss: 59.52744674682617\n","Epoch: 1709/10000, Train Loss: 58.50960922241211, Valid Loss: 59.51419194539388\n","Epoch: 1710/10000, Train Loss: 58.58020990545099, Valid Loss: 59.45822397867838\n","Epoch: 1711/10000, Train Loss: 58.38825884732333, Valid Loss: 59.45901616414388\n","Epoch: 1712/10000, Train Loss: 58.59703514792702, Valid Loss: 59.45649719238281\n","Epoch: 1713/10000, Train Loss: 58.46792255748402, Valid Loss: 59.45505396525065\n","Epoch: 1714/10000, Train Loss: 58.40510697798295, Valid Loss: 59.432865142822266\n","Epoch: 1715/10000, Train Loss: 58.51567320390181, Valid Loss: 59.487342834472656\n","Epoch: 1716/10000, Train Loss: 58.40764167092063, Valid Loss: 59.47943878173828\n","Epoch: 1717/10000, Train Loss: 58.51694696599787, Valid Loss: 59.51271438598633\n","Epoch: 1718/10000, Train Loss: 58.410392414439805, Valid Loss: 59.516971588134766\n","Epoch: 1719/10000, Train Loss: 58.21988955411044, Valid Loss: 59.5191281636556\n","Epoch: 1720/10000, Train Loss: 58.30454566261985, Valid Loss: 59.53280512491862\n","Epoch: 1721/10000, Train Loss: 58.283001292835586, Valid Loss: 59.50175348917643\n","Epoch: 1722/10000, Train Loss: 58.36469546231356, Valid Loss: 59.532301584879555\n","Epoch: 1723/10000, Train Loss: 58.34772491455078, Valid Loss: 59.42695744832357\n","Epoch: 1724/10000, Train Loss: 58.40484480424361, Valid Loss: 59.44767506917318\n","Epoch: 1725/10000, Train Loss: 58.20213768698952, Valid Loss: 59.39239374796549\n","Epoch: 1726/10000, Train Loss: 58.37412227283824, Valid Loss: 59.42639032999674\n","Epoch: 1727/10000, Train Loss: 58.259063720703125, Valid Loss: 59.43818664550781\n","Epoch: 1728/10000, Train Loss: 58.213508952747695, Valid Loss: 59.45645014444987\n","Epoch: 1729/10000, Train Loss: 58.24526665427468, Valid Loss: 59.48582967122396\n","Epoch: 1730/10000, Train Loss: 58.30354101007635, Valid Loss: 59.38868967692057\n","Epoch: 1731/10000, Train Loss: 58.38114755803888, Valid Loss: 59.39937210083008\n","Epoch: 1732/10000, Train Loss: 58.30824349143288, Valid Loss: 59.405537923177086\n","Epoch: 1733/10000, Train Loss: 58.27237042513761, Valid Loss: 59.37774658203125\n","Epoch: 1734/10000, Train Loss: 58.31637920032848, Valid Loss: 59.40049489339193\n","Epoch: 1735/10000, Train Loss: 58.27411929043856, Valid Loss: 59.36824035644531\n","Epoch: 1736/10000, Train Loss: 58.33348187533292, Valid Loss: 59.34340286254883\n","Epoch: 1737/10000, Train Loss: 58.30050277709961, Valid Loss: 59.42809804280599\n","Epoch: 1738/10000, Train Loss: 58.26607444069602, Valid Loss: 59.43503952026367\n","Epoch: 1739/10000, Train Loss: 58.21883981878107, Valid Loss: 59.394598642985024\n","Epoch: 1740/10000, Train Loss: 58.333309867165305, Valid Loss: 59.36693572998047\n","Epoch: 1741/10000, Train Loss: 58.18877757679332, Valid Loss: 59.32528813680013\n","Epoch: 1742/10000, Train Loss: 58.31566897305575, Valid Loss: 59.3074099222819\n","Epoch: 1743/10000, Train Loss: 58.15987812389027, Valid Loss: 59.44029744466146\n","Epoch: 1744/10000, Train Loss: 58.25107088955966, Valid Loss: 59.405775705973305\n","Epoch: 1745/10000, Train Loss: 58.35149730335582, Valid Loss: 59.39430491129557\n","Epoch: 1746/10000, Train Loss: 58.178286812522195, Valid Loss: 59.330518086751304\n","Epoch: 1747/10000, Train Loss: 58.26557991721413, Valid Loss: 59.379310607910156\n","Epoch: 1748/10000, Train Loss: 58.18430016257546, Valid Loss: 59.37777837117513\n","Epoch: 1749/10000, Train Loss: 58.13572033968839, Valid Loss: 59.36616007486979\n","Epoch: 1750/10000, Train Loss: 58.19519112326882, Valid Loss: 59.2837880452474\n","Epoch: 1751/10000, Train Loss: 58.249270005659625, Valid Loss: 59.35947291056315\n","Epoch: 1752/10000, Train Loss: 58.28002270785245, Valid Loss: 59.292022705078125\n","Epoch: 1753/10000, Train Loss: 58.10414366288619, Valid Loss: 59.2904421488444\n","Epoch: 1754/10000, Train Loss: 58.30157678777521, Valid Loss: 59.44417826334635\n","Epoch: 1755/10000, Train Loss: 58.15325026078658, Valid Loss: 59.39024353027344\n","Epoch: 1756/10000, Train Loss: 58.2762038490989, Valid Loss: 59.34968566894531\n","Epoch: 1757/10000, Train Loss: 58.132465015758164, Valid Loss: 59.32891845703125\n","Epoch: 1758/10000, Train Loss: 58.247704245827414, Valid Loss: 59.29116948445638\n","Epoch: 1759/10000, Train Loss: 58.11859824440696, Valid Loss: 59.32708994547526\n","Epoch: 1760/10000, Train Loss: 58.07406304099343, Valid Loss: 59.43068186442057\n","Epoch: 1761/10000, Train Loss: 58.070710615678266, Valid Loss: 59.313079833984375\n","Epoch: 1762/10000, Train Loss: 58.065711281516336, Valid Loss: 59.28749084472656\n","Epoch: 1763/10000, Train Loss: 58.18165831132369, Valid Loss: 59.254591623942055\n","Epoch: 1764/10000, Train Loss: 58.13056529651988, Valid Loss: 59.344017028808594\n","Epoch: 1765/10000, Train Loss: 58.26217755404386, Valid Loss: 59.32372156778971\n","Epoch: 1766/10000, Train Loss: 58.225465601140804, Valid Loss: 59.35887781778971\n","Epoch: 1767/10000, Train Loss: 58.04188988425515, Valid Loss: 59.21480051676432\n","Epoch: 1768/10000, Train Loss: 58.090558832341976, Valid Loss: 59.271705627441406\n","Epoch: 1769/10000, Train Loss: 58.064848466352984, Valid Loss: 59.247711181640625\n","Epoch: 1770/10000, Train Loss: 58.175837776877664, Valid Loss: 59.324563344319664\n","Epoch: 1771/10000, Train Loss: 58.08914496681907, Valid Loss: 59.332417805989586\n","Epoch: 1772/10000, Train Loss: 58.22605237093839, Valid Loss: 59.30524698893229\n","Epoch: 1773/10000, Train Loss: 58.18494380604137, Valid Loss: 59.26727294921875\n","Epoch: 1774/10000, Train Loss: 58.13757046786222, Valid Loss: 59.25660959879557\n","Epoch: 1775/10000, Train Loss: 58.12219168923118, Valid Loss: 59.229193369547524\n","Epoch: 1776/10000, Train Loss: 58.02070478959517, Valid Loss: 59.26958465576172\n","Epoch: 1777/10000, Train Loss: 58.23688160289418, Valid Loss: 59.26040267944336\n","Epoch: 1778/10000, Train Loss: 58.17131874778054, Valid Loss: 59.26355743408203\n","Epoch: 1779/10000, Train Loss: 57.958642439408735, Valid Loss: 59.19233322143555\n","Epoch: 1780/10000, Train Loss: 58.1311579617587, Valid Loss: 59.16873677571615\n","Epoch: 1781/10000, Train Loss: 57.93601677634499, Valid Loss: 59.18317159016927\n","Epoch: 1782/10000, Train Loss: 58.09571040760387, Valid Loss: 59.24734369913737\n","Epoch: 1783/10000, Train Loss: 57.994874780828304, Valid Loss: 59.277757008870445\n","Epoch: 1784/10000, Train Loss: 58.07137263904918, Valid Loss: 59.31718826293945\n","Epoch: 1785/10000, Train Loss: 58.14030803333629, Valid Loss: 59.272963205973305\n","Epoch: 1786/10000, Train Loss: 58.12401719526811, Valid Loss: 59.205954233805336\n","Epoch: 1787/10000, Train Loss: 58.107817909934305, Valid Loss: 59.22685877482096\n","Epoch: 1788/10000, Train Loss: 58.02642822265625, Valid Loss: 59.24206034342448\n","Epoch: 1789/10000, Train Loss: 58.11029746315696, Valid Loss: 59.27475102742513\n","Epoch: 1790/10000, Train Loss: 57.911354064941406, Valid Loss: 59.259246826171875\n","Epoch: 1791/10000, Train Loss: 57.951133728027344, Valid Loss: 59.197811126708984\n","Epoch: 1792/10000, Train Loss: 58.14267418601296, Valid Loss: 59.16500600179037\n","Epoch: 1793/10000, Train Loss: 57.96103737571023, Valid Loss: 59.179203033447266\n","Epoch: 1794/10000, Train Loss: 57.97208161787553, Valid Loss: 59.181992848714195\n","Epoch: 1795/10000, Train Loss: 57.99006583473899, Valid Loss: 59.07949574788412\n","Epoch: 1796/10000, Train Loss: 57.95737491954457, Valid Loss: 59.14429219563802\n","Epoch: 1797/10000, Train Loss: 57.91412214799361, Valid Loss: 59.1528434753418\n","Epoch: 1798/10000, Train Loss: 57.93648702448065, Valid Loss: 59.241259256998696\n","Epoch: 1799/10000, Train Loss: 58.02765308726918, Valid Loss: 59.21871693929037\n","Epoch: 1800/10000, Train Loss: 58.010228243741125, Valid Loss: 59.15425491333008\n","Epoch: 1801/10000, Train Loss: 57.977991277521305, Valid Loss: 59.185743967692055\n","Epoch: 1802/10000, Train Loss: 57.989385084672406, Valid Loss: 59.144795735677086\n","Epoch: 1803/10000, Train Loss: 58.11028636585582, Valid Loss: 59.111611684163414\n","Epoch: 1804/10000, Train Loss: 57.91259072043679, Valid Loss: 59.143349965413414\n","Epoch: 1805/10000, Train Loss: 57.80067894675515, Valid Loss: 59.203269958496094\n","Epoch: 1806/10000, Train Loss: 57.99238829179244, Valid Loss: 59.1776974995931\n","Epoch: 1807/10000, Train Loss: 58.03539414839311, Valid Loss: 59.14975357055664\n","Epoch: 1808/10000, Train Loss: 57.81426793878729, Valid Loss: 59.183722178141274\n","Epoch: 1809/10000, Train Loss: 57.99734774502841, Valid Loss: 59.211961110432945\n","Epoch: 1810/10000, Train Loss: 57.955663507634945, Valid Loss: 59.1890983581543\n","Epoch: 1811/10000, Train Loss: 57.875795884565875, Valid Loss: 59.11922709147135\n","Epoch: 1812/10000, Train Loss: 58.01750495217063, Valid Loss: 59.13480122884115\n","Epoch: 1813/10000, Train Loss: 57.81192259355025, Valid Loss: 59.08978525797526\n","Epoch: 1814/10000, Train Loss: 57.89484786987305, Valid Loss: 59.07963180541992\n","Epoch: 1815/10000, Train Loss: 57.91516668146307, Valid Loss: 59.07589594523112\n","Epoch: 1816/10000, Train Loss: 57.86097717285156, Valid Loss: 59.079229990641274\n","Epoch: 1817/10000, Train Loss: 57.91630311445756, Valid Loss: 59.05239232381185\n","Epoch: 1818/10000, Train Loss: 57.84433364868164, Valid Loss: 59.03637186686198\n","Epoch: 1819/10000, Train Loss: 57.887088775634766, Valid Loss: 59.11565399169922\n","Epoch: 1820/10000, Train Loss: 57.97106864235618, Valid Loss: 59.08187484741211\n","Epoch: 1821/10000, Train Loss: 57.82749453457919, Valid Loss: 59.111924489339195\n","Epoch: 1822/10000, Train Loss: 57.873620466752485, Valid Loss: 59.06641133626302\n","Epoch: 1823/10000, Train Loss: 57.736053466796875, Valid Loss: 58.992872873942055\n","Epoch: 1824/10000, Train Loss: 57.85921963778409, Valid Loss: 59.004564921061196\n","Epoch: 1825/10000, Train Loss: 57.962405464865945, Valid Loss: 59.085211435953774\n","Epoch: 1826/10000, Train Loss: 57.731260473077946, Valid Loss: 59.07431157430013\n","Epoch: 1827/10000, Train Loss: 57.86526801369407, Valid Loss: 59.01354853312174\n","Epoch: 1828/10000, Train Loss: 57.792668429288, Valid Loss: 59.09266026814779\n","Epoch: 1829/10000, Train Loss: 57.88997303355824, Valid Loss: 59.015524546305336\n","Epoch: 1830/10000, Train Loss: 57.76771649447355, Valid Loss: 59.039658864339195\n","Epoch: 1831/10000, Train Loss: 57.74745420976119, Valid Loss: 59.02438608805338\n","Epoch: 1832/10000, Train Loss: 57.84880308671431, Valid Loss: 59.01240158081055\n","Epoch: 1833/10000, Train Loss: 57.813202597878195, Valid Loss: 59.00047302246094\n","Epoch: 1834/10000, Train Loss: 57.87096578424627, Valid Loss: 58.978416442871094\n","Epoch: 1835/10000, Train Loss: 57.775504719127305, Valid Loss: 59.0337282816569\n","Epoch: 1836/10000, Train Loss: 57.783360567959875, Valid Loss: 59.028008778889976\n","Epoch: 1837/10000, Train Loss: 57.69493449818004, Valid Loss: 59.01603571573893\n","Epoch: 1838/10000, Train Loss: 57.772077387029476, Valid Loss: 59.0311648050944\n","Epoch: 1839/10000, Train Loss: 57.91549370505593, Valid Loss: 59.0326296488444\n","Epoch: 1840/10000, Train Loss: 57.7345744046298, Valid Loss: 59.03562545776367\n","Epoch: 1841/10000, Train Loss: 57.737483284690164, Valid Loss: 59.07854080200195\n","Epoch: 1842/10000, Train Loss: 57.86651021784002, Valid Loss: 59.06540044148763\n","Epoch: 1843/10000, Train Loss: 57.7715669111772, Valid Loss: 59.035909016927086\n","Epoch: 1844/10000, Train Loss: 57.640045859596945, Valid Loss: 58.89553451538086\n","Epoch: 1845/10000, Train Loss: 57.79796635020863, Valid Loss: 58.96295674641927\n","Epoch: 1846/10000, Train Loss: 57.7093391418457, Valid Loss: 58.939456939697266\n","Epoch: 1847/10000, Train Loss: 57.685434168035336, Valid Loss: 58.93388366699219\n","Epoch: 1848/10000, Train Loss: 57.59634919600053, Valid Loss: 58.90176010131836\n","Epoch: 1849/10000, Train Loss: 57.758475910533555, Valid Loss: 58.89185460408529\n","Epoch: 1850/10000, Train Loss: 57.79115364768288, Valid Loss: 58.95829772949219\n","Epoch: 1851/10000, Train Loss: 57.736770976673476, Valid Loss: 58.94517135620117\n","Epoch: 1852/10000, Train Loss: 57.71818299727006, Valid Loss: 58.96172078450521\n","Epoch: 1853/10000, Train Loss: 57.8067477833141, Valid Loss: 59.006692250569664\n","Epoch: 1854/10000, Train Loss: 57.68238379738548, Valid Loss: 58.984273274739586\n","Epoch: 1855/10000, Train Loss: 57.559240861372515, Valid Loss: 59.005688985188804\n","Epoch: 1856/10000, Train Loss: 57.84077037464488, Valid Loss: 58.971482594807945\n","Epoch: 1857/10000, Train Loss: 57.62431578202681, Valid Loss: 58.95805231730143\n","Epoch: 1858/10000, Train Loss: 57.76936132257635, Valid Loss: 58.901912689208984\n","Epoch: 1859/10000, Train Loss: 57.79121329567649, Valid Loss: 58.879564921061196\n","Epoch: 1860/10000, Train Loss: 57.68567033247514, Valid Loss: 58.91746139526367\n","Epoch: 1861/10000, Train Loss: 57.60935662009499, Valid Loss: 58.974074045817055\n","Epoch: 1862/10000, Train Loss: 57.74421761252663, Valid Loss: 58.94681040445963\n","Epoch: 1863/10000, Train Loss: 57.647154721346766, Valid Loss: 58.90133794148763\n","Epoch: 1864/10000, Train Loss: 57.670296062122695, Valid Loss: 58.9192746480306\n","Epoch: 1865/10000, Train Loss: 57.53516179865057, Valid Loss: 58.91664123535156\n","Epoch: 1866/10000, Train Loss: 57.71670220114968, Valid Loss: 58.90679423014323\n","Epoch: 1867/10000, Train Loss: 57.651153564453125, Valid Loss: 58.879554748535156\n","Epoch: 1868/10000, Train Loss: 57.713170831853695, Valid Loss: 58.93812688191732\n","Epoch: 1869/10000, Train Loss: 57.4745022166859, Valid Loss: 58.88899230957031\n","Epoch: 1870/10000, Train Loss: 57.64970952814276, Valid Loss: 58.88382466634115\n","Epoch: 1871/10000, Train Loss: 57.60264518044212, Valid Loss: 58.863268534342446\n","Epoch: 1872/10000, Train Loss: 57.65727511319247, Valid Loss: 58.860846201578774\n","Epoch: 1873/10000, Train Loss: 57.84530917080966, Valid Loss: 58.868675231933594\n","Epoch: 1874/10000, Train Loss: 57.68658031116832, Valid Loss: 58.9149055480957\n","Epoch: 1875/10000, Train Loss: 57.61217706853693, Valid Loss: 58.87390391031901\n","Epoch: 1876/10000, Train Loss: 57.45649164373224, Valid Loss: 58.81010055541992\n","Epoch: 1877/10000, Train Loss: 57.66207781704989, Valid Loss: 58.76073201497396\n","Epoch: 1878/10000, Train Loss: 57.71139214255593, Valid Loss: 58.83063888549805\n","Epoch: 1879/10000, Train Loss: 57.592951341108844, Valid Loss: 58.85384750366211\n","Epoch: 1880/10000, Train Loss: 57.51044394753196, Valid Loss: 58.76219813028971\n","Epoch: 1881/10000, Train Loss: 57.608800714666195, Valid Loss: 58.83141072591146\n","Epoch: 1882/10000, Train Loss: 57.51514296098189, Valid Loss: 58.83012135823568\n","Epoch: 1883/10000, Train Loss: 57.5186240456321, Valid Loss: 58.834075927734375\n","Epoch: 1884/10000, Train Loss: 57.536209453235976, Valid Loss: 58.834145863850914\n","Epoch: 1885/10000, Train Loss: 57.63399817726829, Valid Loss: 58.832275390625\n","Epoch: 1886/10000, Train Loss: 57.51259231567383, Valid Loss: 58.76281483968099\n","Epoch: 1887/10000, Train Loss: 57.61237196488814, Valid Loss: 58.73282368977865\n","Epoch: 1888/10000, Train Loss: 57.6823449568315, Valid Loss: 58.85563278198242\n","Epoch: 1889/10000, Train Loss: 57.420042904940516, Valid Loss: 58.823134104410805\n","Epoch: 1890/10000, Train Loss: 57.565561121160336, Valid Loss: 58.72622426350912\n","Epoch: 1891/10000, Train Loss: 57.56783329356801, Valid Loss: 58.77774175008138\n","Epoch: 1892/10000, Train Loss: 57.58916057239879, Valid Loss: 58.78880182902018\n","Epoch: 1893/10000, Train Loss: 57.509671991521664, Valid Loss: 58.8028818766276\n","Epoch: 1894/10000, Train Loss: 57.404572920365766, Valid Loss: 58.76915613810221\n","Epoch: 1895/10000, Train Loss: 57.52802692760121, Valid Loss: 58.66011301676432\n","Epoch: 1896/10000, Train Loss: 57.59113277088512, Valid Loss: 58.76656595865885\n","Epoch: 1897/10000, Train Loss: 57.48421270197088, Valid Loss: 58.7419319152832\n","Epoch: 1898/10000, Train Loss: 57.514699415727094, Valid Loss: 58.787349700927734\n","Epoch: 1899/10000, Train Loss: 57.35063587535512, Valid Loss: 58.7109260559082\n","Epoch: 1900/10000, Train Loss: 57.27584318681197, Valid Loss: 58.72033564249674\n","Epoch: 1901/10000, Train Loss: 57.44349323619496, Valid Loss: 58.69639205932617\n","Epoch: 1902/10000, Train Loss: 57.39467655528676, Valid Loss: 58.7112922668457\n","Epoch: 1903/10000, Train Loss: 57.491978038441054, Valid Loss: 58.70321528116862\n","Epoch: 1904/10000, Train Loss: 57.47374898737127, Valid Loss: 58.71309916178385\n","Epoch: 1905/10000, Train Loss: 57.50346409190785, Valid Loss: 58.621073404947914\n","Epoch: 1906/10000, Train Loss: 57.477257468483664, Valid Loss: 58.65768178304037\n","Epoch: 1907/10000, Train Loss: 57.5190544128418, Valid Loss: 58.6439577738444\n","Epoch: 1908/10000, Train Loss: 57.36492191661488, Valid Loss: 58.71400578816732\n","Epoch: 1909/10000, Train Loss: 57.48894188620827, Valid Loss: 58.756064097086586\n","Epoch: 1910/10000, Train Loss: 57.38372074473988, Valid Loss: 58.73228327433268\n","Epoch: 1911/10000, Train Loss: 57.36737615411932, Valid Loss: 58.84659067789713\n","Epoch: 1912/10000, Train Loss: 57.4127443486994, Valid Loss: 58.677197774251304\n","Epoch: 1913/10000, Train Loss: 57.62059575861151, Valid Loss: 58.714290618896484\n","Epoch: 1914/10000, Train Loss: 57.38117842240767, Valid Loss: 58.68299357096354\n","Epoch: 1915/10000, Train Loss: 57.389034271240234, Valid Loss: 58.65958786010742\n","Epoch: 1916/10000, Train Loss: 57.36038520119407, Valid Loss: 58.62902704874674\n","Epoch: 1917/10000, Train Loss: 57.35230567238548, Valid Loss: 58.65385182698568\n","Epoch: 1918/10000, Train Loss: 57.4099155772816, Valid Loss: 58.62603632609049\n","Epoch: 1919/10000, Train Loss: 57.25751842151988, Valid Loss: 58.63460795084635\n","Epoch: 1920/10000, Train Loss: 57.345337260853164, Valid Loss: 58.74111557006836\n","Epoch: 1921/10000, Train Loss: 57.430036371404476, Valid Loss: 58.66846593221029\n","Epoch: 1922/10000, Train Loss: 57.50481414794922, Valid Loss: 58.61610539754232\n","Epoch: 1923/10000, Train Loss: 57.41543752496893, Valid Loss: 58.504191080729164\n","Epoch: 1924/10000, Train Loss: 57.29480812766335, Valid Loss: 58.56945673624674\n","Epoch: 1925/10000, Train Loss: 57.47570384632457, Valid Loss: 58.57582346598307\n","Epoch: 1926/10000, Train Loss: 57.27833661166105, Valid Loss: 58.6411984761556\n","Epoch: 1927/10000, Train Loss: 57.26172429865057, Valid Loss: 58.6917355855306\n","Epoch: 1928/10000, Train Loss: 57.413619648326524, Valid Loss: 58.68879954020182\n","Epoch: 1929/10000, Train Loss: 57.316436073996805, Valid Loss: 58.68962605794271\n","Epoch: 1930/10000, Train Loss: 57.35286261818626, Valid Loss: 58.646933237711586\n","Epoch: 1931/10000, Train Loss: 57.3912599736994, Valid Loss: 58.68762334187826\n","Epoch: 1932/10000, Train Loss: 57.211068240079015, Valid Loss: 58.639076232910156\n","Epoch: 1933/10000, Train Loss: 57.25388509576971, Valid Loss: 58.63555018107096\n","Epoch: 1934/10000, Train Loss: 57.23162148215554, Valid Loss: 58.62071863810221\n","Epoch: 1935/10000, Train Loss: 57.158544367009945, Valid Loss: 58.545492808024086\n","Epoch: 1936/10000, Train Loss: 57.36851189353249, Valid Loss: 58.68563461303711\n","Epoch: 1937/10000, Train Loss: 57.23341300270774, Valid Loss: 58.6987190246582\n","Epoch: 1938/10000, Train Loss: 57.29498429731889, Valid Loss: 58.68681716918945\n","Epoch: 1939/10000, Train Loss: 57.3100436817516, Valid Loss: 58.512428283691406\n","Epoch: 1940/10000, Train Loss: 57.256716988303445, Valid Loss: 58.51096852620443\n","Epoch: 1941/10000, Train Loss: 57.190284035422586, Valid Loss: 58.56145985921224\n","Epoch: 1942/10000, Train Loss: 57.15774154663086, Valid Loss: 58.53642145792643\n","Epoch: 1943/10000, Train Loss: 57.15159502896395, Valid Loss: 58.57546742757162\n","Epoch: 1944/10000, Train Loss: 57.21769228848544, Valid Loss: 58.52300898234049\n","Epoch: 1945/10000, Train Loss: 57.25847140225497, Valid Loss: 58.660046895345054\n","Epoch: 1946/10000, Train Loss: 57.24334023215554, Valid Loss: 58.65761947631836\n","Epoch: 1947/10000, Train Loss: 57.22251337224787, Valid Loss: 58.62963740030924\n","Epoch: 1948/10000, Train Loss: 57.144687999378554, Valid Loss: 58.59877904256185\n","Epoch: 1949/10000, Train Loss: 57.2046723799272, Valid Loss: 58.54501978556315\n","Epoch: 1950/10000, Train Loss: 57.20298385620117, Valid Loss: 58.41028722127279\n","Epoch: 1951/10000, Train Loss: 57.15964057228782, Valid Loss: 58.56858825683594\n","Epoch: 1952/10000, Train Loss: 57.23545039783824, Valid Loss: 58.515786488850914\n","Epoch: 1953/10000, Train Loss: 57.31043035333807, Valid Loss: 58.62403106689453\n","Epoch: 1954/10000, Train Loss: 57.27230592207475, Valid Loss: 58.570491790771484\n","Epoch: 1955/10000, Train Loss: 57.220895593816586, Valid Loss: 58.4908078511556\n","Epoch: 1956/10000, Train Loss: 57.188452980735086, Valid Loss: 58.43616485595703\n","Epoch: 1957/10000, Train Loss: 57.1637736233798, Valid Loss: 58.512003580729164\n","Epoch: 1958/10000, Train Loss: 57.287017822265625, Valid Loss: 58.512481689453125\n","Epoch: 1959/10000, Train Loss: 57.020851135253906, Valid Loss: 58.485496520996094\n","Epoch: 1960/10000, Train Loss: 57.08561845259233, Valid Loss: 58.47332890828451\n","Epoch: 1961/10000, Train Loss: 57.19130672108043, Valid Loss: 58.50590896606445\n","Epoch: 1962/10000, Train Loss: 57.32238179987127, Valid Loss: 58.47446950276693\n","Epoch: 1963/10000, Train Loss: 57.09850658069957, Valid Loss: 58.48936971028646\n","Epoch: 1964/10000, Train Loss: 57.085541465065695, Valid Loss: 58.39757537841797\n","Epoch: 1965/10000, Train Loss: 57.241112448952414, Valid Loss: 58.436387379964195\n","Epoch: 1966/10000, Train Loss: 57.11665760387074, Valid Loss: 58.43856684366862\n","Epoch: 1967/10000, Train Loss: 57.140476573597304, Valid Loss: 58.409166971842446\n","Epoch: 1968/10000, Train Loss: 57.229307348077946, Valid Loss: 58.431654612223305\n","Epoch: 1969/10000, Train Loss: 57.144714008678086, Valid Loss: 58.42103576660156\n","Epoch: 1970/10000, Train Loss: 57.05504816228693, Valid Loss: 58.46959559122721\n","Epoch: 1971/10000, Train Loss: 57.00220281427557, Valid Loss: 58.46002197265625\n","Epoch: 1972/10000, Train Loss: 57.05673044378107, Valid Loss: 58.45570373535156\n","Epoch: 1973/10000, Train Loss: 57.098478143865414, Valid Loss: 58.4490966796875\n","Epoch: 1974/10000, Train Loss: 57.228331479159266, Valid Loss: 58.40530141194662\n","Epoch: 1975/10000, Train Loss: 57.09987050836737, Valid Loss: 58.37281290690104\n","Epoch: 1976/10000, Train Loss: 57.19195972789418, Valid Loss: 58.43591181437174\n","Epoch: 1977/10000, Train Loss: 57.15448899702592, Valid Loss: 58.41438674926758\n","Epoch: 1978/10000, Train Loss: 57.05037481134588, Valid Loss: 58.336160024007164\n","Epoch: 1979/10000, Train Loss: 57.07897463711825, Valid Loss: 58.329331715901695\n","Epoch: 1980/10000, Train Loss: 57.13864968039773, Valid Loss: 58.4012451171875\n","Epoch: 1981/10000, Train Loss: 57.05060958862305, Valid Loss: 58.35275141398112\n","Epoch: 1982/10000, Train Loss: 57.06929258866744, Valid Loss: 58.42258071899414\n","Epoch: 1983/10000, Train Loss: 57.06894891912287, Valid Loss: 58.41830062866211\n","Epoch: 1984/10000, Train Loss: 57.08293151855469, Valid Loss: 58.414511362711586\n","Epoch: 1985/10000, Train Loss: 56.92753080888228, Valid Loss: 58.33746592203776\n","Epoch: 1986/10000, Train Loss: 57.02019362016158, Valid Loss: 58.388894399007164\n","Epoch: 1987/10000, Train Loss: 56.941588315096766, Valid Loss: 58.40671412150065\n","Epoch: 1988/10000, Train Loss: 56.98131665316495, Valid Loss: 58.34873580932617\n","Epoch: 1989/10000, Train Loss: 56.87205956198952, Valid Loss: 58.292799631754555\n","Epoch: 1990/10000, Train Loss: 56.97188741510565, Valid Loss: 58.42588678995768\n","Epoch: 1991/10000, Train Loss: 57.064762809059836, Valid Loss: 58.28515497843424\n","Epoch: 1992/10000, Train Loss: 56.980011679909445, Valid Loss: 58.289971669514976\n","Epoch: 1993/10000, Train Loss: 57.01482946222479, Valid Loss: 58.39889144897461\n","Epoch: 1994/10000, Train Loss: 57.23378718983043, Valid Loss: 58.4062868754069\n","Epoch: 1995/10000, Train Loss: 56.87200927734375, Valid Loss: 58.28390248616537\n","Epoch: 1996/10000, Train Loss: 56.96036286787553, Valid Loss: 58.321282704671226\n","Epoch: 1997/10000, Train Loss: 56.94438622214577, Valid Loss: 58.373549143473305\n","Epoch: 1998/10000, Train Loss: 57.01889939741655, Valid Loss: 58.3023935953776\n","Epoch: 1999/10000, Train Loss: 56.88551712036133, Valid Loss: 58.32000605265299\n","Epoch: 2000/10000, Train Loss: 56.955209558660336, Valid Loss: 58.346808115641274\n","Epoch: 2001/10000, Train Loss: 57.02277374267578, Valid Loss: 58.289605458577476\n","Epoch: 2002/10000, Train Loss: 56.86232063987038, Valid Loss: 58.28387578328451\n","Epoch: 2003/10000, Train Loss: 56.84823365644975, Valid Loss: 58.29022216796875\n","Epoch: 2004/10000, Train Loss: 56.90008406205611, Valid Loss: 58.32077153523763\n","Epoch: 2005/10000, Train Loss: 57.007563851096414, Valid Loss: 58.293643951416016\n","Epoch: 2006/10000, Train Loss: 57.032191189852625, Valid Loss: 58.28226216634115\n","Epoch: 2007/10000, Train Loss: 57.00368915904652, Valid Loss: 58.30907185872396\n","Epoch: 2008/10000, Train Loss: 56.9752197265625, Valid Loss: 58.346537272135414\n","Epoch: 2009/10000, Train Loss: 56.92068308049982, Valid Loss: 58.30320739746094\n","Epoch: 2010/10000, Train Loss: 56.8502162586559, Valid Loss: 58.178507486979164\n","Epoch: 2011/10000, Train Loss: 56.99761373346502, Valid Loss: 58.23509089152018\n","Epoch: 2012/10000, Train Loss: 56.91086335615678, Valid Loss: 58.21223449707031\n","Epoch: 2013/10000, Train Loss: 56.97023079612038, Valid Loss: 58.27164204915365\n","Epoch: 2014/10000, Train Loss: 56.89272273670543, Valid Loss: 58.321537017822266\n","Epoch: 2015/10000, Train Loss: 56.77180099487305, Valid Loss: 58.261122385660805\n","Epoch: 2016/10000, Train Loss: 56.85901156338778, Valid Loss: 58.35419209798177\n","Epoch: 2017/10000, Train Loss: 56.946692033247515, Valid Loss: 58.27129872639974\n","Epoch: 2018/10000, Train Loss: 56.998802185058594, Valid Loss: 58.25309499104818\n","Epoch: 2019/10000, Train Loss: 56.79375319047408, Valid Loss: 58.32496643066406\n","Epoch: 2020/10000, Train Loss: 56.87072684548118, Valid Loss: 58.222215016682945\n","Epoch: 2021/10000, Train Loss: 56.75796196677468, Valid Loss: 58.2984364827474\n","Epoch: 2022/10000, Train Loss: 56.70975320989435, Valid Loss: 58.24118677775065\n","Epoch: 2023/10000, Train Loss: 56.76403323086825, Valid Loss: 58.256046295166016\n","Epoch: 2024/10000, Train Loss: 56.76353627985174, Valid Loss: 58.1793212890625\n","Epoch: 2025/10000, Train Loss: 56.78809842196378, Valid Loss: 58.25847244262695\n","Epoch: 2026/10000, Train Loss: 56.6573652787642, Valid Loss: 58.23330434163412\n","Epoch: 2027/10000, Train Loss: 56.68407544222745, Valid Loss: 58.197802225748696\n","Epoch: 2028/10000, Train Loss: 56.816739862615414, Valid Loss: 58.18768183390299\n","Epoch: 2029/10000, Train Loss: 56.7123856977983, Valid Loss: 58.29230499267578\n","Epoch: 2030/10000, Train Loss: 56.65408013083718, Valid Loss: 58.255236307779946\n","Epoch: 2031/10000, Train Loss: 56.77721509066495, Valid Loss: 58.22512563069662\n","Epoch: 2032/10000, Train Loss: 56.59562197598544, Valid Loss: 58.284559885660805\n","Epoch: 2033/10000, Train Loss: 56.90552520751953, Valid Loss: 58.274157206217446\n","Epoch: 2034/10000, Train Loss: 56.89780460704457, Valid Loss: 58.247519175211586\n","Epoch: 2035/10000, Train Loss: 56.672327215021305, Valid Loss: 58.244832356770836\n","Epoch: 2036/10000, Train Loss: 56.75443233143199, Valid Loss: 58.19655227661133\n","Epoch: 2037/10000, Train Loss: 56.474163402210586, Valid Loss: 58.108646392822266\n","Epoch: 2038/10000, Train Loss: 56.80098342895508, Valid Loss: 58.122083028157554\n","Epoch: 2039/10000, Train Loss: 56.69624224576083, Valid Loss: 58.270617167154946\n","Epoch: 2040/10000, Train Loss: 56.671442552046344, Valid Loss: 58.249794006347656\n","Epoch: 2041/10000, Train Loss: 56.798504916104406, Valid Loss: 58.167144775390625\n","Epoch: 2042/10000, Train Loss: 56.773564772172406, Valid Loss: 58.1268679300944\n","Epoch: 2043/10000, Train Loss: 56.62787073308771, Valid Loss: 58.11925506591797\n","Epoch: 2044/10000, Train Loss: 56.60931465842507, Valid Loss: 58.10839970906576\n","Epoch: 2045/10000, Train Loss: 56.74076115001332, Valid Loss: 58.13909784952799\n","Epoch: 2046/10000, Train Loss: 56.687536066228695, Valid Loss: 58.14686075846354\n","Epoch: 2047/10000, Train Loss: 56.78265935724432, Valid Loss: 58.06096903483073\n","Epoch: 2048/10000, Train Loss: 56.71936659379439, Valid Loss: 58.07522964477539\n","Epoch: 2049/10000, Train Loss: 56.61653934825551, Valid Loss: 58.09292984008789\n","Epoch: 2050/10000, Train Loss: 56.7182651866566, Valid Loss: 58.186834971110024\n","Epoch: 2051/10000, Train Loss: 56.71303211558949, Valid Loss: 58.08725229899088\n","Epoch: 2052/10000, Train Loss: 56.62451657381925, Valid Loss: 58.030312856038414\n","Epoch: 2053/10000, Train Loss: 56.640076030384414, Valid Loss: 58.141764322916664\n","Epoch: 2054/10000, Train Loss: 56.59260559082031, Valid Loss: 58.066766103108726\n","Epoch: 2055/10000, Train Loss: 56.77775330977006, Valid Loss: 58.08698399861654\n","Epoch: 2056/10000, Train Loss: 56.72404792092063, Valid Loss: 58.071390787760414\n","Epoch: 2057/10000, Train Loss: 56.7427451393821, Valid Loss: 58.08604049682617\n","Epoch: 2058/10000, Train Loss: 56.58021302656694, Valid Loss: 58.08717346191406\n","Epoch: 2059/10000, Train Loss: 56.5014103976163, Valid Loss: 58.084067026774086\n","Epoch: 2060/10000, Train Loss: 56.62221145629883, Valid Loss: 58.069016774495445\n","Epoch: 2061/10000, Train Loss: 56.46196087923917, Valid Loss: 58.06670125325521\n","Epoch: 2062/10000, Train Loss: 56.58900208906694, Valid Loss: 58.089125315348305\n","Epoch: 2063/10000, Train Loss: 56.54357077858665, Valid Loss: 58.04721323649088\n","Epoch: 2064/10000, Train Loss: 56.49911048195579, Valid Loss: 57.97286732991537\n","Epoch: 2065/10000, Train Loss: 56.669471740722656, Valid Loss: 58.08948262532552\n","Epoch: 2066/10000, Train Loss: 56.555515636097304, Valid Loss: 58.05102030436198\n","Epoch: 2067/10000, Train Loss: 56.58635919744318, Valid Loss: 57.99333699544271\n","Epoch: 2068/10000, Train Loss: 56.6357536315918, Valid Loss: 58.05490493774414\n","Epoch: 2069/10000, Train Loss: 56.60723148692738, Valid Loss: 58.02630360921224\n","Epoch: 2070/10000, Train Loss: 56.593181956898086, Valid Loss: 58.11375172932943\n","Epoch: 2071/10000, Train Loss: 56.65004591508345, Valid Loss: 57.92514165242513\n","Epoch: 2072/10000, Train Loss: 56.62898982654918, Valid Loss: 57.92647806803385\n","Epoch: 2073/10000, Train Loss: 56.46666752208363, Valid Loss: 57.995470682779946\n","Epoch: 2074/10000, Train Loss: 56.50840239091353, Valid Loss: 58.001121520996094\n","Epoch: 2075/10000, Train Loss: 56.55302775989879, Valid Loss: 57.958550771077476\n","Epoch: 2076/10000, Train Loss: 56.47661729292436, Valid Loss: 57.92297108968099\n","Epoch: 2077/10000, Train Loss: 56.56619782881303, Valid Loss: 57.86310323079427\n","Epoch: 2078/10000, Train Loss: 56.58983750776811, Valid Loss: 57.86182149251302\n","Epoch: 2079/10000, Train Loss: 56.47728833285245, Valid Loss: 57.847076416015625\n","Epoch: 2080/10000, Train Loss: 56.48271352594549, Valid Loss: 57.98106384277344\n","Epoch: 2081/10000, Train Loss: 56.492929978804156, Valid Loss: 57.915489196777344\n","Epoch: 2082/10000, Train Loss: 56.51972059770064, Valid Loss: 57.94998041788737\n","Epoch: 2083/10000, Train Loss: 56.370380054820664, Valid Loss: 57.9613405863444\n","Epoch: 2084/10000, Train Loss: 56.40147642655806, Valid Loss: 57.84936650594076\n","Epoch: 2085/10000, Train Loss: 56.3986271944913, Valid Loss: 57.887438456217446\n","Epoch: 2086/10000, Train Loss: 56.486023989590734, Valid Loss: 57.92703755696615\n","Epoch: 2087/10000, Train Loss: 56.40630028464577, Valid Loss: 57.92414220174154\n","Epoch: 2088/10000, Train Loss: 56.42817757346413, Valid Loss: 57.912298838297524\n","Epoch: 2089/10000, Train Loss: 56.56556458906694, Valid Loss: 57.901485443115234\n","Epoch: 2090/10000, Train Loss: 56.48657365278764, Valid Loss: 57.85005315144857\n","Epoch: 2091/10000, Train Loss: 56.33949453180487, Valid Loss: 57.86697006225586\n","Epoch: 2092/10000, Train Loss: 56.39745053378019, Valid Loss: 58.053819020589195\n","Epoch: 2093/10000, Train Loss: 56.41552456942472, Valid Loss: 57.818468729654946\n","Epoch: 2094/10000, Train Loss: 56.322898864746094, Valid Loss: 57.83427429199219\n","Epoch: 2095/10000, Train Loss: 56.40743429010565, Valid Loss: 57.90045038859049\n","Epoch: 2096/10000, Train Loss: 56.45340347290039, Valid Loss: 57.87291717529297\n","Epoch: 2097/10000, Train Loss: 56.60765387795188, Valid Loss: 57.86304219563802\n","Epoch: 2098/10000, Train Loss: 56.248569835316054, Valid Loss: 57.905267079671226\n","Epoch: 2099/10000, Train Loss: 56.63660500266335, Valid Loss: 57.85058085123698\n","Epoch: 2100/10000, Train Loss: 56.49785232543945, Valid Loss: 57.82526143391927\n","Epoch: 2101/10000, Train Loss: 56.374013380570844, Valid Loss: 57.87023798624674\n","Epoch: 2102/10000, Train Loss: 56.409415158358485, Valid Loss: 57.8104362487793\n","Epoch: 2103/10000, Train Loss: 56.65420254794034, Valid Loss: 57.81100082397461\n","Epoch: 2104/10000, Train Loss: 56.40725361217152, Valid Loss: 57.870435078938804\n","Epoch: 2105/10000, Train Loss: 56.34584634954279, Valid Loss: 57.889783223470054\n","Epoch: 2106/10000, Train Loss: 56.28707226839933, Valid Loss: 57.778387705485024\n","Epoch: 2107/10000, Train Loss: 56.44435535777699, Valid Loss: 57.67529805501302\n","Epoch: 2108/10000, Train Loss: 56.41994510997426, Valid Loss: 57.76410929361979\n","Epoch: 2109/10000, Train Loss: 56.43281208385121, Valid Loss: 57.72693634033203\n","Epoch: 2110/10000, Train Loss: 56.29718607122248, Valid Loss: 57.77861022949219\n","Epoch: 2111/10000, Train Loss: 56.21271792325106, Valid Loss: 57.79235585530599\n","Epoch: 2112/10000, Train Loss: 56.3833042491566, Valid Loss: 57.68989817301432\n","Epoch: 2113/10000, Train Loss: 56.46678439053622, Valid Loss: 57.73688888549805\n","Epoch: 2114/10000, Train Loss: 56.30388710715554, Valid Loss: 57.88548787434896\n","Epoch: 2115/10000, Train Loss: 56.30808015303178, Valid Loss: 57.8616689046224\n","Epoch: 2116/10000, Train Loss: 56.296172402121805, Valid Loss: 57.77914047241211\n","Epoch: 2117/10000, Train Loss: 56.29210524125533, Valid Loss: 57.75225575764974\n","Epoch: 2118/10000, Train Loss: 56.281692851673476, Valid Loss: 57.767660776774086\n","Epoch: 2119/10000, Train Loss: 56.24335132945668, Valid Loss: 57.8070068359375\n","Epoch: 2120/10000, Train Loss: 56.33542043512518, Valid Loss: 57.80287551879883\n","Epoch: 2121/10000, Train Loss: 56.23067578402433, Valid Loss: 57.71807734171549\n","Epoch: 2122/10000, Train Loss: 56.20781222256747, Valid Loss: 57.797662099202476\n","Epoch: 2123/10000, Train Loss: 56.15478931773793, Valid Loss: 57.782005310058594\n","Epoch: 2124/10000, Train Loss: 56.191999262029476, Valid Loss: 57.80459340413412\n","Epoch: 2125/10000, Train Loss: 56.30986473777077, Valid Loss: 57.81796391805013\n","Epoch: 2126/10000, Train Loss: 56.10928032614968, Valid Loss: 57.70164362589518\n","Epoch: 2127/10000, Train Loss: 56.21576274525035, Valid Loss: 57.66948445638021\n","Epoch: 2128/10000, Train Loss: 56.12951868230646, Valid Loss: 57.70863469441732\n","Epoch: 2129/10000, Train Loss: 56.282696810635656, Valid Loss: 57.68607076009115\n","Epoch: 2130/10000, Train Loss: 56.36513831398704, Valid Loss: 57.694461822509766\n","Epoch: 2131/10000, Train Loss: 56.2853889465332, Valid Loss: 57.75367991129557\n","Epoch: 2132/10000, Train Loss: 56.266929626464844, Valid Loss: 57.66531499226888\n","Epoch: 2133/10000, Train Loss: 56.203149275346235, Valid Loss: 57.70662053426107\n","Epoch: 2134/10000, Train Loss: 56.151213212446734, Valid Loss: 57.80595779418945\n","Epoch: 2135/10000, Train Loss: 56.10452097112482, Valid Loss: 57.6749521891276\n","Epoch: 2136/10000, Train Loss: 56.23247736150568, Valid Loss: 57.633131663004555\n","Epoch: 2137/10000, Train Loss: 56.0785886591131, Valid Loss: 57.67244211832682\n","Epoch: 2138/10000, Train Loss: 56.33883701671254, Valid Loss: 57.653099060058594\n","Epoch: 2139/10000, Train Loss: 56.23146611993963, Valid Loss: 57.69418080647787\n","Epoch: 2140/10000, Train Loss: 56.185222972523086, Valid Loss: 57.70095443725586\n","Epoch: 2141/10000, Train Loss: 56.062231584028765, Valid Loss: 57.668408711751304\n","Epoch: 2142/10000, Train Loss: 56.244875474409625, Valid Loss: 57.62290064493815\n","Epoch: 2143/10000, Train Loss: 56.21025848388672, Valid Loss: 57.57982889811198\n","Epoch: 2144/10000, Train Loss: 56.0988918651234, Valid Loss: 57.688280741373696\n","Epoch: 2145/10000, Train Loss: 56.14874545010653, Valid Loss: 57.748887379964195\n","Epoch: 2146/10000, Train Loss: 56.20930446277965, Valid Loss: 57.59701665242513\n","Epoch: 2147/10000, Train Loss: 56.17552670565519, Valid Loss: 57.6006228129069\n","Epoch: 2148/10000, Train Loss: 56.19075150923295, Valid Loss: 57.634560902913414\n","Epoch: 2149/10000, Train Loss: 56.26493245905096, Valid Loss: 57.520284016927086\n","Epoch: 2150/10000, Train Loss: 56.24229119040749, Valid Loss: 57.6286506652832\n","Epoch: 2151/10000, Train Loss: 56.09580612182617, Valid Loss: 57.53695551554362\n","Epoch: 2152/10000, Train Loss: 56.232146523215555, Valid Loss: 57.70030848185221\n","Epoch: 2153/10000, Train Loss: 56.17628583041105, Valid Loss: 57.65737533569336\n","Epoch: 2154/10000, Train Loss: 56.31303648515181, Valid Loss: 57.5857785542806\n","Epoch: 2155/10000, Train Loss: 56.003842787309125, Valid Loss: 57.555948893229164\n","Epoch: 2156/10000, Train Loss: 56.20319713245738, Valid Loss: 57.588175455729164\n","Epoch: 2157/10000, Train Loss: 56.15546729347923, Valid Loss: 57.601304372151695\n","Epoch: 2158/10000, Train Loss: 56.23666728626598, Valid Loss: 57.68824005126953\n","Epoch: 2159/10000, Train Loss: 56.092677029696375, Valid Loss: 57.644694010416664\n","Epoch: 2160/10000, Train Loss: 56.05559088967063, Valid Loss: 57.68358866373698\n","Epoch: 2161/10000, Train Loss: 55.964242761785336, Valid Loss: 57.55790583292643\n","Epoch: 2162/10000, Train Loss: 56.12211678244851, Valid Loss: 57.52759552001953\n","Epoch: 2163/10000, Train Loss: 56.09502098777077, Valid Loss: 57.609185536702476\n","Epoch: 2164/10000, Train Loss: 55.95768599076705, Valid Loss: 57.56875228881836\n","Epoch: 2165/10000, Train Loss: 56.04696967385032, Valid Loss: 57.49762217203776\n","Epoch: 2166/10000, Train Loss: 55.97220438176935, Valid Loss: 57.56516647338867\n","Epoch: 2167/10000, Train Loss: 55.960297324440695, Valid Loss: 57.55769475301107\n","Epoch: 2168/10000, Train Loss: 56.014047449285336, Valid Loss: 57.52962748209635\n","Epoch: 2169/10000, Train Loss: 56.12314952503551, Valid Loss: 57.44465637207031\n","Epoch: 2170/10000, Train Loss: 56.031436920166016, Valid Loss: 57.551841735839844\n","Epoch: 2171/10000, Train Loss: 56.00948923284357, Valid Loss: 57.61782582600912\n","Epoch: 2172/10000, Train Loss: 56.01963875510476, Valid Loss: 57.57304763793945\n","Epoch: 2173/10000, Train Loss: 56.0438100641424, Valid Loss: 57.48910903930664\n","Epoch: 2174/10000, Train Loss: 56.07476598566229, Valid Loss: 57.45188649495443\n","Epoch: 2175/10000, Train Loss: 55.75414137406783, Valid Loss: 57.424163818359375\n","Epoch: 2176/10000, Train Loss: 55.8403469432484, Valid Loss: 57.47990290323893\n","Epoch: 2177/10000, Train Loss: 56.056093736128375, Valid Loss: 57.56069310506185\n","Epoch: 2178/10000, Train Loss: 55.801332993940875, Valid Loss: 57.4798952738444\n","Epoch: 2179/10000, Train Loss: 55.97705078125, Valid Loss: 57.48283767700195\n","Epoch: 2180/10000, Train Loss: 55.985855449329726, Valid Loss: 57.50568135579427\n","Epoch: 2181/10000, Train Loss: 56.087838259610265, Valid Loss: 57.496649424235024\n","Epoch: 2182/10000, Train Loss: 56.01957147771662, Valid Loss: 57.50384775797526\n","Epoch: 2183/10000, Train Loss: 56.1764162236994, Valid Loss: 57.45942687988281\n","Epoch: 2184/10000, Train Loss: 55.97189157659357, Valid Loss: 57.4112803141276\n","Epoch: 2185/10000, Train Loss: 55.98338421908292, Valid Loss: 57.41081746419271\n","Epoch: 2186/10000, Train Loss: 56.01379186456854, Valid Loss: 57.469305674235024\n","Epoch: 2187/10000, Train Loss: 55.91526482321999, Valid Loss: 57.46627934773763\n","Epoch: 2188/10000, Train Loss: 55.974355177445844, Valid Loss: 57.49109013875326\n","Epoch: 2189/10000, Train Loss: 55.870629744096235, Valid Loss: 57.421094258626304\n","Epoch: 2190/10000, Train Loss: 55.946128845214844, Valid Loss: 57.45029830932617\n","Epoch: 2191/10000, Train Loss: 56.05325213345614, Valid Loss: 57.45003128051758\n","Epoch: 2192/10000, Train Loss: 56.01258607344194, Valid Loss: 57.41839599609375\n","Epoch: 2193/10000, Train Loss: 55.778011322021484, Valid Loss: 57.36242421468099\n","Epoch: 2194/10000, Train Loss: 55.78794791481712, Valid Loss: 57.41741816202799\n","Epoch: 2195/10000, Train Loss: 55.96859082308683, Valid Loss: 57.515743255615234\n","Epoch: 2196/10000, Train Loss: 55.95378459583629, Valid Loss: 57.43981679280599\n","Epoch: 2197/10000, Train Loss: 55.976933219216086, Valid Loss: 57.439170837402344\n","Epoch: 2198/10000, Train Loss: 55.88359520652077, Valid Loss: 57.381083170572914\n","Epoch: 2199/10000, Train Loss: 55.84109115600586, Valid Loss: 57.4008674621582\n","Epoch: 2200/10000, Train Loss: 55.8185587796298, Valid Loss: 57.36478932698568\n","Epoch: 2201/10000, Train Loss: 55.83604986017401, Valid Loss: 57.40463638305664\n","Epoch: 2202/10000, Train Loss: 55.91496831720526, Valid Loss: 57.47831344604492\n","Epoch: 2203/10000, Train Loss: 55.716492739590734, Valid Loss: 57.45895767211914\n","Epoch: 2204/10000, Train Loss: 55.974796988747336, Valid Loss: 57.35952504475912\n","Epoch: 2205/10000, Train Loss: 55.79566192626953, Valid Loss: 57.27953211466471\n","Epoch: 2206/10000, Train Loss: 55.816898345947266, Valid Loss: 57.257546742757164\n","Epoch: 2207/10000, Train Loss: 55.55419783158736, Valid Loss: 57.297986348470054\n","Epoch: 2208/10000, Train Loss: 55.65269054066051, Valid Loss: 57.35119120279948\n","Epoch: 2209/10000, Train Loss: 55.74857503717596, Valid Loss: 57.35026168823242\n","Epoch: 2210/10000, Train Loss: 55.69270740855824, Valid Loss: 57.29540125528971\n","Epoch: 2211/10000, Train Loss: 55.754229458895594, Valid Loss: 57.369589487711586\n","Epoch: 2212/10000, Train Loss: 55.66196580366655, Valid Loss: 57.28482564290365\n","Epoch: 2213/10000, Train Loss: 55.988786870783024, Valid Loss: 57.273520151774086\n","Epoch: 2214/10000, Train Loss: 55.70723967118697, Valid Loss: 57.323883056640625\n","Epoch: 2215/10000, Train Loss: 55.892450852827594, Valid Loss: 57.252340952555336\n","Epoch: 2216/10000, Train Loss: 55.994732249866836, Valid Loss: 57.24096171061198\n","Epoch: 2217/10000, Train Loss: 55.77929618141868, Valid Loss: 57.242627461751304\n","Epoch: 2218/10000, Train Loss: 55.83915328979492, Valid Loss: 57.210931142171226\n","Epoch: 2219/10000, Train Loss: 55.64799499511719, Valid Loss: 57.33518854777018\n","Epoch: 2220/10000, Train Loss: 55.72691900079901, Valid Loss: 57.20136642456055\n","Epoch: 2221/10000, Train Loss: 55.76413414695046, Valid Loss: 57.295693715413414\n","Epoch: 2222/10000, Train Loss: 55.851658214222304, Valid Loss: 57.33380635579427\n","Epoch: 2223/10000, Train Loss: 55.660713542591445, Valid Loss: 57.222798665364586\n","Epoch: 2224/10000, Train Loss: 55.64054489135742, Valid Loss: 57.23375701904297\n","Epoch: 2225/10000, Train Loss: 55.57209743152965, Valid Loss: 57.256142934163414\n","Epoch: 2226/10000, Train Loss: 55.697152918035336, Valid Loss: 57.368584950764976\n","Epoch: 2227/10000, Train Loss: 55.581242994828656, Valid Loss: 57.236708323160805\n","Epoch: 2228/10000, Train Loss: 55.85302040793679, Valid Loss: 57.37943903605143\n","Epoch: 2229/10000, Train Loss: 55.58133246681907, Valid Loss: 57.18822987874349\n","Epoch: 2230/10000, Train Loss: 55.52896014126864, Valid Loss: 57.227437337239586\n","Epoch: 2231/10000, Train Loss: 55.51113579489968, Valid Loss: 57.36480840047201\n","Epoch: 2232/10000, Train Loss: 55.785477031360976, Valid Loss: 57.17546590169271\n","Epoch: 2233/10000, Train Loss: 55.68317621404474, Valid Loss: 57.1897341410319\n","Epoch: 2234/10000, Train Loss: 55.70128666270863, Valid Loss: 57.25076548258463\n","Epoch: 2235/10000, Train Loss: 55.592076388272375, Valid Loss: 57.15399932861328\n","Epoch: 2236/10000, Train Loss: 55.79414159601385, Valid Loss: 57.288519541422524\n","Epoch: 2237/10000, Train Loss: 55.690861788663, Valid Loss: 57.35601933797201\n","Epoch: 2238/10000, Train Loss: 55.54044931585138, Valid Loss: 57.184791564941406\n","Epoch: 2239/10000, Train Loss: 55.670725388960406, Valid Loss: 57.15788777669271\n","Epoch: 2240/10000, Train Loss: 55.555001345547765, Valid Loss: 57.280967712402344\n","Epoch: 2241/10000, Train Loss: 55.60215759277344, Valid Loss: 57.22341664632162\n","Epoch: 2242/10000, Train Loss: 55.7851527820934, Valid Loss: 57.17337544759115\n","Epoch: 2243/10000, Train Loss: 55.649443886496805, Valid Loss: 57.19901021321615\n","Epoch: 2244/10000, Train Loss: 55.520715193314985, Valid Loss: 57.135009765625\n","Epoch: 2245/10000, Train Loss: 55.57996645840731, Valid Loss: 57.18768819173177\n","Epoch: 2246/10000, Train Loss: 55.59336783669212, Valid Loss: 57.15629196166992\n","Epoch: 2247/10000, Train Loss: 55.69644754583185, Valid Loss: 57.19928868611654\n","Epoch: 2248/10000, Train Loss: 55.546186273748226, Valid Loss: 57.14202626546224\n","Epoch: 2249/10000, Train Loss: 55.662084406072445, Valid Loss: 57.083360036214195\n","Epoch: 2250/10000, Train Loss: 55.67583014748313, Valid Loss: 57.08258056640625\n","Epoch: 2251/10000, Train Loss: 55.58241029219194, Valid Loss: 57.232916514078774\n","Epoch: 2252/10000, Train Loss: 55.761144464666195, Valid Loss: 57.16926193237305\n","Epoch: 2253/10000, Train Loss: 55.456235365434125, Valid Loss: 57.197391510009766\n","Epoch: 2254/10000, Train Loss: 55.5248742537065, Valid Loss: 57.13650767008463\n","Epoch: 2255/10000, Train Loss: 55.59410095214844, Valid Loss: 57.13885498046875\n","Epoch: 2256/10000, Train Loss: 55.69716609608043, Valid Loss: 57.050313313802086\n","Epoch: 2257/10000, Train Loss: 55.528229453346945, Valid Loss: 57.04306157430013\n","Epoch: 2258/10000, Train Loss: 55.28800790960138, Valid Loss: 57.11583964029948\n","Epoch: 2259/10000, Train Loss: 55.507613788951524, Valid Loss: 57.19510142008463\n","Epoch: 2260/10000, Train Loss: 55.529592687433414, Valid Loss: 57.118815104166664\n","Epoch: 2261/10000, Train Loss: 55.58470396562056, Valid Loss: 57.110913594563804\n","Epoch: 2262/10000, Train Loss: 55.39162132956765, Valid Loss: 57.06208038330078\n","Epoch: 2263/10000, Train Loss: 55.464599956165664, Valid Loss: 57.1274299621582\n","Epoch: 2264/10000, Train Loss: 55.53200253573331, Valid Loss: 57.0723622639974\n","Epoch: 2265/10000, Train Loss: 55.427305394952946, Valid Loss: 56.99001439412435\n","Epoch: 2266/10000, Train Loss: 55.51802721890536, Valid Loss: 56.97936884562174\n","Epoch: 2267/10000, Train Loss: 55.4877534346147, Valid Loss: 56.96209589640299\n","Epoch: 2268/10000, Train Loss: 55.62305311723189, Valid Loss: 57.01700210571289\n","Epoch: 2269/10000, Train Loss: 55.5121262290261, Valid Loss: 57.053473154703774\n","Epoch: 2270/10000, Train Loss: 55.2615422335538, Valid Loss: 57.096771240234375\n","Epoch: 2271/10000, Train Loss: 55.492609544233844, Valid Loss: 56.940738677978516\n","Epoch: 2272/10000, Train Loss: 55.19805838844993, Valid Loss: 56.99607467651367\n","Epoch: 2273/10000, Train Loss: 55.35520761663263, Valid Loss: 57.069889068603516\n","Epoch: 2274/10000, Train Loss: 55.50065092606978, Valid Loss: 56.98497009277344\n","Epoch: 2275/10000, Train Loss: 55.3543139371005, Valid Loss: 57.00098419189453\n","Epoch: 2276/10000, Train Loss: 55.54254011674361, Valid Loss: 57.00666300455729\n","Epoch: 2277/10000, Train Loss: 55.31833683360707, Valid Loss: 57.03719965616862\n","Epoch: 2278/10000, Train Loss: 55.29759909889915, Valid Loss: 56.94221750895182\n","Epoch: 2279/10000, Train Loss: 55.408829082142226, Valid Loss: 57.09710566202799\n","Epoch: 2280/10000, Train Loss: 55.42551179365678, Valid Loss: 57.01327006022135\n","Epoch: 2281/10000, Train Loss: 55.55170232599432, Valid Loss: 57.05989456176758\n","Epoch: 2282/10000, Train Loss: 55.48575834794478, Valid Loss: 56.92504628499349\n","Epoch: 2283/10000, Train Loss: 55.34232087568803, Valid Loss: 56.8680419921875\n","Epoch: 2284/10000, Train Loss: 55.435306549072266, Valid Loss: 56.91130701700846\n","Epoch: 2285/10000, Train Loss: 55.25813674926758, Valid Loss: 56.95113754272461\n","Epoch: 2286/10000, Train Loss: 55.4766994823109, Valid Loss: 56.940104166666664\n","Epoch: 2287/10000, Train Loss: 55.43747884576971, Valid Loss: 56.88487116495768\n","Epoch: 2288/10000, Train Loss: 55.230530825528234, Valid Loss: 56.838661193847656\n","Epoch: 2289/10000, Train Loss: 55.45790585604581, Valid Loss: 56.857643127441406\n","Epoch: 2290/10000, Train Loss: 55.26939565485174, Valid Loss: 56.95705922444662\n","Epoch: 2291/10000, Train Loss: 55.294756109064274, Valid Loss: 57.04375457763672\n","Epoch: 2292/10000, Train Loss: 55.388506802645594, Valid Loss: 56.905321756998696\n","Epoch: 2293/10000, Train Loss: 55.415013399991125, Valid Loss: 57.02118428548177\n","Epoch: 2294/10000, Train Loss: 55.36958971890536, Valid Loss: 56.90468978881836\n","Epoch: 2295/10000, Train Loss: 55.19875058260831, Valid Loss: 56.99382654825846\n","Epoch: 2296/10000, Train Loss: 55.28461872447621, Valid Loss: 56.93092600504557\n","Epoch: 2297/10000, Train Loss: 55.327274322509766, Valid Loss: 56.930091857910156\n","Epoch: 2298/10000, Train Loss: 55.36086099798029, Valid Loss: 56.908555348714195\n","Epoch: 2299/10000, Train Loss: 55.36274372447621, Valid Loss: 56.86769485473633\n","Epoch: 2300/10000, Train Loss: 55.428441134366125, Valid Loss: 56.76234563191732\n","Epoch: 2301/10000, Train Loss: 55.26934259588068, Valid Loss: 56.87351608276367\n","Epoch: 2302/10000, Train Loss: 55.452727577903055, Valid Loss: 56.90834172566732\n","Epoch: 2303/10000, Train Loss: 55.263343117453836, Valid Loss: 56.80450185139974\n","Epoch: 2304/10000, Train Loss: 55.2072077664462, Valid Loss: 56.87937927246094\n","Epoch: 2305/10000, Train Loss: 55.179785294966265, Valid Loss: 56.89159647623698\n","Epoch: 2306/10000, Train Loss: 55.08643999966708, Valid Loss: 56.80291875203451\n","Epoch: 2307/10000, Train Loss: 55.297223871404476, Valid Loss: 56.782958984375\n","Epoch: 2308/10000, Train Loss: 55.18345919522372, Valid Loss: 56.667990366617836\n","Epoch: 2309/10000, Train Loss: 55.2713623046875, Valid Loss: 56.713958740234375\n","Epoch: 2310/10000, Train Loss: 55.13239773837003, Valid Loss: 56.80404281616211\n","Epoch: 2311/10000, Train Loss: 55.279535813765094, Valid Loss: 56.84101231892904\n","Epoch: 2312/10000, Train Loss: 55.396991382945664, Valid Loss: 56.841898600260414\n","Epoch: 2313/10000, Train Loss: 55.32142327048562, Valid Loss: 56.84648640950521\n","Epoch: 2314/10000, Train Loss: 55.06888406926935, Valid Loss: 56.874219258626304\n","Epoch: 2315/10000, Train Loss: 55.17613983154297, Valid Loss: 56.78568649291992\n","Epoch: 2316/10000, Train Loss: 55.21792429143732, Valid Loss: 56.813313802083336\n","Epoch: 2317/10000, Train Loss: 55.07424025102095, Valid Loss: 56.75566736857096\n","Epoch: 2318/10000, Train Loss: 55.21623403375799, Valid Loss: 56.68336868286133\n","Epoch: 2319/10000, Train Loss: 55.31791097467596, Valid Loss: 56.75798797607422\n","Epoch: 2320/10000, Train Loss: 55.25655850497159, Valid Loss: 56.887533823649086\n","Epoch: 2321/10000, Train Loss: 55.29816956953569, Valid Loss: 56.75076675415039\n","Epoch: 2322/10000, Train Loss: 55.10206846757369, Valid Loss: 56.611541748046875\n","Epoch: 2323/10000, Train Loss: 54.98085438121449, Valid Loss: 56.67645263671875\n","Epoch: 2324/10000, Train Loss: 55.00713695179332, Valid Loss: 56.691935221354164\n","Epoch: 2325/10000, Train Loss: 55.224191492254086, Valid Loss: 56.697689056396484\n","Epoch: 2326/10000, Train Loss: 55.27147847955877, Valid Loss: 56.62876637776693\n","Epoch: 2327/10000, Train Loss: 55.027099262584336, Valid Loss: 56.77777099609375\n","Epoch: 2328/10000, Train Loss: 55.0737849148837, Valid Loss: 56.77474721272787\n","Epoch: 2329/10000, Train Loss: 55.343767339533024, Valid Loss: 56.785760243733726\n","Epoch: 2330/10000, Train Loss: 55.25870028409091, Valid Loss: 56.738259633382164\n","Epoch: 2331/10000, Train Loss: 54.875880154696375, Valid Loss: 56.70602544148763\n","Epoch: 2332/10000, Train Loss: 55.07670836015181, Valid Loss: 56.722494761149086\n","Epoch: 2333/10000, Train Loss: 55.057688279585406, Valid Loss: 56.637274424235024\n","Epoch: 2334/10000, Train Loss: 54.977207530628554, Valid Loss: 56.613040924072266\n","Epoch: 2335/10000, Train Loss: 54.88469071821733, Valid Loss: 56.78737767537435\n","Epoch: 2336/10000, Train Loss: 55.234681216153234, Valid Loss: 56.69337463378906\n","Epoch: 2337/10000, Train Loss: 55.10174976695668, Valid Loss: 56.657511393229164\n","Epoch: 2338/10000, Train Loss: 54.966209411621094, Valid Loss: 56.57922871907552\n","Epoch: 2339/10000, Train Loss: 54.90642339533026, Valid Loss: 56.54391352335612\n","Epoch: 2340/10000, Train Loss: 55.03861409967596, Valid Loss: 56.60685348510742\n","Epoch: 2341/10000, Train Loss: 55.13696947964755, Valid Loss: 56.69517262776693\n","Epoch: 2342/10000, Train Loss: 55.09197096391158, Valid Loss: 56.74988683064779\n","Epoch: 2343/10000, Train Loss: 55.12607192993164, Valid Loss: 56.73899586995443\n","Epoch: 2344/10000, Train Loss: 55.09722622958097, Valid Loss: 56.572436014811196\n","Epoch: 2345/10000, Train Loss: 54.85692769830877, Valid Loss: 56.578478495279946\n","Epoch: 2346/10000, Train Loss: 55.06772232055664, Valid Loss: 56.66769282023112\n","Epoch: 2347/10000, Train Loss: 54.94095368818803, Valid Loss: 56.59295781453451\n","Epoch: 2348/10000, Train Loss: 55.07992831143466, Valid Loss: 56.6054941813151\n","Epoch: 2349/10000, Train Loss: 55.09387623180043, Valid Loss: 56.57434844970703\n","Epoch: 2350/10000, Train Loss: 54.9002439325506, Valid Loss: 56.64432017008463\n","Epoch: 2351/10000, Train Loss: 55.14803487604315, Valid Loss: 56.597607930501304\n","Epoch: 2352/10000, Train Loss: 54.800567626953125, Valid Loss: 56.631003061930336\n","Epoch: 2353/10000, Train Loss: 54.70473514903676, Valid Loss: 56.463784535725914\n","Epoch: 2354/10000, Train Loss: 54.87940112027255, Valid Loss: 56.53169250488281\n","Epoch: 2355/10000, Train Loss: 54.740510420365766, Valid Loss: 56.56934356689453\n","Epoch: 2356/10000, Train Loss: 55.02773319591176, Valid Loss: 56.68058522542318\n","Epoch: 2357/10000, Train Loss: 54.93174882368608, Valid Loss: 56.6870969136556\n","Epoch: 2358/10000, Train Loss: 54.96746479381215, Valid Loss: 56.47645568847656\n","Epoch: 2359/10000, Train Loss: 55.00748270208185, Valid Loss: 56.614724477132164\n","Epoch: 2360/10000, Train Loss: 54.928998773748226, Valid Loss: 56.62417984008789\n","Epoch: 2361/10000, Train Loss: 54.89504137906161, Valid Loss: 56.555789947509766\n","Epoch: 2362/10000, Train Loss: 54.91496554287997, Valid Loss: 56.55396270751953\n","Epoch: 2363/10000, Train Loss: 54.971051302823156, Valid Loss: 56.51469930013021\n","Epoch: 2364/10000, Train Loss: 54.903906388716265, Valid Loss: 56.51255416870117\n","Epoch: 2365/10000, Train Loss: 55.0425779169256, Valid Loss: 56.48041025797526\n","Epoch: 2366/10000, Train Loss: 54.82912063598633, Valid Loss: 56.6458740234375\n","Epoch: 2367/10000, Train Loss: 54.84956845370206, Valid Loss: 56.60066223144531\n","Epoch: 2368/10000, Train Loss: 54.74843354658647, Valid Loss: 56.46813456217448\n","Epoch: 2369/10000, Train Loss: 54.821937561035156, Valid Loss: 56.54338709513346\n","Epoch: 2370/10000, Train Loss: 54.68618739734996, Valid Loss: 56.579446156819664\n","Epoch: 2371/10000, Train Loss: 54.90946891091087, Valid Loss: 56.5475819905599\n","Epoch: 2372/10000, Train Loss: 54.81286482377486, Valid Loss: 56.51528549194336\n","Epoch: 2373/10000, Train Loss: 55.030000860040836, Valid Loss: 56.45794804890951\n","Epoch: 2374/10000, Train Loss: 54.868779615922406, Valid Loss: 56.48395538330078\n","Epoch: 2375/10000, Train Loss: 54.740237496115945, Valid Loss: 56.524271647135414\n","Epoch: 2376/10000, Train Loss: 54.69449095292525, Valid Loss: 56.39367802937826\n","Epoch: 2377/10000, Train Loss: 55.08829567649148, Valid Loss: 56.4657351175944\n","Epoch: 2378/10000, Train Loss: 54.745973413640804, Valid Loss: 56.37249883015951\n","Epoch: 2379/10000, Train Loss: 54.832463351163, Valid Loss: 56.51438013712565\n","Epoch: 2380/10000, Train Loss: 54.85752001675692, Valid Loss: 56.559313456217446\n","Epoch: 2381/10000, Train Loss: 54.79332525079901, Valid Loss: 56.53765996297201\n","Epoch: 2382/10000, Train Loss: 54.5082234469327, Valid Loss: 56.35589345296224\n","Epoch: 2383/10000, Train Loss: 54.80030753395774, Valid Loss: 56.434983571370445\n","Epoch: 2384/10000, Train Loss: 54.78285876187411, Valid Loss: 56.42605845133463\n","Epoch: 2385/10000, Train Loss: 54.845779765735976, Valid Loss: 56.376748402913414\n","Epoch: 2386/10000, Train Loss: 54.94455892389471, Valid Loss: 56.299643198649086\n","Epoch: 2387/10000, Train Loss: 54.706046017733485, Valid Loss: 56.29891713460287\n","Epoch: 2388/10000, Train Loss: 54.712745666503906, Valid Loss: 56.28042984008789\n","Epoch: 2389/10000, Train Loss: 54.88632306185636, Valid Loss: 56.33877690633138\n","Epoch: 2390/10000, Train Loss: 54.94703778353605, Valid Loss: 56.30451456705729\n","Epoch: 2391/10000, Train Loss: 54.698855660178445, Valid Loss: 56.38709259033203\n","Epoch: 2392/10000, Train Loss: 54.58752580122514, Valid Loss: 56.46135711669922\n","Epoch: 2393/10000, Train Loss: 54.62892324274237, Valid Loss: 56.46746317545573\n","Epoch: 2394/10000, Train Loss: 54.7078163840554, Valid Loss: 56.41867192586263\n","Epoch: 2395/10000, Train Loss: 54.60865714333274, Valid Loss: 56.34686279296875\n","Epoch: 2396/10000, Train Loss: 54.76622876253995, Valid Loss: 56.36542002360026\n","Epoch: 2397/10000, Train Loss: 54.71003272316673, Valid Loss: 56.41827519734701\n","Epoch: 2398/10000, Train Loss: 54.8122111233798, Valid Loss: 56.48891830444336\n","Epoch: 2399/10000, Train Loss: 54.67845465920188, Valid Loss: 56.48598607381185\n","Epoch: 2400/10000, Train Loss: 54.6965498490767, Valid Loss: 56.348960876464844\n","Epoch: 2401/10000, Train Loss: 54.794884421608664, Valid Loss: 56.38769785563151\n","Epoch: 2402/10000, Train Loss: 54.72358322143555, Valid Loss: 56.23837916056315\n","Epoch: 2403/10000, Train Loss: 54.822054082697086, Valid Loss: 56.268768310546875\n","Epoch: 2404/10000, Train Loss: 54.75626442649148, Valid Loss: 56.41270319620768\n","Epoch: 2405/10000, Train Loss: 54.7151704268022, Valid Loss: 56.33415985107422\n","Epoch: 2406/10000, Train Loss: 54.50377377596769, Valid Loss: 56.309730529785156\n","Epoch: 2407/10000, Train Loss: 54.554103504527696, Valid Loss: 56.24219512939453\n","Epoch: 2408/10000, Train Loss: 54.685759804465555, Valid Loss: 56.216836293538414\n","Epoch: 2409/10000, Train Loss: 54.61677724664862, Valid Loss: 56.30163828531901\n","Epoch: 2410/10000, Train Loss: 54.681544217196375, Valid Loss: 56.37748718261719\n","Epoch: 2411/10000, Train Loss: 54.74283669211648, Valid Loss: 56.324713389078774\n","Epoch: 2412/10000, Train Loss: 54.64407799460671, Valid Loss: 56.35321553548177\n","Epoch: 2413/10000, Train Loss: 54.7053257335316, Valid Loss: 56.313761393229164\n","Epoch: 2414/10000, Train Loss: 54.524137323552914, Valid Loss: 56.27588399251302\n","Epoch: 2415/10000, Train Loss: 54.80721664428711, Valid Loss: 56.247030893961586\n","Epoch: 2416/10000, Train Loss: 54.423305164683946, Valid Loss: 56.33047739664713\n","Epoch: 2417/10000, Train Loss: 54.52006288008256, Valid Loss: 56.325401306152344\n","Epoch: 2418/10000, Train Loss: 54.531904047185726, Valid Loss: 56.383575439453125\n","Epoch: 2419/10000, Train Loss: 54.493376298384234, Valid Loss: 56.22176615397135\n","Epoch: 2420/10000, Train Loss: 54.77661202170632, Valid Loss: 56.23993937174479\n","Epoch: 2421/10000, Train Loss: 54.60078360817649, Valid Loss: 56.29145177205404\n","Epoch: 2422/10000, Train Loss: 54.55153343894265, Valid Loss: 56.21635818481445\n","Epoch: 2423/10000, Train Loss: 54.44470804387873, Valid Loss: 56.25053787231445\n","Epoch: 2424/10000, Train Loss: 54.44816450639205, Valid Loss: 56.21652603149414\n","Epoch: 2425/10000, Train Loss: 54.572385961359196, Valid Loss: 56.24109141031901\n","Epoch: 2426/10000, Train Loss: 54.389178189364344, Valid Loss: 56.302581787109375\n","Epoch: 2427/10000, Train Loss: 54.567265250466086, Valid Loss: 56.27955881754557\n","Epoch: 2428/10000, Train Loss: 54.4699179909446, Valid Loss: 56.32942326863607\n","Epoch: 2429/10000, Train Loss: 54.55492089011452, Valid Loss: 56.24449666341146\n","Epoch: 2430/10000, Train Loss: 54.603796525435015, Valid Loss: 56.158748626708984\n","Epoch: 2431/10000, Train Loss: 54.54409963434393, Valid Loss: 56.17727915445963\n","Epoch: 2432/10000, Train Loss: 54.49181157892401, Valid Loss: 56.218831380208336\n","Epoch: 2433/10000, Train Loss: 54.60723322088068, Valid Loss: 56.212301890055336\n","Epoch: 2434/10000, Train Loss: 54.761498191139914, Valid Loss: 56.168131510416664\n","Epoch: 2435/10000, Train Loss: 54.41344625299627, Valid Loss: 56.13577016194662\n","Epoch: 2436/10000, Train Loss: 54.279390855269, Valid Loss: 56.18157831827799\n","Epoch: 2437/10000, Train Loss: 54.51128110018644, Valid Loss: 56.09710184733073\n","Epoch: 2438/10000, Train Loss: 54.45830743963068, Valid Loss: 56.029136657714844\n","Epoch: 2439/10000, Train Loss: 54.56102544611151, Valid Loss: 56.01589838663737\n","Epoch: 2440/10000, Train Loss: 54.425961927934125, Valid Loss: 56.051727294921875\n","Epoch: 2441/10000, Train Loss: 54.39824676513672, Valid Loss: 56.12254969278971\n","Epoch: 2442/10000, Train Loss: 54.35088487104936, Valid Loss: 56.1680653889974\n","Epoch: 2443/10000, Train Loss: 54.585690238259055, Valid Loss: 56.091983795166016\n","Epoch: 2444/10000, Train Loss: 54.547825899991125, Valid Loss: 56.14124552408854\n","Epoch: 2445/10000, Train Loss: 54.47688813643022, Valid Loss: 56.09667714436849\n","Epoch: 2446/10000, Train Loss: 54.4135988408869, Valid Loss: 56.09858194986979\n","Epoch: 2447/10000, Train Loss: 54.512147730047054, Valid Loss: 56.18910598754883\n","Epoch: 2448/10000, Train Loss: 54.46168205954812, Valid Loss: 56.086509704589844\n","Epoch: 2449/10000, Train Loss: 54.41401568326083, Valid Loss: 56.14040501912435\n","Epoch: 2450/10000, Train Loss: 54.375761552290484, Valid Loss: 56.14530690511068\n","Epoch: 2451/10000, Train Loss: 54.33106162331321, Valid Loss: 56.088818868001304\n","Epoch: 2452/10000, Train Loss: 54.58817395296964, Valid Loss: 56.085259755452476\n","Epoch: 2453/10000, Train Loss: 54.36564393477006, Valid Loss: 55.946267445882164\n","Epoch: 2454/10000, Train Loss: 54.57751672918146, Valid Loss: 55.939449310302734\n","Epoch: 2455/10000, Train Loss: 54.5214018388228, Valid Loss: 56.01982752482096\n","Epoch: 2456/10000, Train Loss: 54.20392123135653, Valid Loss: 56.260361989339195\n","Epoch: 2457/10000, Train Loss: 54.30711503462358, Valid Loss: 56.04297892252604\n","Epoch: 2458/10000, Train Loss: 54.29154552112926, Valid Loss: 56.084754943847656\n","Epoch: 2459/10000, Train Loss: 54.363097797740586, Valid Loss: 56.16586430867513\n","Epoch: 2460/10000, Train Loss: 54.27251607721502, Valid Loss: 56.057421366373696\n","Epoch: 2461/10000, Train Loss: 54.468083815141156, Valid Loss: 56.01116689046224\n","Epoch: 2462/10000, Train Loss: 54.417167316783555, Valid Loss: 56.09309768676758\n","Epoch: 2463/10000, Train Loss: 54.38593604347923, Valid Loss: 56.100302378336586\n","Epoch: 2464/10000, Train Loss: 54.288142117587, Valid Loss: 56.07113393147787\n","Epoch: 2465/10000, Train Loss: 54.354310122403234, Valid Loss: 56.06110127766927\n","Epoch: 2466/10000, Train Loss: 54.22757686268199, Valid Loss: 56.05270640055338\n","Epoch: 2467/10000, Train Loss: 54.20595446499911, Valid Loss: 55.956092834472656\n","Epoch: 2468/10000, Train Loss: 54.21443731134588, Valid Loss: 55.96649932861328\n","Epoch: 2469/10000, Train Loss: 54.516250957142226, Valid Loss: 56.04887390136719\n","Epoch: 2470/10000, Train Loss: 54.33092706853693, Valid Loss: 56.01998392740885\n","Epoch: 2471/10000, Train Loss: 54.386577952991836, Valid Loss: 55.89915974934896\n","Epoch: 2472/10000, Train Loss: 54.41473735462535, Valid Loss: 56.075974782307945\n","Epoch: 2473/10000, Train Loss: 54.315405412153765, Valid Loss: 55.92829259236654\n","Epoch: 2474/10000, Train Loss: 54.17146058516069, Valid Loss: 56.03238169352213\n","Epoch: 2475/10000, Train Loss: 54.20027230002663, Valid Loss: 56.06033706665039\n","Epoch: 2476/10000, Train Loss: 54.28612206198952, Valid Loss: 56.01615651448568\n","Epoch: 2477/10000, Train Loss: 54.25049382990057, Valid Loss: 55.96284103393555\n","Epoch: 2478/10000, Train Loss: 54.27537155151367, Valid Loss: 55.97613652547201\n","Epoch: 2479/10000, Train Loss: 54.26268560236151, Valid Loss: 55.95120747884115\n","Epoch: 2480/10000, Train Loss: 54.30664339932528, Valid Loss: 56.02363967895508\n","Epoch: 2481/10000, Train Loss: 54.21793400157582, Valid Loss: 55.84464009602865\n","Epoch: 2482/10000, Train Loss: 54.179085124622695, Valid Loss: 55.92474238077799\n","Epoch: 2483/10000, Train Loss: 54.281617944890804, Valid Loss: 55.97721608479818\n","Epoch: 2484/10000, Train Loss: 54.19163339788263, Valid Loss: 55.923327128092446\n","Epoch: 2485/10000, Train Loss: 54.165254072709516, Valid Loss: 56.08210245768229\n","Epoch: 2486/10000, Train Loss: 54.081181959672406, Valid Loss: 55.99313608805338\n","Epoch: 2487/10000, Train Loss: 54.337672840465196, Valid Loss: 55.87957763671875\n","Epoch: 2488/10000, Train Loss: 54.06508463079279, Valid Loss: 55.846258799235024\n","Epoch: 2489/10000, Train Loss: 54.205951343883164, Valid Loss: 55.808789571126304\n","Epoch: 2490/10000, Train Loss: 54.157319502397016, Valid Loss: 55.744895935058594\n","Epoch: 2491/10000, Train Loss: 54.18427970192649, Valid Loss: 55.92404301961263\n","Epoch: 2492/10000, Train Loss: 54.29320005937056, Valid Loss: 55.980611165364586\n","Epoch: 2493/10000, Train Loss: 54.21133873679421, Valid Loss: 55.8509890238444\n","Epoch: 2494/10000, Train Loss: 54.140686381946914, Valid Loss: 55.68397521972656\n","Epoch: 2495/10000, Train Loss: 54.357460021972656, Valid Loss: 55.648871103922524\n","Epoch: 2496/10000, Train Loss: 54.07061143354936, Valid Loss: 55.803157806396484\n","Epoch: 2497/10000, Train Loss: 54.098080374977805, Valid Loss: 55.80506896972656\n","Epoch: 2498/10000, Train Loss: 54.2250317660245, Valid Loss: 55.7760378519694\n","Epoch: 2499/10000, Train Loss: 54.16617688265714, Valid Loss: 55.7439079284668\n","Epoch: 2500/10000, Train Loss: 54.087609724564985, Valid Loss: 55.70272445678711\n","Epoch: 2501/10000, Train Loss: 54.107326160777696, Valid Loss: 55.66358947753906\n","Epoch: 2502/10000, Train Loss: 54.039216475053266, Valid Loss: 55.69935989379883\n","Epoch: 2503/10000, Train Loss: 54.194705963134766, Valid Loss: 55.67961502075195\n","Epoch: 2504/10000, Train Loss: 54.129797501997515, Valid Loss: 55.60818862915039\n","Epoch: 2505/10000, Train Loss: 54.04796877774325, Valid Loss: 55.869188944498696\n","Epoch: 2506/10000, Train Loss: 54.164718281139024, Valid Loss: 55.817752838134766\n","Epoch: 2507/10000, Train Loss: 53.86647727272727, Valid Loss: 55.805075327555336\n","Epoch: 2508/10000, Train Loss: 54.03949737548828, Valid Loss: 55.63537343343099\n","Epoch: 2509/10000, Train Loss: 54.170265197753906, Valid Loss: 55.72234853108724\n","Epoch: 2510/10000, Train Loss: 53.98922625454989, Valid Loss: 55.66625722249349\n","Epoch: 2511/10000, Train Loss: 54.05305723710494, Valid Loss: 55.91656239827474\n","Epoch: 2512/10000, Train Loss: 54.062823208895594, Valid Loss: 55.843161265055336\n","Epoch: 2513/10000, Train Loss: 53.9701059514826, Valid Loss: 55.67914708455404\n","Epoch: 2514/10000, Train Loss: 54.02547212080522, Valid Loss: 55.774645487467446\n","Epoch: 2515/10000, Train Loss: 54.15926811911843, Valid Loss: 55.78369649251302\n","Epoch: 2516/10000, Train Loss: 54.11079372059215, Valid Loss: 55.77301788330078\n","Epoch: 2517/10000, Train Loss: 53.89763363924894, Valid Loss: 55.61599604288737\n","Epoch: 2518/10000, Train Loss: 54.0900483564897, Valid Loss: 55.703086853027344\n","Epoch: 2519/10000, Train Loss: 54.0632771578702, Valid Loss: 55.79455312093099\n","Epoch: 2520/10000, Train Loss: 53.820486242120914, Valid Loss: 55.78169504801432\n","Epoch: 2521/10000, Train Loss: 54.041127638383344, Valid Loss: 55.73439915974935\n","Epoch: 2522/10000, Train Loss: 54.10846155340021, Valid Loss: 55.76736831665039\n","Epoch: 2523/10000, Train Loss: 53.93148214166815, Valid Loss: 55.71709187825521\n","Epoch: 2524/10000, Train Loss: 54.07970601862127, Valid Loss: 55.760807037353516\n","Epoch: 2525/10000, Train Loss: 53.86719443581321, Valid Loss: 55.582106272379555\n","Epoch: 2526/10000, Train Loss: 53.74998023293235, Valid Loss: 55.62807973225912\n","Epoch: 2527/10000, Train Loss: 53.81115445223722, Valid Loss: 55.57885869344076\n","Epoch: 2528/10000, Train Loss: 54.06464385986328, Valid Loss: 55.695672353108726\n","Epoch: 2529/10000, Train Loss: 53.900753021240234, Valid Loss: 55.70782343546549\n","Epoch: 2530/10000, Train Loss: 53.94047962535512, Valid Loss: 55.65141296386719\n","Epoch: 2531/10000, Train Loss: 53.874392075972125, Valid Loss: 55.66213353474935\n","Epoch: 2532/10000, Train Loss: 53.96360466696999, Valid Loss: 55.62946319580078\n","Epoch: 2533/10000, Train Loss: 54.000655781139024, Valid Loss: 55.61350123087565\n","Epoch: 2534/10000, Train Loss: 53.98618698120117, Valid Loss: 55.63715489705404\n","Epoch: 2535/10000, Train Loss: 53.838648709383875, Valid Loss: 55.62367630004883\n","Epoch: 2536/10000, Train Loss: 53.71998353437944, Valid Loss: 55.687381744384766\n","Epoch: 2537/10000, Train Loss: 53.91171576760032, Valid Loss: 55.72879155476888\n","Epoch: 2538/10000, Train Loss: 53.96283999356356, Valid Loss: 55.59152094523112\n","Epoch: 2539/10000, Train Loss: 53.78858809037642, Valid Loss: 55.59247080485026\n","Epoch: 2540/10000, Train Loss: 53.86719825051048, Valid Loss: 55.58679453531901\n","Epoch: 2541/10000, Train Loss: 53.98657018488104, Valid Loss: 55.46705881754557\n","Epoch: 2542/10000, Train Loss: 53.7470852244984, Valid Loss: 55.5350710550944\n","Epoch: 2543/10000, Train Loss: 53.70118297230113, Valid Loss: 55.579949696858726\n","Epoch: 2544/10000, Train Loss: 53.70333342118697, Valid Loss: 55.52880096435547\n","Epoch: 2545/10000, Train Loss: 53.85825625332919, Valid Loss: 55.5464121500651\n","Epoch: 2546/10000, Train Loss: 53.94159282337535, Valid Loss: 55.518351236979164\n","Epoch: 2547/10000, Train Loss: 54.04627713290128, Valid Loss: 55.49659729003906\n","Epoch: 2548/10000, Train Loss: 53.81443301114169, Valid Loss: 55.466565450032554\n","Epoch: 2549/10000, Train Loss: 53.91974293101918, Valid Loss: 55.53561147054037\n","Epoch: 2550/10000, Train Loss: 53.657496365633875, Valid Loss: 55.30606587727865\n","Epoch: 2551/10000, Train Loss: 53.714993910356, Valid Loss: 55.52143224080404\n","Epoch: 2552/10000, Train Loss: 54.014374472878195, Valid Loss: 55.57069778442383\n","Epoch: 2553/10000, Train Loss: 53.70734717629173, Valid Loss: 55.56511942545573\n","Epoch: 2554/10000, Train Loss: 53.89287601817738, Valid Loss: 55.44813919067383\n","Epoch: 2555/10000, Train Loss: 53.64369028264826, Valid Loss: 55.56306838989258\n","Epoch: 2556/10000, Train Loss: 53.63231000033292, Valid Loss: 55.47924041748047\n","Epoch: 2557/10000, Train Loss: 53.7884635925293, Valid Loss: 55.50783157348633\n","Epoch: 2558/10000, Train Loss: 53.96141225641424, Valid Loss: 55.52413431803385\n","Epoch: 2559/10000, Train Loss: 53.61889162930575, Valid Loss: 55.5920778910319\n","Epoch: 2560/10000, Train Loss: 53.72930838844993, Valid Loss: 55.467812856038414\n","Epoch: 2561/10000, Train Loss: 53.522662076083094, Valid Loss: 55.39492543538412\n","Epoch: 2562/10000, Train Loss: 53.78937807950106, Valid Loss: 55.48024368286133\n","Epoch: 2563/10000, Train Loss: 53.90610261396928, Valid Loss: 55.55655415852865\n","Epoch: 2564/10000, Train Loss: 53.60435971346769, Valid Loss: 55.569461822509766\n","Epoch: 2565/10000, Train Loss: 53.69394198330966, Valid Loss: 55.521654764811196\n","Epoch: 2566/10000, Train Loss: 53.70821831443093, Valid Loss: 55.38218688964844\n","Epoch: 2567/10000, Train Loss: 53.63899230957031, Valid Loss: 55.44770177205404\n","Epoch: 2568/10000, Train Loss: 53.676285136829726, Valid Loss: 55.42581685384115\n","Epoch: 2569/10000, Train Loss: 53.57479685003107, Valid Loss: 55.39765548706055\n","Epoch: 2570/10000, Train Loss: 53.49048926613548, Valid Loss: 55.38641357421875\n","Epoch: 2571/10000, Train Loss: 53.66782344471324, Valid Loss: 55.371725718180336\n","Epoch: 2572/10000, Train Loss: 53.755896828391336, Valid Loss: 55.190731048583984\n","Epoch: 2573/10000, Train Loss: 53.63192402232777, Valid Loss: 55.27826182047526\n","Epoch: 2574/10000, Train Loss: 53.74288073453036, Valid Loss: 55.37594095865885\n","Epoch: 2575/10000, Train Loss: 53.63508467240767, Valid Loss: 55.33746083577474\n","Epoch: 2576/10000, Train Loss: 53.71775921908292, Valid Loss: 55.36756134033203\n","Epoch: 2577/10000, Train Loss: 53.52147397128019, Valid Loss: 55.300244649251304\n","Epoch: 2578/10000, Train Loss: 53.52802103215998, Valid Loss: 55.36316045125326\n","Epoch: 2579/10000, Train Loss: 53.76333583484996, Valid Loss: 55.33025995890299\n","Epoch: 2580/10000, Train Loss: 53.84125033291903, Valid Loss: 55.383008321126304\n","Epoch: 2581/10000, Train Loss: 53.63330667669123, Valid Loss: 55.40771484375\n","Epoch: 2582/10000, Train Loss: 53.70017311789773, Valid Loss: 55.50346374511719\n","Epoch: 2583/10000, Train Loss: 53.7754714272239, Valid Loss: 55.33495076497396\n","Epoch: 2584/10000, Train Loss: 53.429570631547406, Valid Loss: 55.30271530151367\n","Epoch: 2585/10000, Train Loss: 53.610783316872336, Valid Loss: 55.118001302083336\n","Epoch: 2586/10000, Train Loss: 53.62496115944602, Valid Loss: 55.29078674316406\n","Epoch: 2587/10000, Train Loss: 53.60432815551758, Valid Loss: 55.35299428304037\n","Epoch: 2588/10000, Train Loss: 53.811270627108485, Valid Loss: 55.15597915649414\n","Epoch: 2589/10000, Train Loss: 53.54510220614347, Valid Loss: 55.224708557128906\n","Epoch: 2590/10000, Train Loss: 53.57715467973189, Valid Loss: 55.18779500325521\n","Epoch: 2591/10000, Train Loss: 53.52483784068715, Valid Loss: 55.184713999430336\n","Epoch: 2592/10000, Train Loss: 53.43660042502663, Valid Loss: 55.19421641031901\n","Epoch: 2593/10000, Train Loss: 53.49518550526012, Valid Loss: 55.24387741088867\n","Epoch: 2594/10000, Train Loss: 53.50014391812411, Valid Loss: 55.24414825439453\n","Epoch: 2595/10000, Train Loss: 53.59849548339844, Valid Loss: 55.24298095703125\n","Epoch: 2596/10000, Train Loss: 53.46518915349787, Valid Loss: 55.221963246663414\n","Epoch: 2597/10000, Train Loss: 53.39849437366832, Valid Loss: 55.27132924397787\n","Epoch: 2598/10000, Train Loss: 53.58016933094371, Valid Loss: 55.34051767985026\n","Epoch: 2599/10000, Train Loss: 53.49915036288175, Valid Loss: 55.32473627726237\n","Epoch: 2600/10000, Train Loss: 53.4500170621005, Valid Loss: 55.221900939941406\n","Epoch: 2601/10000, Train Loss: 53.66556999900124, Valid Loss: 55.28539530436198\n","Epoch: 2602/10000, Train Loss: 53.623713753440164, Valid Loss: 55.26975123087565\n","Epoch: 2603/10000, Train Loss: 53.44026010686701, Valid Loss: 55.290496826171875\n","Epoch: 2604/10000, Train Loss: 53.44578032060103, Valid Loss: 55.182909647623696\n","Epoch: 2605/10000, Train Loss: 53.672363628040664, Valid Loss: 55.14688237508138\n","Epoch: 2606/10000, Train Loss: 53.36276973377574, Valid Loss: 55.24295171101888\n","Epoch: 2607/10000, Train Loss: 53.296540693803266, Valid Loss: 55.153664906819664\n","Epoch: 2608/10000, Train Loss: 53.55427100441673, Valid Loss: 55.182861328125\n","Epoch: 2609/10000, Train Loss: 53.70173957131126, Valid Loss: 55.395005544026695\n","Epoch: 2610/10000, Train Loss: 53.45721504905007, Valid Loss: 55.112250010172524\n","Epoch: 2611/10000, Train Loss: 53.46072699806907, Valid Loss: 55.05986785888672\n","Epoch: 2612/10000, Train Loss: 53.43333539095792, Valid Loss: 55.13523737589518\n","Epoch: 2613/10000, Train Loss: 53.43101570822976, Valid Loss: 55.247519175211586\n","Epoch: 2614/10000, Train Loss: 53.219078757546164, Valid Loss: 55.092047373453774\n","Epoch: 2615/10000, Train Loss: 53.590995441783555, Valid Loss: 55.147239685058594\n","Epoch: 2616/10000, Train Loss: 53.33766902576793, Valid Loss: 55.160203297932945\n","Epoch: 2617/10000, Train Loss: 53.234400662508875, Valid Loss: 55.19140116373698\n","Epoch: 2618/10000, Train Loss: 53.3830601085316, Valid Loss: 55.19125493367513\n","Epoch: 2619/10000, Train Loss: 53.40798638083718, Valid Loss: 55.15008544921875\n","Epoch: 2620/10000, Train Loss: 53.59174763072621, Valid Loss: 55.181382497151695\n","Epoch: 2621/10000, Train Loss: 53.249304337935015, Valid Loss: 55.133880615234375\n","Epoch: 2622/10000, Train Loss: 53.40998354825106, Valid Loss: 55.176378885904946\n","Epoch: 2623/10000, Train Loss: 53.229867761785336, Valid Loss: 55.216260274251304\n","Epoch: 2624/10000, Train Loss: 53.3081221147017, Valid Loss: 55.20268885294596\n","Epoch: 2625/10000, Train Loss: 53.21931284124201, Valid Loss: 55.094250996907554\n","Epoch: 2626/10000, Train Loss: 53.316499189897016, Valid Loss: 55.09200795491537\n","Epoch: 2627/10000, Train Loss: 53.38987835970792, Valid Loss: 55.17529169718424\n","Epoch: 2628/10000, Train Loss: 53.334749395197086, Valid Loss: 55.104339599609375\n","Epoch: 2629/10000, Train Loss: 53.463048761541195, Valid Loss: 55.0461311340332\n","Epoch: 2630/10000, Train Loss: 53.52473623102362, Valid Loss: 54.947287241617836\n","Epoch: 2631/10000, Train Loss: 53.47123475508256, Valid Loss: 54.86542765299479\n","Epoch: 2632/10000, Train Loss: 53.05559713190252, Valid Loss: 54.999534606933594\n","Epoch: 2633/10000, Train Loss: 53.31641249223189, Valid Loss: 55.136915842692055\n","Epoch: 2634/10000, Train Loss: 53.48391966386275, Valid Loss: 55.07612864176432\n","Epoch: 2635/10000, Train Loss: 53.49389509721236, Valid Loss: 55.01855341593424\n","Epoch: 2636/10000, Train Loss: 53.219541723077946, Valid Loss: 54.97799301147461\n","Epoch: 2637/10000, Train Loss: 53.266753456809305, Valid Loss: 54.95633316040039\n","Epoch: 2638/10000, Train Loss: 53.40674903176048, Valid Loss: 55.068528493245445\n","Epoch: 2639/10000, Train Loss: 53.348167419433594, Valid Loss: 55.032342274983726\n","Epoch: 2640/10000, Train Loss: 53.42572229558771, Valid Loss: 55.04425938924154\n","Epoch: 2641/10000, Train Loss: 53.31537593494762, Valid Loss: 54.951531728108726\n","Epoch: 2642/10000, Train Loss: 53.20691819624467, Valid Loss: 54.94396845499674\n","Epoch: 2643/10000, Train Loss: 53.23858365145597, Valid Loss: 55.0370127360026\n","Epoch: 2644/10000, Train Loss: 53.25616663152521, Valid Loss: 54.926995595296226\n","Epoch: 2645/10000, Train Loss: 53.315508755770594, Valid Loss: 55.123270670572914\n","Epoch: 2646/10000, Train Loss: 53.32520745017312, Valid Loss: 54.8571891784668\n","Epoch: 2647/10000, Train Loss: 53.01803554188121, Valid Loss: 54.98782221476237\n","Epoch: 2648/10000, Train Loss: 53.10003454034979, Valid Loss: 54.945271809895836\n","Epoch: 2649/10000, Train Loss: 53.21101310036399, Valid Loss: 54.91925557454427\n","Epoch: 2650/10000, Train Loss: 53.09833179820668, Valid Loss: 54.887167612711586\n","Epoch: 2651/10000, Train Loss: 53.294118361039594, Valid Loss: 54.966973622639976\n","Epoch: 2652/10000, Train Loss: 53.23221206665039, Valid Loss: 54.93009948730469\n","Epoch: 2653/10000, Train Loss: 53.22889258644798, Valid Loss: 54.8277587890625\n","Epoch: 2654/10000, Train Loss: 53.06664137406783, Valid Loss: 55.061265309651695\n","Epoch: 2655/10000, Train Loss: 52.821257851340555, Valid Loss: 54.833578745524086\n","Epoch: 2656/10000, Train Loss: 53.15976992520419, Valid Loss: 54.75839360555013\n","Epoch: 2657/10000, Train Loss: 53.35326593572443, Valid Loss: 54.76565806070963\n","Epoch: 2658/10000, Train Loss: 53.1517087763006, Valid Loss: 54.836981455485024\n","Epoch: 2659/10000, Train Loss: 53.33646600896662, Valid Loss: 54.93828582763672\n","Epoch: 2660/10000, Train Loss: 53.00832609696822, Valid Loss: 54.90294392903646\n","Epoch: 2661/10000, Train Loss: 53.0193415555087, Valid Loss: 55.024148305257164\n","Epoch: 2662/10000, Train Loss: 53.01612958041105, Valid Loss: 54.930650075276695\n","Epoch: 2663/10000, Train Loss: 53.110476753928445, Valid Loss: 54.87665303548177\n","Epoch: 2664/10000, Train Loss: 53.10069344260476, Valid Loss: 54.90397389729818\n","Epoch: 2665/10000, Train Loss: 53.33083170110529, Valid Loss: 54.926788330078125\n","Epoch: 2666/10000, Train Loss: 53.056828585538, Valid Loss: 54.90925216674805\n","Epoch: 2667/10000, Train Loss: 53.058779976584695, Valid Loss: 54.82161331176758\n","Epoch: 2668/10000, Train Loss: 52.96806508844549, Valid Loss: 54.83276621500651\n","Epoch: 2669/10000, Train Loss: 53.091562791304156, Valid Loss: 54.710391998291016\n","Epoch: 2670/10000, Train Loss: 53.11445617675781, Valid Loss: 54.801937103271484\n","Epoch: 2671/10000, Train Loss: 52.934290799227625, Valid Loss: 54.74457677205404\n","Epoch: 2672/10000, Train Loss: 52.99839956110174, Valid Loss: 54.80693054199219\n","Epoch: 2673/10000, Train Loss: 52.9312612360174, Valid Loss: 54.898433685302734\n","Epoch: 2674/10000, Train Loss: 52.97724845192649, Valid Loss: 54.915122985839844\n","Epoch: 2675/10000, Train Loss: 53.05414407903498, Valid Loss: 54.85364023844401\n","Epoch: 2676/10000, Train Loss: 52.80701966719194, Valid Loss: 54.81207402547201\n","Epoch: 2677/10000, Train Loss: 53.00878836891868, Valid Loss: 54.85600662231445\n","Epoch: 2678/10000, Train Loss: 53.12752498279918, Valid Loss: 54.832681020100914\n","Epoch: 2679/10000, Train Loss: 53.0258903503418, Valid Loss: 54.73076502482096\n","Epoch: 2680/10000, Train Loss: 53.030879280783914, Valid Loss: 54.626267751057945\n","Epoch: 2681/10000, Train Loss: 52.91877503828569, Valid Loss: 54.73629506429037\n","Epoch: 2682/10000, Train Loss: 53.024012478915125, Valid Loss: 54.67050806681315\n","Epoch: 2683/10000, Train Loss: 52.92450852827592, Valid Loss: 54.643060048421226\n","Epoch: 2684/10000, Train Loss: 52.92943087491122, Valid Loss: 54.65015538533529\n","Epoch: 2685/10000, Train Loss: 52.88706484707919, Valid Loss: 54.71444447835287\n","Epoch: 2686/10000, Train Loss: 52.91954179243608, Valid Loss: 54.723061879475914\n","Epoch: 2687/10000, Train Loss: 53.011945551091976, Valid Loss: 54.753761291503906\n","Epoch: 2688/10000, Train Loss: 52.96547421542081, Valid Loss: 54.72848383585612\n","Epoch: 2689/10000, Train Loss: 52.984064622358844, Valid Loss: 54.748521169026695\n","Epoch: 2690/10000, Train Loss: 53.03358320756392, Valid Loss: 54.82636388142904\n","Epoch: 2691/10000, Train Loss: 52.95127209750089, Valid Loss: 54.63482666015625\n","Epoch: 2692/10000, Train Loss: 52.64273868907582, Valid Loss: 54.78936767578125\n","Epoch: 2693/10000, Train Loss: 52.83603841608221, Valid Loss: 54.65045038859049\n","Epoch: 2694/10000, Train Loss: 53.157405853271484, Valid Loss: 54.50748062133789\n","Epoch: 2695/10000, Train Loss: 52.90939504450018, Valid Loss: 54.60265096028646\n","Epoch: 2696/10000, Train Loss: 53.01766620982777, Valid Loss: 54.65325673421224\n","Epoch: 2697/10000, Train Loss: 52.98143248124556, Valid Loss: 54.649087270100914\n","Epoch: 2698/10000, Train Loss: 52.77390254627574, Valid Loss: 54.72075271606445\n","Epoch: 2699/10000, Train Loss: 52.93574177135121, Valid Loss: 54.620538075764976\n","Epoch: 2700/10000, Train Loss: 53.112422943115234, Valid Loss: 54.60903676350912\n","Epoch: 2701/10000, Train Loss: 52.946109771728516, Valid Loss: 54.67753601074219\n","Epoch: 2702/10000, Train Loss: 52.994192990389735, Valid Loss: 54.62167485555013\n","Epoch: 2703/10000, Train Loss: 52.80247983065519, Valid Loss: 54.70156606038412\n","Epoch: 2704/10000, Train Loss: 52.81314745816317, Valid Loss: 54.63185373942057\n","Epoch: 2705/10000, Train Loss: 52.80656883933327, Valid Loss: 54.502176920572914\n","Epoch: 2706/10000, Train Loss: 52.78775960748846, Valid Loss: 54.596246083577476\n","Epoch: 2707/10000, Train Loss: 52.998126636851914, Valid Loss: 54.63467915852865\n","Epoch: 2708/10000, Train Loss: 52.927899447354406, Valid Loss: 54.54680506388346\n","Epoch: 2709/10000, Train Loss: 52.92232444069602, Valid Loss: 54.54880142211914\n","Epoch: 2710/10000, Train Loss: 52.707543806596235, Valid Loss: 54.70186869303385\n","Epoch: 2711/10000, Train Loss: 52.79934241554954, Valid Loss: 54.57013066609701\n","Epoch: 2712/10000, Train Loss: 52.639530181884766, Valid Loss: 54.54003397623698\n","Epoch: 2713/10000, Train Loss: 52.849543831565164, Valid Loss: 54.60751469930013\n","Epoch: 2714/10000, Train Loss: 53.120257290926844, Valid Loss: 54.49298095703125\n","Epoch: 2715/10000, Train Loss: 52.84453929554332, Valid Loss: 54.54342778523763\n","Epoch: 2716/10000, Train Loss: 52.71004416725852, Valid Loss: 54.605186462402344\n","Epoch: 2717/10000, Train Loss: 52.72810190374201, Valid Loss: 54.57786178588867\n","Epoch: 2718/10000, Train Loss: 52.72129752419212, Valid Loss: 54.61928939819336\n","Epoch: 2719/10000, Train Loss: 52.78071594238281, Valid Loss: 54.554551442464195\n","Epoch: 2720/10000, Train Loss: 52.62300526012074, Valid Loss: 54.46783574422201\n","Epoch: 2721/10000, Train Loss: 52.684770757501774, Valid Loss: 54.58876037597656\n","Epoch: 2722/10000, Train Loss: 52.7792309847745, Valid Loss: 54.68873977661133\n","Epoch: 2723/10000, Train Loss: 52.64707322554155, Valid Loss: 54.50188318888346\n","Epoch: 2724/10000, Train Loss: 52.644681410356, Valid Loss: 54.53922780354818\n","Epoch: 2725/10000, Train Loss: 52.87331841208718, Valid Loss: 54.37823232014974\n","Epoch: 2726/10000, Train Loss: 52.76185191761363, Valid Loss: 54.56976445515951\n","Epoch: 2727/10000, Train Loss: 52.88359208540483, Valid Loss: 54.4936777750651\n","Epoch: 2728/10000, Train Loss: 52.948904904452235, Valid Loss: 54.510274251302086\n","Epoch: 2729/10000, Train Loss: 52.57787392356179, Valid Loss: 54.655565897623696\n","Epoch: 2730/10000, Train Loss: 52.68963831121271, Valid Loss: 54.4260508219401\n","Epoch: 2731/10000, Train Loss: 52.86589258367365, Valid Loss: 54.403848012288414\n","Epoch: 2732/10000, Train Loss: 52.75126821344549, Valid Loss: 54.54077911376953\n","Epoch: 2733/10000, Train Loss: 52.617474642666906, Valid Loss: 54.52331797281901\n","Epoch: 2734/10000, Train Loss: 52.60793235085227, Valid Loss: 54.54449335734049\n","Epoch: 2735/10000, Train Loss: 52.604703729802914, Valid Loss: 54.41235097249349\n","Epoch: 2736/10000, Train Loss: 52.59086712923917, Valid Loss: 54.37246958414713\n","Epoch: 2737/10000, Train Loss: 52.66549856012518, Valid Loss: 54.48451487223307\n","Epoch: 2738/10000, Train Loss: 52.87244623357599, Valid Loss: 54.4415168762207\n","Epoch: 2739/10000, Train Loss: 52.57761487093839, Valid Loss: 54.49623998006185\n","Epoch: 2740/10000, Train Loss: 52.670087640935726, Valid Loss: 54.50271224975586\n","Epoch: 2741/10000, Train Loss: 52.600652174516156, Valid Loss: 54.30290222167969\n","Epoch: 2742/10000, Train Loss: 52.425546472722836, Valid Loss: 54.50375239054362\n","Epoch: 2743/10000, Train Loss: 52.757509058172054, Valid Loss: 54.39427057902018\n","Epoch: 2744/10000, Train Loss: 52.8735202442516, Valid Loss: 54.48958969116211\n","Epoch: 2745/10000, Train Loss: 52.5338661887429, Valid Loss: 54.42061233520508\n","Epoch: 2746/10000, Train Loss: 52.61392732100053, Valid Loss: 54.36342239379883\n","Epoch: 2747/10000, Train Loss: 52.58689568259499, Valid Loss: 54.33440144856771\n","Epoch: 2748/10000, Train Loss: 52.63652281327681, Valid Loss: 54.34281794230143\n","Epoch: 2749/10000, Train Loss: 52.53592924638228, Valid Loss: 54.47882207234701\n","Epoch: 2750/10000, Train Loss: 52.64142539284446, Valid Loss: 54.39546585083008\n","Epoch: 2751/10000, Train Loss: 52.47159611095082, Valid Loss: 54.276763916015625\n","Epoch: 2752/10000, Train Loss: 52.44039466164329, Valid Loss: 54.34313837687174\n","Epoch: 2753/10000, Train Loss: 52.49901719526811, Valid Loss: 54.35382334391276\n","Epoch: 2754/10000, Train Loss: 52.55713965676048, Valid Loss: 54.2873903910319\n","Epoch: 2755/10000, Train Loss: 52.493060025301844, Valid Loss: 54.28083928426107\n","Epoch: 2756/10000, Train Loss: 52.47834777832031, Valid Loss: 54.20851516723633\n","Epoch: 2757/10000, Train Loss: 52.227642406116836, Valid Loss: 54.321495056152344\n","Epoch: 2758/10000, Train Loss: 52.51228055087003, Valid Loss: 54.43492889404297\n","Epoch: 2759/10000, Train Loss: 52.38969247991388, Valid Loss: 54.25072224934896\n","Epoch: 2760/10000, Train Loss: 52.56636186079545, Valid Loss: 54.246978759765625\n","Epoch: 2761/10000, Train Loss: 52.37290226329457, Valid Loss: 54.41504033406576\n","Epoch: 2762/10000, Train Loss: 52.18006619540128, Valid Loss: 54.45893096923828\n","Epoch: 2763/10000, Train Loss: 52.30918780240145, Valid Loss: 54.3645871480306\n","Epoch: 2764/10000, Train Loss: 52.56590340354226, Valid Loss: 54.386923472086586\n","Epoch: 2765/10000, Train Loss: 52.446498524058946, Valid Loss: 54.24627176920573\n","Epoch: 2766/10000, Train Loss: 52.519563154740766, Valid Loss: 54.2412363688151\n","Epoch: 2767/10000, Train Loss: 52.430669264359906, Valid Loss: 54.29915110270182\n","Epoch: 2768/10000, Train Loss: 52.49214311079545, Valid Loss: 54.21782938639323\n","Epoch: 2769/10000, Train Loss: 52.52101655439897, Valid Loss: 54.237562815348305\n","Epoch: 2770/10000, Train Loss: 52.61012822931463, Valid Loss: 54.15460968017578\n","Epoch: 2771/10000, Train Loss: 52.447505950927734, Valid Loss: 54.25015640258789\n","Epoch: 2772/10000, Train Loss: 52.44357577237216, Valid Loss: 54.335183461507164\n","Epoch: 2773/10000, Train Loss: 52.55665831132369, Valid Loss: 54.24514134724935\n","Epoch: 2774/10000, Train Loss: 52.40000291304155, Valid Loss: 54.2571169535319\n","Epoch: 2775/10000, Train Loss: 52.44795192371715, Valid Loss: 54.21601231892904\n","Epoch: 2776/10000, Train Loss: 52.30665692416105, Valid Loss: 54.20824432373047\n","Epoch: 2777/10000, Train Loss: 52.37098589810458, Valid Loss: 54.17952219645182\n","Epoch: 2778/10000, Train Loss: 52.50109655206854, Valid Loss: 54.14662297566732\n","Epoch: 2779/10000, Train Loss: 52.60508797385476, Valid Loss: 54.21177419026693\n","Epoch: 2780/10000, Train Loss: 52.4678788618608, Valid Loss: 54.10372543334961\n","Epoch: 2781/10000, Train Loss: 52.4688193581321, Valid Loss: 54.127601623535156\n","Epoch: 2782/10000, Train Loss: 52.46731914173473, Valid Loss: 54.21625264485677\n","Epoch: 2783/10000, Train Loss: 52.26603768088601, Valid Loss: 54.20485814412435\n","Epoch: 2784/10000, Train Loss: 52.24617316506126, Valid Loss: 54.219231923421226\n","Epoch: 2785/10000, Train Loss: 52.264618613503195, Valid Loss: 54.1705436706543\n","Epoch: 2786/10000, Train Loss: 52.382017309015446, Valid Loss: 54.08837636311849\n","Epoch: 2787/10000, Train Loss: 52.2178559736772, Valid Loss: 54.074326833089195\n","Epoch: 2788/10000, Train Loss: 52.36649149114435, Valid Loss: 54.07137934366862\n","Epoch: 2789/10000, Train Loss: 52.16865331476385, Valid Loss: 54.208030700683594\n","Epoch: 2790/10000, Train Loss: 52.18669509887695, Valid Loss: 54.15249506632487\n","Epoch: 2791/10000, Train Loss: 52.29719057950106, Valid Loss: 54.16087849934896\n","Epoch: 2792/10000, Train Loss: 52.18402515758168, Valid Loss: 54.199971516927086\n","Epoch: 2793/10000, Train Loss: 52.0427395213734, Valid Loss: 54.085018157958984\n","Epoch: 2794/10000, Train Loss: 52.096953652121805, Valid Loss: 54.24876912434896\n","Epoch: 2795/10000, Train Loss: 52.316255742853336, Valid Loss: 54.18539047241211\n","Epoch: 2796/10000, Train Loss: 52.30544593117454, Valid Loss: 53.999061584472656\n","Epoch: 2797/10000, Train Loss: 52.21339000355113, Valid Loss: 54.07859547932943\n","Epoch: 2798/10000, Train Loss: 52.361465800892226, Valid Loss: 54.0526008605957\n","Epoch: 2799/10000, Train Loss: 52.051238320090555, Valid Loss: 54.07790883382162\n","Epoch: 2800/10000, Train Loss: 52.158789894797586, Valid Loss: 54.005383809407554\n","Epoch: 2801/10000, Train Loss: 52.1912956237793, Valid Loss: 54.02528762817383\n","Epoch: 2802/10000, Train Loss: 52.33135986328125, Valid Loss: 54.098089853922524\n","Epoch: 2803/10000, Train Loss: 52.28368655118075, Valid Loss: 54.06918970743815\n","Epoch: 2804/10000, Train Loss: 52.19725314053622, Valid Loss: 54.05453109741211\n","Epoch: 2805/10000, Train Loss: 52.28000224720348, Valid Loss: 54.125755310058594\n","Epoch: 2806/10000, Train Loss: 52.00410842895508, Valid Loss: 54.152581532796226\n","Epoch: 2807/10000, Train Loss: 52.397131486372515, Valid Loss: 54.118796030680336\n","Epoch: 2808/10000, Train Loss: 52.0544267134233, Valid Loss: 53.963540395100914\n","Epoch: 2809/10000, Train Loss: 52.30151089754972, Valid Loss: 54.0543581644694\n","Epoch: 2810/10000, Train Loss: 52.32086112282493, Valid Loss: 54.039807637532554\n","Epoch: 2811/10000, Train Loss: 52.015290693803266, Valid Loss: 54.04331970214844\n","Epoch: 2812/10000, Train Loss: 52.027318087491125, Valid Loss: 53.95654551188151\n","Epoch: 2813/10000, Train Loss: 52.309025504372336, Valid Loss: 53.9854482014974\n","Epoch: 2814/10000, Train Loss: 52.088129563765094, Valid Loss: 53.967411041259766\n","Epoch: 2815/10000, Train Loss: 52.03444012728605, Valid Loss: 53.85110346476237\n","Epoch: 2816/10000, Train Loss: 52.04871888594194, Valid Loss: 53.85716883341471\n","Epoch: 2817/10000, Train Loss: 51.93529510498047, Valid Loss: 53.91580581665039\n","Epoch: 2818/10000, Train Loss: 52.28657288984819, Valid Loss: 54.0289052327474\n","Epoch: 2819/10000, Train Loss: 52.317320736971766, Valid Loss: 53.94210433959961\n","Epoch: 2820/10000, Train Loss: 52.32934015447443, Valid Loss: 54.069679260253906\n","Epoch: 2821/10000, Train Loss: 51.83351516723633, Valid Loss: 53.90218734741211\n","Epoch: 2822/10000, Train Loss: 52.05963828346946, Valid Loss: 53.73391469319662\n","Epoch: 2823/10000, Train Loss: 52.14076649058949, Valid Loss: 53.896949768066406\n","Epoch: 2824/10000, Train Loss: 52.07635428688743, Valid Loss: 53.91645304361979\n","Epoch: 2825/10000, Train Loss: 52.39011972600763, Valid Loss: 53.8414306640625\n","Epoch: 2826/10000, Train Loss: 52.23038933493874, Valid Loss: 53.848731994628906\n","Epoch: 2827/10000, Train Loss: 51.97631177035245, Valid Loss: 53.84353256225586\n","Epoch: 2828/10000, Train Loss: 51.94438483498313, Valid Loss: 53.77729797363281\n","Epoch: 2829/10000, Train Loss: 52.10377051613548, Valid Loss: 53.88864262898763\n","Epoch: 2830/10000, Train Loss: 52.20247892899947, Valid Loss: 53.823038736979164\n","Epoch: 2831/10000, Train Loss: 51.9743898565119, Valid Loss: 53.774855295817055\n","Epoch: 2832/10000, Train Loss: 52.27109076760032, Valid Loss: 53.8457883199056\n","Epoch: 2833/10000, Train Loss: 52.13416567715731, Valid Loss: 53.930006663004555\n","Epoch: 2834/10000, Train Loss: 51.929052873091265, Valid Loss: 53.85014343261719\n","Epoch: 2835/10000, Train Loss: 52.019704992120914, Valid Loss: 53.829568227132164\n","Epoch: 2836/10000, Train Loss: 51.8007153597745, Valid Loss: 53.86200714111328\n","Epoch: 2837/10000, Train Loss: 52.025896245783024, Valid Loss: 53.79364267985026\n","Epoch: 2838/10000, Train Loss: 52.14269256591797, Valid Loss: 53.698988596598305\n","Epoch: 2839/10000, Train Loss: 52.013052853670985, Valid Loss: 53.72493362426758\n","Epoch: 2840/10000, Train Loss: 51.79852711070668, Valid Loss: 53.8563486735026\n","Epoch: 2841/10000, Train Loss: 52.16147752241655, Valid Loss: 53.79493967692057\n","Epoch: 2842/10000, Train Loss: 52.077147397128016, Valid Loss: 53.8329823811849\n","Epoch: 2843/10000, Train Loss: 52.1275107643821, Valid Loss: 53.67515563964844\n","Epoch: 2844/10000, Train Loss: 51.97349132191051, Valid Loss: 53.76237360636393\n","Epoch: 2845/10000, Train Loss: 52.01155749234286, Valid Loss: 53.81161753336588\n","Epoch: 2846/10000, Train Loss: 51.91643003983931, Valid Loss: 53.81877009073893\n","Epoch: 2847/10000, Train Loss: 51.89015024358576, Valid Loss: 53.68520863850912\n","Epoch: 2848/10000, Train Loss: 52.00465947931463, Valid Loss: 53.74284362792969\n","Epoch: 2849/10000, Train Loss: 51.85802667791193, Valid Loss: 53.76476287841797\n","Epoch: 2850/10000, Train Loss: 52.059413563121446, Valid Loss: 53.85096104939779\n","Epoch: 2851/10000, Train Loss: 51.95933636752042, Valid Loss: 53.91086196899414\n","Epoch: 2852/10000, Train Loss: 51.85290388627486, Valid Loss: 53.814343770345054\n","Epoch: 2853/10000, Train Loss: 52.02772071144798, Valid Loss: 53.76947275797526\n","Epoch: 2854/10000, Train Loss: 52.013513738458805, Valid Loss: 53.94098790486654\n","Epoch: 2855/10000, Train Loss: 52.00157442959872, Valid Loss: 53.63684209187826\n","Epoch: 2856/10000, Train Loss: 51.882480968128554, Valid Loss: 53.67845789591471\n","Epoch: 2857/10000, Train Loss: 51.82353973388672, Valid Loss: 53.68868637084961\n","Epoch: 2858/10000, Train Loss: 51.794044494628906, Valid Loss: 53.507240295410156\n","Epoch: 2859/10000, Train Loss: 51.75895829634233, Valid Loss: 53.636426289876304\n","Epoch: 2860/10000, Train Loss: 51.842317754572086, Valid Loss: 53.81470489501953\n","Epoch: 2861/10000, Train Loss: 51.94619300148704, Valid Loss: 53.592899322509766\n","Epoch: 2862/10000, Train Loss: 51.69126371903853, Valid Loss: 53.691636403401695\n","Epoch: 2863/10000, Train Loss: 51.84805609963157, Valid Loss: 53.76989237467448\n","Epoch: 2864/10000, Train Loss: 51.7550725069913, Valid Loss: 53.667641957600914\n","Epoch: 2865/10000, Train Loss: 51.85914438421076, Valid Loss: 53.54161580403646\n","Epoch: 2866/10000, Train Loss: 52.062603343616836, Valid Loss: 53.619649251302086\n","Epoch: 2867/10000, Train Loss: 51.98719510165128, Valid Loss: 53.803717295328774\n","Epoch: 2868/10000, Train Loss: 51.71027755737305, Valid Loss: 53.51492563883463\n","Epoch: 2869/10000, Train Loss: 51.63424405184659, Valid Loss: 53.67097600301107\n","Epoch: 2870/10000, Train Loss: 51.729217529296875, Valid Loss: 53.771776835123696\n","Epoch: 2871/10000, Train Loss: 51.931326085870914, Valid Loss: 53.70495478312174\n","Epoch: 2872/10000, Train Loss: 51.805176821621984, Valid Loss: 53.733428955078125\n","Epoch: 2873/10000, Train Loss: 51.966792366721414, Valid Loss: 53.691331227620445\n","Epoch: 2874/10000, Train Loss: 51.76535970514471, Valid Loss: 53.68073272705078\n","Epoch: 2875/10000, Train Loss: 51.63920870694247, Valid Loss: 53.714612325032554\n","Epoch: 2876/10000, Train Loss: 51.84056160666726, Valid Loss: 53.55628458658854\n","Epoch: 2877/10000, Train Loss: 51.555852369828656, Valid Loss: 53.51736958821615\n","Epoch: 2878/10000, Train Loss: 51.645319505171344, Valid Loss: 53.67328008015951\n","Epoch: 2879/10000, Train Loss: 51.61482238769531, Valid Loss: 53.62811279296875\n","Epoch: 2880/10000, Train Loss: 51.8318117315119, Valid Loss: 53.55581283569336\n","Epoch: 2881/10000, Train Loss: 51.932199304754086, Valid Loss: 53.494851430257164\n","Epoch: 2882/10000, Train Loss: 51.79136033491655, Valid Loss: 53.431504567464195\n","Epoch: 2883/10000, Train Loss: 51.54597334428267, Valid Loss: 53.550942738850914\n","Epoch: 2884/10000, Train Loss: 51.934656316583805, Valid Loss: 53.665289560953774\n","Epoch: 2885/10000, Train Loss: 51.7334397055886, Valid Loss: 53.561257680257164\n","Epoch: 2886/10000, Train Loss: 51.47947519475763, Valid Loss: 53.58165613810221\n","Epoch: 2887/10000, Train Loss: 51.48063798384233, Valid Loss: 53.533644358317055\n","Epoch: 2888/10000, Train Loss: 51.82903081720526, Valid Loss: 53.63142013549805\n","Epoch: 2889/10000, Train Loss: 51.59997003728693, Valid Loss: 53.60039138793945\n","Epoch: 2890/10000, Train Loss: 51.459531957452946, Valid Loss: 53.48472595214844\n","Epoch: 2891/10000, Train Loss: 51.80501209605824, Valid Loss: 53.39115524291992\n","Epoch: 2892/10000, Train Loss: 51.476102655584164, Valid Loss: 53.43892923990885\n","Epoch: 2893/10000, Train Loss: 51.59292429143732, Valid Loss: 53.389400482177734\n","Epoch: 2894/10000, Train Loss: 51.655970486727625, Valid Loss: 53.48861312866211\n","Epoch: 2895/10000, Train Loss: 51.610410863702946, Valid Loss: 53.34749984741211\n","Epoch: 2896/10000, Train Loss: 51.55518618496981, Valid Loss: 53.36021296183268\n","Epoch: 2897/10000, Train Loss: 51.71220328591087, Valid Loss: 53.45619455973307\n","Epoch: 2898/10000, Train Loss: 51.53509937633168, Valid Loss: 53.59794235229492\n","Epoch: 2899/10000, Train Loss: 51.750236164439805, Valid Loss: 53.31846237182617\n","Epoch: 2900/10000, Train Loss: 51.65163803100586, Valid Loss: 53.4645029703776\n","Epoch: 2901/10000, Train Loss: 51.67055372758345, Valid Loss: 53.452935536702476\n","Epoch: 2902/10000, Train Loss: 51.73482131958008, Valid Loss: 53.43054962158203\n","Epoch: 2903/10000, Train Loss: 51.75486686012962, Valid Loss: 53.56083297729492\n","Epoch: 2904/10000, Train Loss: 51.56165209683505, Valid Loss: 53.52691141764323\n","Epoch: 2905/10000, Train Loss: 51.72659128362482, Valid Loss: 53.44661331176758\n","Epoch: 2906/10000, Train Loss: 51.61543828790838, Valid Loss: 53.43356577555338\n","Epoch: 2907/10000, Train Loss: 51.60648588700728, Valid Loss: 53.4726816813151\n","Epoch: 2908/10000, Train Loss: 51.53399519486861, Valid Loss: 53.454627990722656\n","Epoch: 2909/10000, Train Loss: 51.64712975241921, Valid Loss: 53.46273930867513\n","Epoch: 2910/10000, Train Loss: 51.54336825284091, Valid Loss: 53.35881678263346\n","Epoch: 2911/10000, Train Loss: 51.36893081665039, Valid Loss: 53.28931427001953\n","Epoch: 2912/10000, Train Loss: 51.365266973322086, Valid Loss: 53.2748654683431\n","Epoch: 2913/10000, Train Loss: 51.639152180064805, Valid Loss: 53.35254414876302\n","Epoch: 2914/10000, Train Loss: 51.51595271717418, Valid Loss: 53.47111129760742\n","Epoch: 2915/10000, Train Loss: 51.46721267700195, Valid Loss: 53.407335917154946\n","Epoch: 2916/10000, Train Loss: 51.36483452536843, Valid Loss: 53.501946767171226\n","Epoch: 2917/10000, Train Loss: 51.398312308571555, Valid Loss: 53.33481979370117\n","Epoch: 2918/10000, Train Loss: 51.72911071777344, Valid Loss: 53.43735376993815\n","Epoch: 2919/10000, Train Loss: 51.47428096424449, Valid Loss: 53.30193583170573\n","Epoch: 2920/10000, Train Loss: 51.30955331975763, Valid Loss: 53.22837448120117\n","Epoch: 2921/10000, Train Loss: 51.50703430175781, Valid Loss: 53.21964009602865\n","Epoch: 2922/10000, Train Loss: 51.41152607310902, Valid Loss: 53.2209587097168\n","Epoch: 2923/10000, Train Loss: 51.33777132901278, Valid Loss: 53.2690175374349\n","Epoch: 2924/10000, Train Loss: 51.325693650679156, Valid Loss: 53.3632443745931\n","Epoch: 2925/10000, Train Loss: 51.50661017678001, Valid Loss: 53.36371612548828\n","Epoch: 2926/10000, Train Loss: 51.500275351784445, Valid Loss: 53.32261276245117\n","Epoch: 2927/10000, Train Loss: 51.31548344005238, Valid Loss: 53.347432454427086\n","Epoch: 2928/10000, Train Loss: 51.481388092041016, Valid Loss: 53.29224395751953\n","Epoch: 2929/10000, Train Loss: 51.377838828346945, Valid Loss: 53.20340092976888\n","Epoch: 2930/10000, Train Loss: 51.53543194857511, Valid Loss: 53.162401835123696\n","Epoch: 2931/10000, Train Loss: 51.38432866876776, Valid Loss: 53.167582194010414\n","Epoch: 2932/10000, Train Loss: 51.35235040838068, Valid Loss: 53.169602711995445\n","Epoch: 2933/10000, Train Loss: 51.435481331565164, Valid Loss: 53.197760264078774\n","Epoch: 2934/10000, Train Loss: 51.21015999533913, Valid Loss: 53.289424896240234\n","Epoch: 2935/10000, Train Loss: 51.37686191905629, Valid Loss: 53.25025304158529\n","Epoch: 2936/10000, Train Loss: 51.42439027266069, Valid Loss: 53.20132319132487\n","Epoch: 2937/10000, Train Loss: 51.41040524569425, Valid Loss: 53.14290237426758\n","Epoch: 2938/10000, Train Loss: 51.33501607721502, Valid Loss: 53.16536076863607\n","Epoch: 2939/10000, Train Loss: 51.26127797907049, Valid Loss: 53.254416147867836\n","Epoch: 2940/10000, Train Loss: 51.38003505359996, Valid Loss: 53.2713508605957\n","Epoch: 2941/10000, Train Loss: 51.32878875732422, Valid Loss: 53.278551737467446\n","Epoch: 2942/10000, Train Loss: 51.3602461381392, Valid Loss: 53.13228988647461\n","Epoch: 2943/10000, Train Loss: 51.33664668690074, Valid Loss: 53.045074462890625\n","Epoch: 2944/10000, Train Loss: 51.352845278653234, Valid Loss: 53.194390614827476\n","Epoch: 2945/10000, Train Loss: 51.44490918246183, Valid Loss: 53.22176869710287\n","Epoch: 2946/10000, Train Loss: 51.170472925359554, Valid Loss: 53.36239751180013\n","Epoch: 2947/10000, Train Loss: 51.34619764848189, Valid Loss: 53.307594299316406\n","Epoch: 2948/10000, Train Loss: 51.352041417902164, Valid Loss: 53.26941172281901\n","Epoch: 2949/10000, Train Loss: 51.04737229780717, Valid Loss: 53.14344278971354\n","Epoch: 2950/10000, Train Loss: 51.51053203235973, Valid Loss: 53.146915435791016\n","Epoch: 2951/10000, Train Loss: 51.20989782159979, Valid Loss: 52.97740681966146\n","Epoch: 2952/10000, Train Loss: 51.2802980596369, Valid Loss: 53.1425526936849\n","Epoch: 2953/10000, Train Loss: 51.154396057128906, Valid Loss: 53.152792612711586\n","Epoch: 2954/10000, Train Loss: 51.17080965909091, Valid Loss: 52.97124226888021\n","Epoch: 2955/10000, Train Loss: 51.189115004106, Valid Loss: 52.938480377197266\n","Epoch: 2956/10000, Train Loss: 51.35065460205078, Valid Loss: 53.0831667582194\n","Epoch: 2957/10000, Train Loss: 51.349872242320664, Valid Loss: 53.06763585408529\n","Epoch: 2958/10000, Train Loss: 51.14250044389205, Valid Loss: 53.16433334350586\n","Epoch: 2959/10000, Train Loss: 51.23732445456765, Valid Loss: 53.24761454264323\n","Epoch: 2960/10000, Train Loss: 51.24353235418146, Valid Loss: 53.18513743082682\n","Epoch: 2961/10000, Train Loss: 51.30767059326172, Valid Loss: 53.223514556884766\n","Epoch: 2962/10000, Train Loss: 51.114478371360086, Valid Loss: 53.125956217447914\n","Epoch: 2963/10000, Train Loss: 51.195856961337, Valid Loss: 53.06940205891927\n","Epoch: 2964/10000, Train Loss: 51.10801800814542, Valid Loss: 53.138126373291016\n","Epoch: 2965/10000, Train Loss: 51.00123526833274, Valid Loss: 53.08743667602539\n","Epoch: 2966/10000, Train Loss: 50.959136269309305, Valid Loss: 52.97175725301107\n","Epoch: 2967/10000, Train Loss: 51.46745508367365, Valid Loss: 52.985172271728516\n","Epoch: 2968/10000, Train Loss: 51.104056965221055, Valid Loss: 53.042850494384766\n","Epoch: 2969/10000, Train Loss: 51.481468200683594, Valid Loss: 52.94274012247721\n","Epoch: 2970/10000, Train Loss: 51.278608148748226, Valid Loss: 53.08732223510742\n","Epoch: 2971/10000, Train Loss: 50.94299108331854, Valid Loss: 52.95389175415039\n","Epoch: 2972/10000, Train Loss: 50.95875792069869, Valid Loss: 53.05493291219076\n","Epoch: 2973/10000, Train Loss: 51.24033806540749, Valid Loss: 53.1455078125\n","Epoch: 2974/10000, Train Loss: 51.1861967606978, Valid Loss: 53.02669779459635\n","Epoch: 2975/10000, Train Loss: 51.042261990633875, Valid Loss: 52.97230784098307\n","Epoch: 2976/10000, Train Loss: 51.39595898714933, Valid Loss: 52.994364420572914\n","Epoch: 2977/10000, Train Loss: 51.23117932406339, Valid Loss: 53.03255716959635\n","Epoch: 2978/10000, Train Loss: 51.31659698486328, Valid Loss: 52.86254374186198\n","Epoch: 2979/10000, Train Loss: 51.31046988747337, Valid Loss: 52.942666371663414\n","Epoch: 2980/10000, Train Loss: 51.329529155384414, Valid Loss: 52.947034200032554\n","Epoch: 2981/10000, Train Loss: 51.040237773548476, Valid Loss: 52.94358698527018\n","Epoch: 2982/10000, Train Loss: 50.98181221701882, Valid Loss: 52.967427571614586\n","Epoch: 2983/10000, Train Loss: 50.969039570201524, Valid Loss: 52.9757194519043\n","Epoch: 2984/10000, Train Loss: 51.26177076859908, Valid Loss: 52.9546267191569\n","Epoch: 2985/10000, Train Loss: 50.74717018821023, Valid Loss: 52.857199350992836\n","Epoch: 2986/10000, Train Loss: 51.004341472278945, Valid Loss: 52.942726135253906\n","Epoch: 2987/10000, Train Loss: 50.97212704745206, Valid Loss: 52.965352376302086\n","Epoch: 2988/10000, Train Loss: 51.06265917691317, Valid Loss: 52.92676035563151\n","Epoch: 2989/10000, Train Loss: 50.765017075972125, Valid Loss: 52.895242055257164\n","Epoch: 2990/10000, Train Loss: 51.16189748590643, Valid Loss: 53.038031260172524\n","Epoch: 2991/10000, Train Loss: 50.879247492009945, Valid Loss: 52.985006968180336\n","Epoch: 2992/10000, Train Loss: 50.93352508544922, Valid Loss: 53.08453114827474\n","Epoch: 2993/10000, Train Loss: 51.05534293434837, Valid Loss: 52.94084040323893\n","Epoch: 2994/10000, Train Loss: 50.873639887029476, Valid Loss: 53.01962534586588\n","Epoch: 2995/10000, Train Loss: 51.02941755814986, Valid Loss: 52.993534088134766\n","Epoch: 2996/10000, Train Loss: 50.64043495871804, Valid Loss: 52.94156265258789\n","Epoch: 2997/10000, Train Loss: 51.10105583884499, Valid Loss: 52.958824157714844\n","Epoch: 2998/10000, Train Loss: 50.94401584972035, Valid Loss: 52.851507822672524\n","Epoch: 2999/10000, Train Loss: 51.007384213534266, Valid Loss: 52.821231842041016\n","Epoch: 3000/10000, Train Loss: 50.84771797873757, Valid Loss: 52.9079958597819\n","Epoch: 3001/10000, Train Loss: 50.97351351651278, Valid Loss: 52.79937489827474\n","Epoch: 3002/10000, Train Loss: 50.973389712246984, Valid Loss: 52.90454864501953\n","Epoch: 3003/10000, Train Loss: 50.77971822565252, Valid Loss: 52.82201385498047\n","Epoch: 3004/10000, Train Loss: 51.043089086359196, Valid Loss: 52.72951126098633\n","Epoch: 3005/10000, Train Loss: 51.01801750876687, Valid Loss: 52.89373652140299\n","Epoch: 3006/10000, Train Loss: 50.89885364879262, Valid Loss: 52.7014528910319\n","Epoch: 3007/10000, Train Loss: 50.77672507546165, Valid Loss: 52.75787226359049\n","Epoch: 3008/10000, Train Loss: 50.88783784346147, Valid Loss: 52.75942738850912\n","Epoch: 3009/10000, Train Loss: 51.04822366887873, Valid Loss: 52.85826746622721\n","Epoch: 3010/10000, Train Loss: 51.05630770596591, Valid Loss: 52.80156707763672\n","Epoch: 3011/10000, Train Loss: 51.01988289572976, Valid Loss: 52.79137293497721\n","Epoch: 3012/10000, Train Loss: 50.79560019753196, Valid Loss: 52.77198791503906\n","Epoch: 3013/10000, Train Loss: 50.98417906327681, Valid Loss: 52.73221969604492\n","Epoch: 3014/10000, Train Loss: 50.7824557911266, Valid Loss: 52.79645792643229\n","Epoch: 3015/10000, Train Loss: 51.15754942460494, Valid Loss: 52.68540954589844\n","Epoch: 3016/10000, Train Loss: 50.97583770751953, Valid Loss: 52.71868006388346\n","Epoch: 3017/10000, Train Loss: 51.075030240145594, Valid Loss: 52.83442687988281\n","Epoch: 3018/10000, Train Loss: 50.67240836403587, Valid Loss: 52.653924306233726\n","Epoch: 3019/10000, Train Loss: 50.6536091891202, Valid Loss: 52.85063680013021\n","Epoch: 3020/10000, Train Loss: 50.666382182728164, Valid Loss: 52.668505350748696\n","Epoch: 3021/10000, Train Loss: 50.725376475941054, Valid Loss: 52.7968381245931\n","Epoch: 3022/10000, Train Loss: 50.68195932561701, Valid Loss: 52.68599319458008\n","Epoch: 3023/10000, Train Loss: 50.829499678178266, Valid Loss: 52.576674143473305\n","Epoch: 3024/10000, Train Loss: 50.75814229791815, Valid Loss: 52.589176177978516\n","Epoch: 3025/10000, Train Loss: 50.77449105002663, Valid Loss: 52.60360336303711\n","Epoch: 3026/10000, Train Loss: 51.07503960349343, Valid Loss: 52.5052235921224\n","Epoch: 3027/10000, Train Loss: 50.70583239468661, Valid Loss: 52.546026865641274\n","Epoch: 3028/10000, Train Loss: 50.800728191028945, Valid Loss: 52.747755686442055\n","Epoch: 3029/10000, Train Loss: 50.8278132351962, Valid Loss: 52.584939320882164\n","Epoch: 3030/10000, Train Loss: 50.78041146018288, Valid Loss: 52.7502810160319\n","Epoch: 3031/10000, Train Loss: 50.579340501265094, Valid Loss: 52.468023935953774\n","Epoch: 3032/10000, Train Loss: 50.6722165888006, Valid Loss: 52.62367502848307\n","Epoch: 3033/10000, Train Loss: 50.91278214888139, Valid Loss: 52.561834971110024\n","Epoch: 3034/10000, Train Loss: 50.736631566827946, Valid Loss: 52.364480336507164\n","Epoch: 3035/10000, Train Loss: 50.38852934403853, Valid Loss: 52.60023498535156\n","Epoch: 3036/10000, Train Loss: 50.64532470703125, Valid Loss: 52.543145497639976\n","Epoch: 3037/10000, Train Loss: 50.60996558449485, Valid Loss: 52.57396697998047\n","Epoch: 3038/10000, Train Loss: 50.72837586836381, Valid Loss: 52.6533088684082\n","Epoch: 3039/10000, Train Loss: 50.66590603915128, Valid Loss: 52.55511474609375\n","Epoch: 3040/10000, Train Loss: 50.57637578790838, Valid Loss: 52.43604278564453\n","Epoch: 3041/10000, Train Loss: 50.59957642988725, Valid Loss: 52.430792490641274\n","Epoch: 3042/10000, Train Loss: 50.76249139959162, Valid Loss: 52.65004094441732\n","Epoch: 3043/10000, Train Loss: 50.67848378961737, Valid Loss: 52.65990956624349\n","Epoch: 3044/10000, Train Loss: 50.60584848577326, Valid Loss: 52.528185526529946\n","Epoch: 3045/10000, Train Loss: 50.77892095392401, Valid Loss: 52.595532735188804\n","Epoch: 3046/10000, Train Loss: 50.708948308771305, Valid Loss: 52.51608403523763\n","Epoch: 3047/10000, Train Loss: 50.52623679421165, Valid Loss: 52.570963541666664\n","Epoch: 3048/10000, Train Loss: 50.72120423750444, Valid Loss: 52.59953816731771\n","Epoch: 3049/10000, Train Loss: 50.815393621271305, Valid Loss: 52.53418095906576\n","Epoch: 3050/10000, Train Loss: 50.6874604658647, Valid Loss: 52.567142486572266\n","Epoch: 3051/10000, Train Loss: 50.46452678333629, Valid Loss: 52.50835164388021\n","Epoch: 3052/10000, Train Loss: 50.47216242009943, Valid Loss: 52.51369984944662\n","Epoch: 3053/10000, Train Loss: 50.64891884543679, Valid Loss: 52.504870096842446\n","Epoch: 3054/10000, Train Loss: 50.735618591308594, Valid Loss: 52.54413859049479\n","Epoch: 3055/10000, Train Loss: 50.49504228071733, Valid Loss: 52.36077626546224\n","Epoch: 3056/10000, Train Loss: 50.70300709117543, Valid Loss: 52.591653188069664\n","Epoch: 3057/10000, Train Loss: 50.770762010054156, Valid Loss: 52.58247629801432\n","Epoch: 3058/10000, Train Loss: 50.735435485839844, Valid Loss: 52.59175364176432\n","Epoch: 3059/10000, Train Loss: 50.60953799161044, Valid Loss: 52.462273915608726\n","Epoch: 3060/10000, Train Loss: 50.54342061823065, Valid Loss: 52.50116856892904\n","Epoch: 3061/10000, Train Loss: 50.685543753884055, Valid Loss: 52.50747807820638\n","Epoch: 3062/10000, Train Loss: 50.500915180553086, Valid Loss: 52.62835184733073\n","Epoch: 3063/10000, Train Loss: 50.3859696821733, Valid Loss: 52.51568730672201\n","Epoch: 3064/10000, Train Loss: 50.714263916015625, Valid Loss: 52.33759053548177\n","Epoch: 3065/10000, Train Loss: 50.779699845747515, Valid Loss: 52.45812861124674\n","Epoch: 3066/10000, Train Loss: 50.517946069890804, Valid Loss: 52.47868347167969\n","Epoch: 3067/10000, Train Loss: 50.54543547196822, Valid Loss: 52.461928049723305\n","Epoch: 3068/10000, Train Loss: 50.37757388028231, Valid Loss: 52.40717697143555\n","Epoch: 3069/10000, Train Loss: 50.448389920321375, Valid Loss: 52.250719706217446\n","Epoch: 3070/10000, Train Loss: 50.674889998002485, Valid Loss: 52.28450012207031\n","Epoch: 3071/10000, Train Loss: 50.36125287142667, Valid Loss: 52.47077178955078\n","Epoch: 3072/10000, Train Loss: 50.32629186456854, Valid Loss: 52.42349497477213\n","Epoch: 3073/10000, Train Loss: 50.37298306551847, Valid Loss: 52.41915384928385\n","Epoch: 3074/10000, Train Loss: 50.456080350008875, Valid Loss: 52.226234436035156\n","Epoch: 3075/10000, Train Loss: 50.2307902249423, Valid Loss: 52.29467010498047\n","Epoch: 3076/10000, Train Loss: 50.40792049061168, Valid Loss: 52.35834630330404\n","Epoch: 3077/10000, Train Loss: 50.44755831631747, Valid Loss: 52.34358342488607\n","Epoch: 3078/10000, Train Loss: 50.38318529996005, Valid Loss: 52.41911951700846\n","Epoch: 3079/10000, Train Loss: 50.402746720747515, Valid Loss: 52.363016764322914\n","Epoch: 3080/10000, Train Loss: 50.498021212491125, Valid Loss: 52.5380490620931\n","Epoch: 3081/10000, Train Loss: 50.657478679310195, Valid Loss: 52.34957631429037\n","Epoch: 3082/10000, Train Loss: 50.54792369495738, Valid Loss: 52.27779642740885\n","Epoch: 3083/10000, Train Loss: 50.4838322726163, Valid Loss: 52.14443715413412\n","Epoch: 3084/10000, Train Loss: 50.48402890292081, Valid Loss: 52.278499603271484\n","Epoch: 3085/10000, Train Loss: 50.389564514160156, Valid Loss: 52.3423220316569\n","Epoch: 3086/10000, Train Loss: 50.379413257945664, Valid Loss: 52.29680633544922\n","Epoch: 3087/10000, Train Loss: 50.41237120194869, Valid Loss: 52.16142908732096\n","Epoch: 3088/10000, Train Loss: 50.29310711947355, Valid Loss: 52.230943044026695\n","Epoch: 3089/10000, Train Loss: 50.44002949107777, Valid Loss: 52.224297841389976\n","Epoch: 3090/10000, Train Loss: 50.37483388727362, Valid Loss: 52.389930725097656\n","Epoch: 3091/10000, Train Loss: 50.434691342440516, Valid Loss: 52.319618225097656\n","Epoch: 3092/10000, Train Loss: 50.45521614768288, Valid Loss: 52.24071248372396\n","Epoch: 3093/10000, Train Loss: 50.136408372358844, Valid Loss: 52.19806416829427\n","Epoch: 3094/10000, Train Loss: 50.52685061368075, Valid Loss: 52.31333796183268\n","Epoch: 3095/10000, Train Loss: 50.16109952059659, Valid Loss: 52.29057312011719\n","Epoch: 3096/10000, Train Loss: 50.03343755548651, Valid Loss: 52.09648513793945\n","Epoch: 3097/10000, Train Loss: 50.333496440540664, Valid Loss: 52.11860148111979\n","Epoch: 3098/10000, Train Loss: 50.31177798184481, Valid Loss: 52.042413075764976\n","Epoch: 3099/10000, Train Loss: 50.406833995472304, Valid Loss: 52.12813822428385\n","Epoch: 3100/10000, Train Loss: 50.27254590121183, Valid Loss: 52.2473258972168\n","Epoch: 3101/10000, Train Loss: 50.11208066073331, Valid Loss: 52.23050435384115\n","Epoch: 3102/10000, Train Loss: 49.99896829778498, Valid Loss: 52.35707092285156\n","Epoch: 3103/10000, Train Loss: 50.258874373002485, Valid Loss: 52.049661000569664\n","Epoch: 3104/10000, Train Loss: 50.37482660466974, Valid Loss: 52.09594599405924\n","Epoch: 3105/10000, Train Loss: 50.26782781427557, Valid Loss: 52.16284306844076\n","Epoch: 3106/10000, Train Loss: 50.262705369429156, Valid Loss: 52.12154642740885\n","Epoch: 3107/10000, Train Loss: 50.40643518621271, Valid Loss: 52.23727798461914\n","Epoch: 3108/10000, Train Loss: 50.340289029208094, Valid Loss: 52.27599334716797\n","Epoch: 3109/10000, Train Loss: 50.430428591641515, Valid Loss: 52.15436299641927\n","Epoch: 3110/10000, Train Loss: 50.25260127674449, Valid Loss: 52.28834533691406\n","Epoch: 3111/10000, Train Loss: 50.303382179953836, Valid Loss: 52.21677907307943\n","Epoch: 3112/10000, Train Loss: 50.35135685313832, Valid Loss: 52.1427256266276\n","Epoch: 3113/10000, Train Loss: 50.129967429421164, Valid Loss: 52.19049835205078\n","Epoch: 3114/10000, Train Loss: 50.07559793645685, Valid Loss: 51.87384160359701\n","Epoch: 3115/10000, Train Loss: 49.98456573486328, Valid Loss: 51.874612172444664\n","Epoch: 3116/10000, Train Loss: 50.145019878040664, Valid Loss: 52.16790008544922\n","Epoch: 3117/10000, Train Loss: 50.44012867320668, Valid Loss: 52.20468012491862\n","Epoch: 3118/10000, Train Loss: 50.15186448530717, Valid Loss: 52.04092661539713\n","Epoch: 3119/10000, Train Loss: 50.046118996360086, Valid Loss: 52.052258809407554\n","Epoch: 3120/10000, Train Loss: 50.113516027277164, Valid Loss: 52.0332400004069\n","Epoch: 3121/10000, Train Loss: 50.16075064919212, Valid Loss: 52.1922353108724\n","Epoch: 3122/10000, Train Loss: 50.16746937144887, Valid Loss: 52.21800231933594\n","Epoch: 3123/10000, Train Loss: 50.36020278930664, Valid Loss: 52.07719294230143\n","Epoch: 3124/10000, Train Loss: 49.88795783303001, Valid Loss: 52.04455439249674\n","Epoch: 3125/10000, Train Loss: 49.84355649081144, Valid Loss: 51.888624827067055\n","Epoch: 3126/10000, Train Loss: 49.83313612504439, Valid Loss: 51.88854726155599\n","Epoch: 3127/10000, Train Loss: 49.99665832519531, Valid Loss: 51.84943644205729\n","Epoch: 3128/10000, Train Loss: 50.063474134965375, Valid Loss: 51.98382314046224\n","Epoch: 3129/10000, Train Loss: 50.03075755726207, Valid Loss: 52.154378255208336\n","Epoch: 3130/10000, Train Loss: 50.27617783979936, Valid Loss: 52.11661148071289\n","Epoch: 3131/10000, Train Loss: 50.15621011907404, Valid Loss: 52.0426991780599\n","Epoch: 3132/10000, Train Loss: 50.023767644708805, Valid Loss: 51.969984690348305\n","Epoch: 3133/10000, Train Loss: 50.00882408835671, Valid Loss: 52.0891227722168\n","Epoch: 3134/10000, Train Loss: 50.1981086730957, Valid Loss: 52.08416748046875\n","Epoch: 3135/10000, Train Loss: 49.8792558149858, Valid Loss: 51.814796447753906\n","Epoch: 3136/10000, Train Loss: 50.068485953591086, Valid Loss: 51.972390492757164\n","Epoch: 3137/10000, Train Loss: 50.17330412431197, Valid Loss: 51.855377197265625\n","Epoch: 3138/10000, Train Loss: 50.15598990700462, Valid Loss: 51.947705586751304\n","Epoch: 3139/10000, Train Loss: 50.23639124090021, Valid Loss: 51.97214380900065\n","Epoch: 3140/10000, Train Loss: 50.03206391768022, Valid Loss: 52.09931182861328\n","Epoch: 3141/10000, Train Loss: 50.06829487193715, Valid Loss: 52.042154947916664\n","Epoch: 3142/10000, Train Loss: 49.99939380992543, Valid Loss: 51.91700236002604\n","Epoch: 3143/10000, Train Loss: 50.00524832985618, Valid Loss: 51.86860020955404\n","Epoch: 3144/10000, Train Loss: 50.06546263261275, Valid Loss: 51.97875213623047\n","Epoch: 3145/10000, Train Loss: 49.73701442371715, Valid Loss: 51.88850784301758\n","Epoch: 3146/10000, Train Loss: 49.77552344582298, Valid Loss: 51.981066385904946\n","Epoch: 3147/10000, Train Loss: 49.87287521362305, Valid Loss: 51.998549143473305\n","Epoch: 3148/10000, Train Loss: 50.16722419045188, Valid Loss: 52.100982666015625\n","Epoch: 3149/10000, Train Loss: 50.09889290549538, Valid Loss: 51.945028940836586\n","Epoch: 3150/10000, Train Loss: 49.94349566372958, Valid Loss: 51.89917119344076\n","Epoch: 3151/10000, Train Loss: 50.20088195800781, Valid Loss: 51.911546071370445\n","Epoch: 3152/10000, Train Loss: 49.93908413973722, Valid Loss: 51.792168935139976\n","Epoch: 3153/10000, Train Loss: 50.01786492087624, Valid Loss: 51.90492248535156\n","Epoch: 3154/10000, Train Loss: 50.0285231850364, Valid Loss: 52.00600941975912\n","Epoch: 3155/10000, Train Loss: 50.15842576460405, Valid Loss: 51.87194569905599\n","Epoch: 3156/10000, Train Loss: 49.68167357011275, Valid Loss: 51.91878763834635\n","Epoch: 3157/10000, Train Loss: 50.0091587413441, Valid Loss: 51.82774098714193\n","Epoch: 3158/10000, Train Loss: 49.870788921009414, Valid Loss: 51.83645884195963\n","Epoch: 3159/10000, Train Loss: 49.861121437766336, Valid Loss: 51.7801767985026\n","Epoch: 3160/10000, Train Loss: 49.815122777765446, Valid Loss: 51.83385213216146\n","Epoch: 3161/10000, Train Loss: 49.609009135853164, Valid Loss: 51.57695515950521\n","Epoch: 3162/10000, Train Loss: 50.020471052689985, Valid Loss: 51.76873906453451\n","Epoch: 3163/10000, Train Loss: 49.93410977450284, Valid Loss: 51.74211883544922\n","Epoch: 3164/10000, Train Loss: 49.85063448819247, Valid Loss: 51.75122960408529\n","Epoch: 3165/10000, Train Loss: 49.92580899325284, Valid Loss: 51.70828628540039\n","Epoch: 3166/10000, Train Loss: 49.9429518959739, Valid Loss: 51.74704233805338\n","Epoch: 3167/10000, Train Loss: 49.720074046741836, Valid Loss: 51.93202209472656\n","Epoch: 3168/10000, Train Loss: 49.646696610884234, Valid Loss: 51.84168497721354\n","Epoch: 3169/10000, Train Loss: 49.754942807284266, Valid Loss: 51.84572982788086\n","Epoch: 3170/10000, Train Loss: 49.707738702947445, Valid Loss: 51.61881637573242\n","Epoch: 3171/10000, Train Loss: 49.70016306096857, Valid Loss: 51.599222819010414\n","Epoch: 3172/10000, Train Loss: 49.64187864823775, Valid Loss: 51.61329650878906\n","Epoch: 3173/10000, Train Loss: 49.804006056352094, Valid Loss: 51.660621643066406\n","Epoch: 3174/10000, Train Loss: 49.82116283069957, Valid Loss: 51.67079162597656\n","Epoch: 3175/10000, Train Loss: 49.693927418101914, Valid Loss: 51.69373067220052\n","Epoch: 3176/10000, Train Loss: 49.81302191994407, Valid Loss: 51.627251942952476\n","Epoch: 3177/10000, Train Loss: 49.77798080444336, Valid Loss: 51.76681900024414\n","Epoch: 3178/10000, Train Loss: 49.681728016246446, Valid Loss: 51.725354512532554\n","Epoch: 3179/10000, Train Loss: 49.58250669999556, Valid Loss: 51.745619455973305\n","Epoch: 3180/10000, Train Loss: 49.945017381147906, Valid Loss: 51.721126556396484\n","Epoch: 3181/10000, Train Loss: 49.810362035577946, Valid Loss: 51.720526377360024\n","Epoch: 3182/10000, Train Loss: 49.84287366000089, Valid Loss: 51.604871114095054\n","Epoch: 3183/10000, Train Loss: 49.796116222034804, Valid Loss: 51.76867421468099\n","Epoch: 3184/10000, Train Loss: 49.86968924782493, Valid Loss: 51.69267272949219\n","Epoch: 3185/10000, Train Loss: 49.59736390547319, Valid Loss: 51.577527364095054\n","Epoch: 3186/10000, Train Loss: 49.66359121149237, Valid Loss: 51.735703786214195\n","Epoch: 3187/10000, Train Loss: 49.70853805541992, Valid Loss: 51.78590774536133\n","Epoch: 3188/10000, Train Loss: 49.73259180242365, Valid Loss: 51.44922637939453\n","Epoch: 3189/10000, Train Loss: 49.621888940984554, Valid Loss: 51.54357782999674\n","Epoch: 3190/10000, Train Loss: 49.49121024391868, Valid Loss: 51.74138895670573\n","Epoch: 3191/10000, Train Loss: 49.687889792702414, Valid Loss: 51.65836715698242\n","Epoch: 3192/10000, Train Loss: 49.45887929742987, Valid Loss: 51.662940979003906\n","Epoch: 3193/10000, Train Loss: 49.61585894497958, Valid Loss: 51.54251607259115\n","Epoch: 3194/10000, Train Loss: 49.40950879183683, Valid Loss: 51.59048970540365\n","Epoch: 3195/10000, Train Loss: 49.57276916503906, Valid Loss: 51.65058263142904\n","Epoch: 3196/10000, Train Loss: 49.67483832619407, Valid Loss: 51.56647491455078\n","Epoch: 3197/10000, Train Loss: 49.670019669966265, Valid Loss: 51.74636459350586\n","Epoch: 3198/10000, Train Loss: 50.062138990922406, Valid Loss: 51.5944569905599\n","Epoch: 3199/10000, Train Loss: 49.66371397538619, Valid Loss: 51.706459045410156\n","Epoch: 3200/10000, Train Loss: 49.58215956254439, Valid Loss: 51.509193420410156\n","Epoch: 3201/10000, Train Loss: 49.523395191539414, Valid Loss: 51.67231750488281\n","Epoch: 3202/10000, Train Loss: 49.722591400146484, Valid Loss: 51.592882792154946\n","Epoch: 3203/10000, Train Loss: 49.47092645818537, Valid Loss: 51.73053105672201\n","Epoch: 3204/10000, Train Loss: 49.70434431596236, Valid Loss: 51.71783192952474\n","Epoch: 3205/10000, Train Loss: 49.74172453446822, Valid Loss: 51.554569244384766\n","Epoch: 3206/10000, Train Loss: 49.59185062755238, Valid Loss: 51.63082631429037\n","Epoch: 3207/10000, Train Loss: 49.48900951038707, Valid Loss: 51.58619054158529\n","Epoch: 3208/10000, Train Loss: 49.67311581698331, Valid Loss: 51.46558634440104\n","Epoch: 3209/10000, Train Loss: 49.43948953801935, Valid Loss: 51.49219640096029\n","Epoch: 3210/10000, Train Loss: 49.62809337269176, Valid Loss: 51.59222157796224\n","Epoch: 3211/10000, Train Loss: 49.470050464976914, Valid Loss: 51.486610412597656\n","Epoch: 3212/10000, Train Loss: 49.466702894731, Valid Loss: 51.330431620279946\n","Epoch: 3213/10000, Train Loss: 49.60344141179865, Valid Loss: 51.38121541341146\n","Epoch: 3214/10000, Train Loss: 49.7591438293457, Valid Loss: 51.35516866048177\n","Epoch: 3215/10000, Train Loss: 49.272483825683594, Valid Loss: 51.61237589518229\n","Epoch: 3216/10000, Train Loss: 49.529734178022906, Valid Loss: 51.54511388142904\n","Epoch: 3217/10000, Train Loss: 49.63595615733754, Valid Loss: 51.43513107299805\n","Epoch: 3218/10000, Train Loss: 49.61968924782493, Valid Loss: 51.52373504638672\n","Epoch: 3219/10000, Train Loss: 49.36127853393555, Valid Loss: 51.515960693359375\n","Epoch: 3220/10000, Train Loss: 49.62732904607599, Valid Loss: 51.41986083984375\n","Epoch: 3221/10000, Train Loss: 49.76062705300071, Valid Loss: 51.44108454386393\n","Epoch: 3222/10000, Train Loss: 49.442894675514914, Valid Loss: 51.44329961140951\n","Epoch: 3223/10000, Train Loss: 49.40759207985618, Valid Loss: 51.41088994344076\n","Epoch: 3224/10000, Train Loss: 49.38472782481801, Valid Loss: 51.38492329915365\n","Epoch: 3225/10000, Train Loss: 49.44441188465465, Valid Loss: 51.43320083618164\n","Epoch: 3226/10000, Train Loss: 49.3943547335538, Valid Loss: 51.38248062133789\n","Epoch: 3227/10000, Train Loss: 49.24534606933594, Valid Loss: 51.503737131754555\n","Epoch: 3228/10000, Train Loss: 49.26541519165039, Valid Loss: 51.33333969116211\n","Epoch: 3229/10000, Train Loss: 49.25089714743874, Valid Loss: 51.29570388793945\n","Epoch: 3230/10000, Train Loss: 49.47900806773793, Valid Loss: 51.26924133300781\n","Epoch: 3231/10000, Train Loss: 49.43665140325373, Valid Loss: 51.15272776285807\n","Epoch: 3232/10000, Train Loss: 49.2543137290261, Valid Loss: 51.207828521728516\n","Epoch: 3233/10000, Train Loss: 49.57158210060813, Valid Loss: 51.36003875732422\n","Epoch: 3234/10000, Train Loss: 49.27354535189542, Valid Loss: 51.3011728922526\n","Epoch: 3235/10000, Train Loss: 49.332345095547765, Valid Loss: 51.157159169514976\n","Epoch: 3236/10000, Train Loss: 49.38166427612305, Valid Loss: 51.23509216308594\n","Epoch: 3237/10000, Train Loss: 49.465593511408024, Valid Loss: 51.300514221191406\n","Epoch: 3238/10000, Train Loss: 49.46831720525568, Valid Loss: 51.346763610839844\n","Epoch: 3239/10000, Train Loss: 49.52822910655629, Valid Loss: 51.30676015218099\n","Epoch: 3240/10000, Train Loss: 49.355180913751774, Valid Loss: 51.186981201171875\n","Epoch: 3241/10000, Train Loss: 49.25572898171165, Valid Loss: 51.151957194010414\n","Epoch: 3242/10000, Train Loss: 49.12896659157493, Valid Loss: 51.21175638834635\n","Epoch: 3243/10000, Train Loss: 49.2602407282049, Valid Loss: 51.21222813924154\n","Epoch: 3244/10000, Train Loss: 49.52012460882013, Valid Loss: 51.41092046101888\n","Epoch: 3245/10000, Train Loss: 49.18765536221591, Valid Loss: 51.291116078694664\n","Epoch: 3246/10000, Train Loss: 49.1284592368386, Valid Loss: 51.21362431844076\n","Epoch: 3247/10000, Train Loss: 49.19734746759588, Valid Loss: 51.32376607259115\n","Epoch: 3248/10000, Train Loss: 49.349700927734375, Valid Loss: 51.37869135538737\n","Epoch: 3249/10000, Train Loss: 49.34593824906783, Valid Loss: 51.27845128377279\n","Epoch: 3250/10000, Train Loss: 49.23526347767223, Valid Loss: 51.2630615234375\n","Epoch: 3251/10000, Train Loss: 49.055966117165305, Valid Loss: 51.203999837239586\n","Epoch: 3252/10000, Train Loss: 49.30016881769354, Valid Loss: 51.196285247802734\n","Epoch: 3253/10000, Train Loss: 49.33452952991832, Valid Loss: 51.26034800211588\n","Epoch: 3254/10000, Train Loss: 49.24108262495561, Valid Loss: 51.23801040649414\n","Epoch: 3255/10000, Train Loss: 49.18991470336914, Valid Loss: 51.21552022298177\n","Epoch: 3256/10000, Train Loss: 49.10879412564364, Valid Loss: 51.35420481363932\n","Epoch: 3257/10000, Train Loss: 49.08592154762962, Valid Loss: 51.10168711344401\n","Epoch: 3258/10000, Train Loss: 49.26269600608132, Valid Loss: 51.017965952555336\n","Epoch: 3259/10000, Train Loss: 49.22071387551048, Valid Loss: 51.17551930745443\n","Epoch: 3260/10000, Train Loss: 49.302668137983844, Valid Loss: 51.01503372192383\n","Epoch: 3261/10000, Train Loss: 49.17558149857955, Valid Loss: 51.18803405761719\n","Epoch: 3262/10000, Train Loss: 49.06388542868874, Valid Loss: 51.27592086791992\n","Epoch: 3263/10000, Train Loss: 49.20309344204989, Valid Loss: 51.211968739827476\n","Epoch: 3264/10000, Train Loss: 49.281196941028945, Valid Loss: 51.28534444173177\n","Epoch: 3265/10000, Train Loss: 48.95189007845792, Valid Loss: 51.321154276529946\n","Epoch: 3266/10000, Train Loss: 48.96491796320135, Valid Loss: 51.48865763346354\n","Epoch: 3267/10000, Train Loss: 49.26952362060547, Valid Loss: 51.31007512410482\n","Epoch: 3268/10000, Train Loss: 49.25084200772372, Valid Loss: 51.202006022135414\n","Epoch: 3269/10000, Train Loss: 49.09714889526367, Valid Loss: 51.26181666056315\n","Epoch: 3270/10000, Train Loss: 49.15540175004439, Valid Loss: 51.103658040364586\n","Epoch: 3271/10000, Train Loss: 48.86449120261452, Valid Loss: 51.24145380655924\n","Epoch: 3272/10000, Train Loss: 49.16873064908114, Valid Loss: 51.092123667399086\n","Epoch: 3273/10000, Train Loss: 49.062745874578304, Valid Loss: 51.156419118245445\n","Epoch: 3274/10000, Train Loss: 49.02669629183683, Valid Loss: 51.0148811340332\n","Epoch: 3275/10000, Train Loss: 49.11083568226207, Valid Loss: 51.01932017008463\n","Epoch: 3276/10000, Train Loss: 49.207510167902164, Valid Loss: 51.0629628499349\n","Epoch: 3277/10000, Train Loss: 49.217632640491836, Valid Loss: 51.08802159627279\n","Epoch: 3278/10000, Train Loss: 49.04962782426314, Valid Loss: 50.98600769042969\n","Epoch: 3279/10000, Train Loss: 48.856389132413, Valid Loss: 50.97524897257487\n","Epoch: 3280/10000, Train Loss: 49.063656546852805, Valid Loss: 51.05369567871094\n","Epoch: 3281/10000, Train Loss: 49.107491579922765, Valid Loss: 51.161294301350914\n","Epoch: 3282/10000, Train Loss: 49.18647835471413, Valid Loss: 51.005914052327476\n","Epoch: 3283/10000, Train Loss: 49.027274738658555, Valid Loss: 50.97495142618815\n","Epoch: 3284/10000, Train Loss: 48.99429286609996, Valid Loss: 51.24203618367513\n","Epoch: 3285/10000, Train Loss: 49.05736194957387, Valid Loss: 51.138067881266274\n","Epoch: 3286/10000, Train Loss: 49.05352713844993, Valid Loss: 51.05414072672526\n","Epoch: 3287/10000, Train Loss: 48.91015208851207, Valid Loss: 51.07623799641927\n","Epoch: 3288/10000, Train Loss: 49.16999747536399, Valid Loss: 51.150508880615234\n","Epoch: 3289/10000, Train Loss: 49.00583163174716, Valid Loss: 50.93117904663086\n","Epoch: 3290/10000, Train Loss: 48.98135826804421, Valid Loss: 50.85235850016276\n","Epoch: 3291/10000, Train Loss: 49.045995538884945, Valid Loss: 51.14964040120443\n","Epoch: 3292/10000, Train Loss: 48.982692371715196, Valid Loss: 51.02392450968424\n","Epoch: 3293/10000, Train Loss: 48.94679364291105, Valid Loss: 50.835252126057945\n","Epoch: 3294/10000, Train Loss: 48.57112364335494, Valid Loss: 50.84269332885742\n","Epoch: 3295/10000, Train Loss: 48.741672862659804, Valid Loss: 50.92121505737305\n","Epoch: 3296/10000, Train Loss: 49.05879384821112, Valid Loss: 50.93578211466471\n","Epoch: 3297/10000, Train Loss: 48.86681053855202, Valid Loss: 50.988529205322266\n","Epoch: 3298/10000, Train Loss: 48.9898532520641, Valid Loss: 50.769989013671875\n","Epoch: 3299/10000, Train Loss: 48.725072687322445, Valid Loss: 50.946154276529946\n","Epoch: 3300/10000, Train Loss: 48.85833670876243, Valid Loss: 50.896331787109375\n","Epoch: 3301/10000, Train Loss: 48.84908086603338, Valid Loss: 50.75778452555338\n","Epoch: 3302/10000, Train Loss: 49.023771112615414, Valid Loss: 50.961358388264976\n","Epoch: 3303/10000, Train Loss: 48.97993954745206, Valid Loss: 50.830535888671875\n","Epoch: 3304/10000, Train Loss: 49.046648198908024, Valid Loss: 50.80516052246094\n","Epoch: 3305/10000, Train Loss: 48.9947509765625, Valid Loss: 50.71527099609375\n","Epoch: 3306/10000, Train Loss: 48.85617169466886, Valid Loss: 50.83898798624674\n","Epoch: 3307/10000, Train Loss: 49.06855323097923, Valid Loss: 50.74311192830404\n","Epoch: 3308/10000, Train Loss: 49.21170425415039, Valid Loss: 50.773145039876304\n","Epoch: 3309/10000, Train Loss: 49.10161313143644, Valid Loss: 50.90314483642578\n","Epoch: 3310/10000, Train Loss: 48.758758544921875, Valid Loss: 50.87677001953125\n","Epoch: 3311/10000, Train Loss: 48.84316184303977, Valid Loss: 50.86521784464518\n","Epoch: 3312/10000, Train Loss: 48.94450239701705, Valid Loss: 50.899434407552086\n","Epoch: 3313/10000, Train Loss: 48.85121397538619, Valid Loss: 50.86455408732096\n","Epoch: 3314/10000, Train Loss: 48.63224133578214, Valid Loss: 50.782599131266274\n","Epoch: 3315/10000, Train Loss: 48.740142128684305, Valid Loss: 50.79879633585612\n","Epoch: 3316/10000, Train Loss: 49.042810613458805, Valid Loss: 50.812381744384766\n","Epoch: 3317/10000, Train Loss: 48.597600069913, Valid Loss: 50.8614133199056\n","Epoch: 3318/10000, Train Loss: 48.89363063465465, Valid Loss: 50.97616449991862\n","Epoch: 3319/10000, Train Loss: 48.74805415760387, Valid Loss: 50.581939697265625\n","Epoch: 3320/10000, Train Loss: 48.609012603759766, Valid Loss: 50.71503448486328\n","Epoch: 3321/10000, Train Loss: 48.78903475674716, Valid Loss: 50.861288706461586\n","Epoch: 3322/10000, Train Loss: 48.79844180020419, Valid Loss: 50.64394505818685\n","Epoch: 3323/10000, Train Loss: 48.66086092862216, Valid Loss: 50.78716150919596\n","Epoch: 3324/10000, Train Loss: 48.54579960216176, Valid Loss: 50.73234303792318\n","Epoch: 3325/10000, Train Loss: 48.82681101018732, Valid Loss: 50.890602111816406\n","Epoch: 3326/10000, Train Loss: 48.57355707341974, Valid Loss: 50.841225941975914\n","Epoch: 3327/10000, Train Loss: 48.54170088334517, Valid Loss: 50.79833857218424\n","Epoch: 3328/10000, Train Loss: 48.46140393343839, Valid Loss: 50.865299224853516\n","Epoch: 3329/10000, Train Loss: 48.325448122891515, Valid Loss: 50.707252502441406\n","Epoch: 3330/10000, Train Loss: 48.7771391435103, Valid Loss: 50.67230733235677\n","Epoch: 3331/10000, Train Loss: 48.550880432128906, Valid Loss: 50.857470194498696\n","Epoch: 3332/10000, Train Loss: 48.765582691539414, Valid Loss: 50.58708826700846\n","Epoch: 3333/10000, Train Loss: 48.643241535533555, Valid Loss: 50.54209899902344\n","Epoch: 3334/10000, Train Loss: 48.68694478815252, Valid Loss: 50.552834828694664\n","Epoch: 3335/10000, Train Loss: 48.70559241554954, Valid Loss: 50.74789174397787\n","Epoch: 3336/10000, Train Loss: 48.90879024158824, Valid Loss: 50.732102711995445\n","Epoch: 3337/10000, Train Loss: 48.50965777310458, Valid Loss: 50.526652018229164\n","Epoch: 3338/10000, Train Loss: 48.530702417547054, Valid Loss: 50.66799290974935\n","Epoch: 3339/10000, Train Loss: 48.656606847589664, Valid Loss: 50.75113296508789\n","Epoch: 3340/10000, Train Loss: 48.52789098566229, Valid Loss: 50.74217732747396\n","Epoch: 3341/10000, Train Loss: 48.58266344937411, Valid Loss: 50.84968185424805\n","Epoch: 3342/10000, Train Loss: 48.32872009277344, Valid Loss: 50.689388275146484\n","Epoch: 3343/10000, Train Loss: 48.662574074485086, Valid Loss: 50.73799387613932\n","Epoch: 3344/10000, Train Loss: 48.588346307927914, Valid Loss: 50.86700566609701\n","Epoch: 3345/10000, Train Loss: 49.04383919455788, Valid Loss: 50.783260345458984\n","Epoch: 3346/10000, Train Loss: 48.47021623091264, Valid Loss: 50.789740244547524\n","Epoch: 3347/10000, Train Loss: 48.16440825028853, Valid Loss: 50.606458028157554\n","Epoch: 3348/10000, Train Loss: 48.254715312610976, Valid Loss: 50.533799489339195\n","Epoch: 3349/10000, Train Loss: 48.42984841086648, Valid Loss: 50.51158650716146\n","Epoch: 3350/10000, Train Loss: 48.639435508034445, Valid Loss: 50.530128479003906\n","Epoch: 3351/10000, Train Loss: 48.464249004017226, Valid Loss: 50.71796544392904\n","Epoch: 3352/10000, Train Loss: 48.72092784534801, Valid Loss: 50.53165054321289\n","Epoch: 3353/10000, Train Loss: 48.4670576615767, Valid Loss: 50.66094462076823\n","Epoch: 3354/10000, Train Loss: 48.46062053333629, Valid Loss: 50.74947611490885\n","Epoch: 3355/10000, Train Loss: 48.56372902610085, Valid Loss: 50.42322794596354\n","Epoch: 3356/10000, Train Loss: 48.54670958085494, Valid Loss: 50.39227040608724\n","Epoch: 3357/10000, Train Loss: 48.470359802246094, Valid Loss: 50.45495478312174\n","Epoch: 3358/10000, Train Loss: 48.20339792424982, Valid Loss: 50.49700164794922\n","Epoch: 3359/10000, Train Loss: 48.42949052290483, Valid Loss: 50.48465474446615\n","Epoch: 3360/10000, Train Loss: 48.698440898548476, Valid Loss: 50.58786265055338\n","Epoch: 3361/10000, Train Loss: 48.44013942371715, Valid Loss: 50.519046783447266\n","Epoch: 3362/10000, Train Loss: 48.302793676202946, Valid Loss: 50.59840647379557\n","Epoch: 3363/10000, Train Loss: 48.270325747403234, Valid Loss: 50.62353388468424\n","Epoch: 3364/10000, Train Loss: 48.28703446821733, Valid Loss: 50.4185676574707\n","Epoch: 3365/10000, Train Loss: 48.47507511485707, Valid Loss: 50.39718882242838\n","Epoch: 3366/10000, Train Loss: 48.434176011519, Valid Loss: 50.424355824788414\n","Epoch: 3367/10000, Train Loss: 48.281008980490945, Valid Loss: 50.408294677734375\n","Epoch: 3368/10000, Train Loss: 48.59888180819425, Valid Loss: 50.532145182291664\n","Epoch: 3369/10000, Train Loss: 48.14134216308594, Valid Loss: 50.570082346598305\n","Epoch: 3370/10000, Train Loss: 48.44332608309659, Valid Loss: 50.570849100748696\n","Epoch: 3371/10000, Train Loss: 48.627499320290305, Valid Loss: 50.73345438639323\n","Epoch: 3372/10000, Train Loss: 48.27311879938299, Valid Loss: 50.62665685017904\n","Epoch: 3373/10000, Train Loss: 48.53937530517578, Valid Loss: 50.510414123535156\n","Epoch: 3374/10000, Train Loss: 48.6209602355957, Valid Loss: 50.56248346964518\n","Epoch: 3375/10000, Train Loss: 48.5844875682484, Valid Loss: 50.63939539591471\n","Epoch: 3376/10000, Train Loss: 48.36636075106534, Valid Loss: 50.47656377156576\n","Epoch: 3377/10000, Train Loss: 48.253354506059125, Valid Loss: 50.509690602620445\n","Epoch: 3378/10000, Train Loss: 48.420123013583094, Valid Loss: 50.478555043538414\n","Epoch: 3379/10000, Train Loss: 48.06562319668856, Valid Loss: 50.45730209350586\n","Epoch: 3380/10000, Train Loss: 48.42527285489169, Valid Loss: 50.23264821370443\n","Epoch: 3381/10000, Train Loss: 48.422015797008164, Valid Loss: 50.35638300577799\n","Epoch: 3382/10000, Train Loss: 48.09843756935813, Valid Loss: 50.37799326578776\n","Epoch: 3383/10000, Train Loss: 48.68849910389293, Valid Loss: 50.46952438354492\n","Epoch: 3384/10000, Train Loss: 48.230860623446375, Valid Loss: 50.33954874674479\n","Epoch: 3385/10000, Train Loss: 48.31238972056996, Valid Loss: 50.38499323527018\n","Epoch: 3386/10000, Train Loss: 48.318516124378554, Valid Loss: 50.664511362711586\n","Epoch: 3387/10000, Train Loss: 48.13557746193626, Valid Loss: 50.44070561726888\n","Epoch: 3388/10000, Train Loss: 48.37132367220792, Valid Loss: 50.38281377156576\n","Epoch: 3389/10000, Train Loss: 48.21022761951793, Valid Loss: 50.39982604980469\n","Epoch: 3390/10000, Train Loss: 48.267995314164594, Valid Loss: 50.33688990275065\n","Epoch: 3391/10000, Train Loss: 48.196326515891336, Valid Loss: 50.37473169962565\n","Epoch: 3392/10000, Train Loss: 48.464720639315516, Valid Loss: 50.46374638875326\n","Epoch: 3393/10000, Train Loss: 48.36800557916815, Valid Loss: 50.46159235636393\n","Epoch: 3394/10000, Train Loss: 48.41600105979226, Valid Loss: 50.34607950846354\n","Epoch: 3395/10000, Train Loss: 48.09801829944957, Valid Loss: 50.31713104248047\n","Epoch: 3396/10000, Train Loss: 48.35995379361239, Valid Loss: 50.3489875793457\n","Epoch: 3397/10000, Train Loss: 48.292939619584516, Valid Loss: 50.138109842936196\n","Epoch: 3398/10000, Train Loss: 48.06806772405451, Valid Loss: 50.17128245035807\n","Epoch: 3399/10000, Train Loss: 47.993324279785156, Valid Loss: 50.15816879272461\n","Epoch: 3400/10000, Train Loss: 48.221488605846055, Valid Loss: 50.343570709228516\n","Epoch: 3401/10000, Train Loss: 48.27482639659535, Valid Loss: 50.320473988850914\n","Epoch: 3402/10000, Train Loss: 47.93336382779208, Valid Loss: 50.31817754109701\n","Epoch: 3403/10000, Train Loss: 48.2795444835316, Valid Loss: 50.13119379679362\n","Epoch: 3404/10000, Train Loss: 48.19540786743164, Valid Loss: 50.342812856038414\n","Epoch: 3405/10000, Train Loss: 48.23676750876687, Valid Loss: 50.37773768107096\n","Epoch: 3406/10000, Train Loss: 48.25954263860529, Valid Loss: 50.23541514078776\n","Epoch: 3407/10000, Train Loss: 48.529174457896836, Valid Loss: 50.34819030761719\n","Epoch: 3408/10000, Train Loss: 48.05335929177024, Valid Loss: 50.389628092447914\n","Epoch: 3409/10000, Train Loss: 48.21504176746715, Valid Loss: 50.2041867574056\n","Epoch: 3410/10000, Train Loss: 48.129638325084336, Valid Loss: 50.249942779541016\n","Epoch: 3411/10000, Train Loss: 48.12821405584162, Valid Loss: 50.188358306884766\n","Epoch: 3412/10000, Train Loss: 48.08240855823863, Valid Loss: 50.272396087646484\n","Epoch: 3413/10000, Train Loss: 48.32836081764915, Valid Loss: 50.28056081136068\n","Epoch: 3414/10000, Train Loss: 48.20400203358043, Valid Loss: 50.227464040120445\n","Epoch: 3415/10000, Train Loss: 47.94288704612038, Valid Loss: 50.19226964314779\n","Epoch: 3416/10000, Train Loss: 47.89502022483132, Valid Loss: 50.48680114746094\n","Epoch: 3417/10000, Train Loss: 47.99839539961381, Valid Loss: 50.254889170328774\n","Epoch: 3418/10000, Train Loss: 47.86370086669922, Valid Loss: 50.20127868652344\n","Epoch: 3419/10000, Train Loss: 48.21157663518732, Valid Loss: 50.171852111816406\n","Epoch: 3420/10000, Train Loss: 47.922522804953836, Valid Loss: 50.07920583089193\n","Epoch: 3421/10000, Train Loss: 47.95935821533203, Valid Loss: 50.033949534098305\n","Epoch: 3422/10000, Train Loss: 48.11887706409801, Valid Loss: 50.27990595499674\n","Epoch: 3423/10000, Train Loss: 48.30758632313121, Valid Loss: 50.22467041015625\n","Epoch: 3424/10000, Train Loss: 48.158910577947445, Valid Loss: 50.272884368896484\n","Epoch: 3425/10000, Train Loss: 48.001604253595524, Valid Loss: 50.28693771362305\n","Epoch: 3426/10000, Train Loss: 48.31674298373136, Valid Loss: 50.18057378133138\n","Epoch: 3427/10000, Train Loss: 48.3452973799272, Valid Loss: 50.22243626912435\n","Epoch: 3428/10000, Train Loss: 48.47843135486949, Valid Loss: 50.17497634887695\n","Epoch: 3429/10000, Train Loss: 47.75102858109908, Valid Loss: 50.03567377726237\n","Epoch: 3430/10000, Train Loss: 48.10559706254439, Valid Loss: 50.09911982218424\n","Epoch: 3431/10000, Train Loss: 47.91897062821822, Valid Loss: 50.115899403889976\n","Epoch: 3432/10000, Train Loss: 47.75602756847035, Valid Loss: 49.95778147379557\n","Epoch: 3433/10000, Train Loss: 47.71370870416815, Valid Loss: 50.12335332234701\n","Epoch: 3434/10000, Train Loss: 47.82658733021129, Valid Loss: 50.046698252360024\n","Epoch: 3435/10000, Train Loss: 48.04369388927113, Valid Loss: 49.97331110636393\n","Epoch: 3436/10000, Train Loss: 47.6511677828702, Valid Loss: 50.11163075764974\n","Epoch: 3437/10000, Train Loss: 48.123700228604406, Valid Loss: 50.01734415690104\n","Epoch: 3438/10000, Train Loss: 47.94839373501864, Valid Loss: 50.06186294555664\n","Epoch: 3439/10000, Train Loss: 47.79087413441051, Valid Loss: 49.992122650146484\n","Epoch: 3440/10000, Train Loss: 47.78799403797496, Valid Loss: 49.78777058919271\n","Epoch: 3441/10000, Train Loss: 47.917052182284266, Valid Loss: 49.953983306884766\n","Epoch: 3442/10000, Train Loss: 48.09539517489347, Valid Loss: 49.97272618611654\n","Epoch: 3443/10000, Train Loss: 47.81658866188743, Valid Loss: 50.07693608601888\n","Epoch: 3444/10000, Train Loss: 47.89301681518555, Valid Loss: 50.041770935058594\n","Epoch: 3445/10000, Train Loss: 48.08628186312589, Valid Loss: 50.11383056640625\n","Epoch: 3446/10000, Train Loss: 47.9344333301891, Valid Loss: 50.07712427775065\n","Epoch: 3447/10000, Train Loss: 47.95447366887873, Valid Loss: 50.14223861694336\n","Epoch: 3448/10000, Train Loss: 47.99420859596946, Valid Loss: 49.94325510660807\n","Epoch: 3449/10000, Train Loss: 48.07342182506215, Valid Loss: 50.002418518066406\n","Epoch: 3450/10000, Train Loss: 47.756858825683594, Valid Loss: 49.89134979248047\n","Epoch: 3451/10000, Train Loss: 48.0583215193315, Valid Loss: 49.92743047078451\n","Epoch: 3452/10000, Train Loss: 47.765668002041906, Valid Loss: 50.12942632039388\n","Epoch: 3453/10000, Train Loss: 47.72165367820046, Valid Loss: 50.10427602132162\n","Epoch: 3454/10000, Train Loss: 47.720822074196555, Valid Loss: 49.8642209370931\n","Epoch: 3455/10000, Train Loss: 47.80708208951083, Valid Loss: 49.8107795715332\n","Epoch: 3456/10000, Train Loss: 47.77781677246094, Valid Loss: 49.820735931396484\n","Epoch: 3457/10000, Train Loss: 47.77910336581144, Valid Loss: 49.949326833089195\n","Epoch: 3458/10000, Train Loss: 48.17382153597745, Valid Loss: 49.881935119628906\n","Epoch: 3459/10000, Train Loss: 47.59996969049627, Valid Loss: 49.73859659830729\n","Epoch: 3460/10000, Train Loss: 47.63648570667613, Valid Loss: 49.841424306233726\n","Epoch: 3461/10000, Train Loss: 47.77679374001243, Valid Loss: 49.97180938720703\n","Epoch: 3462/10000, Train Loss: 47.96219184181907, Valid Loss: 49.916578928629555\n","Epoch: 3463/10000, Train Loss: 47.90530083396218, Valid Loss: 49.837565104166664\n","Epoch: 3464/10000, Train Loss: 47.726511521772906, Valid Loss: 49.86222712198893\n","Epoch: 3465/10000, Train Loss: 48.044800151478164, Valid Loss: 49.79978688557943\n","Epoch: 3466/10000, Train Loss: 47.91017393632369, Valid Loss: 49.669090270996094\n","Epoch: 3467/10000, Train Loss: 47.61677169799805, Valid Loss: 49.74435170491537\n","Epoch: 3468/10000, Train Loss: 47.43094218860973, Valid Loss: 49.75956471761068\n","Epoch: 3469/10000, Train Loss: 47.945011138916016, Valid Loss: 49.80834452311198\n","Epoch: 3470/10000, Train Loss: 47.57128316705877, Valid Loss: 49.785455067952476\n","Epoch: 3471/10000, Train Loss: 47.437075181440875, Valid Loss: 49.807787577311196\n","Epoch: 3472/10000, Train Loss: 48.049283807927914, Valid Loss: 49.73274612426758\n","Epoch: 3473/10000, Train Loss: 48.014969218860976, Valid Loss: 49.737509409586586\n","Epoch: 3474/10000, Train Loss: 47.769147699529476, Valid Loss: 49.76425806681315\n","Epoch: 3475/10000, Train Loss: 47.822485490278765, Valid Loss: 49.81612014770508\n","Epoch: 3476/10000, Train Loss: 47.671361056241125, Valid Loss: 50.0011838277181\n","Epoch: 3477/10000, Train Loss: 47.71984030983665, Valid Loss: 49.8336296081543\n","Epoch: 3478/10000, Train Loss: 47.641173969615586, Valid Loss: 50.07618077596029\n","Epoch: 3479/10000, Train Loss: 47.61994587291371, Valid Loss: 49.89254887898763\n","Epoch: 3480/10000, Train Loss: 47.6647404757413, Valid Loss: 49.70885213216146\n","Epoch: 3481/10000, Train Loss: 47.836380351673476, Valid Loss: 49.62801742553711\n","Epoch: 3482/10000, Train Loss: 47.93001105568626, Valid Loss: 49.7142079671224\n","Epoch: 3483/10000, Train Loss: 47.536307941783555, Valid Loss: 49.75905100504557\n","Epoch: 3484/10000, Train Loss: 47.58482846346769, Valid Loss: 49.76235707600912\n","Epoch: 3485/10000, Train Loss: 47.46458920565519, Valid Loss: 49.75280634562174\n","Epoch: 3486/10000, Train Loss: 47.551909706809305, Valid Loss: 49.72221120198568\n","Epoch: 3487/10000, Train Loss: 47.85916969992898, Valid Loss: 49.820786794026695\n","Epoch: 3488/10000, Train Loss: 47.48770731145685, Valid Loss: 49.85530217488607\n","Epoch: 3489/10000, Train Loss: 47.50507562810724, Valid Loss: 49.76220830281576\n","Epoch: 3490/10000, Train Loss: 47.33175277709961, Valid Loss: 49.67651621500651\n","Epoch: 3491/10000, Train Loss: 47.658001986416906, Valid Loss: 49.619223276774086\n","Epoch: 3492/10000, Train Loss: 47.59050230546431, Valid Loss: 49.78985595703125\n","Epoch: 3493/10000, Train Loss: 47.61015770652077, Valid Loss: 49.73418426513672\n","Epoch: 3494/10000, Train Loss: 47.22911245172674, Valid Loss: 49.80402119954427\n","Epoch: 3495/10000, Train Loss: 47.759159781716086, Valid Loss: 49.730611165364586\n","Epoch: 3496/10000, Train Loss: 47.43641523881392, Valid Loss: 49.749646504720054\n","Epoch: 3497/10000, Train Loss: 47.343204498291016, Valid Loss: 49.642252604166664\n","Epoch: 3498/10000, Train Loss: 47.36775138161399, Valid Loss: 49.603720347086586\n","Epoch: 3499/10000, Train Loss: 47.30674917047674, Valid Loss: 49.87231190999349\n","Epoch: 3500/10000, Train Loss: 47.73549478704279, Valid Loss: 49.73486836751302\n","Epoch: 3501/10000, Train Loss: 47.31853346391158, Valid Loss: 49.642059326171875\n","Epoch: 3502/10000, Train Loss: 47.663816625421696, Valid Loss: 49.47200393676758\n","Epoch: 3503/10000, Train Loss: 47.471105402166195, Valid Loss: 49.71950149536133\n","Epoch: 3504/10000, Train Loss: 47.689204476096414, Valid Loss: 49.5258903503418\n","Epoch: 3505/10000, Train Loss: 47.54999889026988, Valid Loss: 49.69914881388346\n","Epoch: 3506/10000, Train Loss: 47.21317117864435, Valid Loss: 49.632110595703125\n","Epoch: 3507/10000, Train Loss: 47.58908185091886, Valid Loss: 49.58034642537435\n","Epoch: 3508/10000, Train Loss: 47.35554504394531, Valid Loss: 49.62962849934896\n","Epoch: 3509/10000, Train Loss: 47.17645991932262, Valid Loss: 49.60363006591797\n","Epoch: 3510/10000, Train Loss: 47.53207674893466, Valid Loss: 49.62251281738281\n","Epoch: 3511/10000, Train Loss: 47.39790101484819, Valid Loss: 49.45899327596029\n","Epoch: 3512/10000, Train Loss: 47.399968580766156, Valid Loss: 49.538107554117836\n","Epoch: 3513/10000, Train Loss: 47.69058609008789, Valid Loss: 49.70576477050781\n","Epoch: 3514/10000, Train Loss: 47.321149652654476, Valid Loss: 49.74623998006185\n","Epoch: 3515/10000, Train Loss: 47.28161482377486, Valid Loss: 49.66711298624674\n","Epoch: 3516/10000, Train Loss: 47.45532850785689, Valid Loss: 49.77541859944662\n","Epoch: 3517/10000, Train Loss: 47.66598614779386, Valid Loss: 49.799172719319664\n","Epoch: 3518/10000, Train Loss: 47.475220766934484, Valid Loss: 49.71547063191732\n","Epoch: 3519/10000, Train Loss: 47.58855126120827, Valid Loss: 49.617724100748696\n","Epoch: 3520/10000, Train Loss: 47.28733582930131, Valid Loss: 49.57146072387695\n","Epoch: 3521/10000, Train Loss: 47.68157889626243, Valid Loss: 49.66304143269857\n","Epoch: 3522/10000, Train Loss: 47.67964137684215, Valid Loss: 49.41811752319336\n","Epoch: 3523/10000, Train Loss: 47.53605409102006, Valid Loss: 49.48732121785482\n","Epoch: 3524/10000, Train Loss: 47.30252456665039, Valid Loss: 49.70614878336588\n","Epoch: 3525/10000, Train Loss: 47.3326003334739, Valid Loss: 49.50053278605143\n","Epoch: 3526/10000, Train Loss: 47.43482624400746, Valid Loss: 49.41492462158203\n","Epoch: 3527/10000, Train Loss: 47.282757845791906, Valid Loss: 49.478867848714195\n","Epoch: 3528/10000, Train Loss: 47.37674817171964, Valid Loss: 49.31626764933268\n","Epoch: 3529/10000, Train Loss: 47.36703179099343, Valid Loss: 49.36327870686849\n","Epoch: 3530/10000, Train Loss: 47.241958964954726, Valid Loss: 49.308152516682945\n","Epoch: 3531/10000, Train Loss: 47.283239191228695, Valid Loss: 49.45481618245443\n","Epoch: 3532/10000, Train Loss: 47.36313871903853, Valid Loss: 49.6689821879069\n","Epoch: 3533/10000, Train Loss: 47.31095747514205, Valid Loss: 49.49517567952474\n","Epoch: 3534/10000, Train Loss: 47.17369911887429, Valid Loss: 49.423651377360024\n","Epoch: 3535/10000, Train Loss: 47.475455197420985, Valid Loss: 49.4217529296875\n","Epoch: 3536/10000, Train Loss: 47.306703394109554, Valid Loss: 49.51492055257162\n","Epoch: 3537/10000, Train Loss: 47.044977708296344, Valid Loss: 49.29296366373698\n","Epoch: 3538/10000, Train Loss: 47.255684939297765, Valid Loss: 49.41569137573242\n","Epoch: 3539/10000, Train Loss: 47.33835879239169, Valid Loss: 49.49281692504883\n","Epoch: 3540/10000, Train Loss: 47.55041226473722, Valid Loss: 49.49008433024088\n","Epoch: 3541/10000, Train Loss: 47.2522517117587, Valid Loss: 49.41193517049154\n","Epoch: 3542/10000, Train Loss: 47.17422034523704, Valid Loss: 49.345864613850914\n","Epoch: 3543/10000, Train Loss: 47.117976448752664, Valid Loss: 49.396532694498696\n","Epoch: 3544/10000, Train Loss: 47.06099735606801, Valid Loss: 49.20570627848307\n","Epoch: 3545/10000, Train Loss: 47.07261553677645, Valid Loss: 49.223402659098305\n","Epoch: 3546/10000, Train Loss: 47.406275662508875, Valid Loss: 49.30121994018555\n","Epoch: 3547/10000, Train Loss: 47.1914097179066, Valid Loss: 49.28491973876953\n","Epoch: 3548/10000, Train Loss: 47.142371437766336, Valid Loss: 49.2109260559082\n","Epoch: 3549/10000, Train Loss: 47.152616327459164, Valid Loss: 49.559897104899086\n","Epoch: 3550/10000, Train Loss: 47.25675582885742, Valid Loss: 49.589639027913414\n","Epoch: 3551/10000, Train Loss: 47.183740095658735, Valid Loss: 49.487327575683594\n","Epoch: 3552/10000, Train Loss: 47.347254666415125, Valid Loss: 49.57270940144857\n","Epoch: 3553/10000, Train Loss: 47.13102167302912, Valid Loss: 49.446816762288414\n","Epoch: 3554/10000, Train Loss: 47.10825555974787, Valid Loss: 49.40349451700846\n","Epoch: 3555/10000, Train Loss: 46.930368943647906, Valid Loss: 49.44070816040039\n","Epoch: 3556/10000, Train Loss: 47.304087205366656, Valid Loss: 49.365132649739586\n","Epoch: 3557/10000, Train Loss: 47.05606044422496, Valid Loss: 49.270303090413414\n","Epoch: 3558/10000, Train Loss: 47.07877453890714, Valid Loss: 49.250651041666664\n","Epoch: 3559/10000, Train Loss: 47.402403744784266, Valid Loss: 49.298631032307945\n","Epoch: 3560/10000, Train Loss: 46.93888681585138, Valid Loss: 49.27251180013021\n","Epoch: 3561/10000, Train Loss: 46.754533941095524, Valid Loss: 49.298648834228516\n","Epoch: 3562/10000, Train Loss: 47.071665330366656, Valid Loss: 49.3256721496582\n","Epoch: 3563/10000, Train Loss: 47.26972579956055, Valid Loss: 49.288689931233726\n","Epoch: 3564/10000, Train Loss: 47.19001527266069, Valid Loss: 49.25107065836588\n","Epoch: 3565/10000, Train Loss: 47.03830684315074, Valid Loss: 49.29797108968099\n","Epoch: 3566/10000, Train Loss: 46.85795073075728, Valid Loss: 49.467706044514976\n","Epoch: 3567/10000, Train Loss: 46.98971314863725, Valid Loss: 49.21430587768555\n","Epoch: 3568/10000, Train Loss: 47.07866287231445, Valid Loss: 49.46955871582031\n","Epoch: 3569/10000, Train Loss: 47.03828187422319, Valid Loss: 49.29348882039388\n","Epoch: 3570/10000, Train Loss: 47.04129305752841, Valid Loss: 49.192344665527344\n","Epoch: 3571/10000, Train Loss: 46.94093149358576, Valid Loss: 49.23944981892904\n","Epoch: 3572/10000, Train Loss: 46.95384493741122, Valid Loss: 49.19601313273112\n","Epoch: 3573/10000, Train Loss: 46.98283316872337, Valid Loss: 49.09843317667643\n","Epoch: 3574/10000, Train Loss: 47.1568717956543, Valid Loss: 49.27269744873047\n","Epoch: 3575/10000, Train Loss: 47.07744459672408, Valid Loss: 49.32715733846029\n","Epoch: 3576/10000, Train Loss: 46.70061180808327, Valid Loss: 49.12251281738281\n","Epoch: 3577/10000, Train Loss: 47.092253251509234, Valid Loss: 49.1050910949707\n","Epoch: 3578/10000, Train Loss: 46.74070913141424, Valid Loss: 49.200670878092446\n","Epoch: 3579/10000, Train Loss: 46.999536687677555, Valid Loss: 49.228981018066406\n","Epoch: 3580/10000, Train Loss: 47.073844562877305, Valid Loss: 49.256524403889976\n","Epoch: 3581/10000, Train Loss: 47.025807814164594, Valid Loss: 49.2681884765625\n","Epoch: 3582/10000, Train Loss: 46.74256064675071, Valid Loss: 49.19535446166992\n","Epoch: 3583/10000, Train Loss: 46.86724159934304, Valid Loss: 49.20169321695963\n","Epoch: 3584/10000, Train Loss: 46.82220458984375, Valid Loss: 49.10455830891927\n","Epoch: 3585/10000, Train Loss: 47.09203546697443, Valid Loss: 49.27090326944987\n","Epoch: 3586/10000, Train Loss: 47.184274500066586, Valid Loss: 49.10959116617838\n","Epoch: 3587/10000, Train Loss: 47.05201270363548, Valid Loss: 49.204697926839195\n","Epoch: 3588/10000, Train Loss: 46.9949802051891, Valid Loss: 49.07465362548828\n","Epoch: 3589/10000, Train Loss: 47.02011281793768, Valid Loss: 49.02697499593099\n","Epoch: 3590/10000, Train Loss: 46.67234802246094, Valid Loss: 48.98713938395182\n","Epoch: 3591/10000, Train Loss: 47.01177423650568, Valid Loss: 49.12186177571615\n","Epoch: 3592/10000, Train Loss: 46.98172968084162, Valid Loss: 49.16775258382162\n","Epoch: 3593/10000, Train Loss: 46.47347675670277, Valid Loss: 49.30132548014323\n","Epoch: 3594/10000, Train Loss: 46.566144076260656, Valid Loss: 49.338356018066406\n","Epoch: 3595/10000, Train Loss: 47.03175666115501, Valid Loss: 49.08618036905924\n","Epoch: 3596/10000, Train Loss: 46.814848466352984, Valid Loss: 49.107513427734375\n","Epoch: 3597/10000, Train Loss: 46.68662331321023, Valid Loss: 48.947767893473305\n","Epoch: 3598/10000, Train Loss: 46.6634687943892, Valid Loss: 48.84427388509115\n","Epoch: 3599/10000, Train Loss: 46.6852746443315, Valid Loss: 48.93911870320638\n","Epoch: 3600/10000, Train Loss: 46.870913765647195, Valid Loss: 49.03750356038412\n","Epoch: 3601/10000, Train Loss: 46.67847442626953, Valid Loss: 49.088486989339195\n","Epoch: 3602/10000, Train Loss: 46.83668622103605, Valid Loss: 49.114976247151695\n","Epoch: 3603/10000, Train Loss: 46.47337410666726, Valid Loss: 49.14951833089193\n","Epoch: 3604/10000, Train Loss: 46.364029277454726, Valid Loss: 48.88649368286133\n","Epoch: 3605/10000, Train Loss: 46.51792422207919, Valid Loss: 48.9086659749349\n","Epoch: 3606/10000, Train Loss: 46.5707876032049, Valid Loss: 48.90201059977213\n","Epoch: 3607/10000, Train Loss: 46.84033757990057, Valid Loss: 48.96465937296549\n","Epoch: 3608/10000, Train Loss: 47.057837746360086, Valid Loss: 48.90176900227865\n","Epoch: 3609/10000, Train Loss: 46.872665058482774, Valid Loss: 48.90198262532552\n","Epoch: 3610/10000, Train Loss: 46.46839003129439, Valid Loss: 49.037803649902344\n","Epoch: 3611/10000, Train Loss: 46.73922764171254, Valid Loss: 49.04708607991537\n","Epoch: 3612/10000, Train Loss: 46.646483334628016, Valid Loss: 49.149847666422524\n","Epoch: 3613/10000, Train Loss: 46.716120286421344, Valid Loss: 48.96218999226888\n","Epoch: 3614/10000, Train Loss: 46.82069986516779, Valid Loss: 49.05030822753906\n","Epoch: 3615/10000, Train Loss: 46.47855481234464, Valid Loss: 49.057501475016274\n","Epoch: 3616/10000, Train Loss: 46.61890480735085, Valid Loss: 49.176900227864586\n","Epoch: 3617/10000, Train Loss: 46.401717792857774, Valid Loss: 49.061074574788414\n","Epoch: 3618/10000, Train Loss: 46.81304931640625, Valid Loss: 48.87717310587565\n","Epoch: 3619/10000, Train Loss: 46.70423438332298, Valid Loss: 48.85237375895182\n","Epoch: 3620/10000, Train Loss: 46.65685133500533, Valid Loss: 48.69013341267904\n","Epoch: 3621/10000, Train Loss: 46.862199956720524, Valid Loss: 48.87145741780599\n","Epoch: 3622/10000, Train Loss: 46.9294679815119, Valid Loss: 48.9431037902832\n","Epoch: 3623/10000, Train Loss: 46.74596474387429, Valid Loss: 48.81442387898763\n","Epoch: 3624/10000, Train Loss: 46.52829846468839, Valid Loss: 48.81216812133789\n","Epoch: 3625/10000, Train Loss: 46.90061950683594, Valid Loss: 48.90868886311849\n","Epoch: 3626/10000, Train Loss: 46.65430173006925, Valid Loss: 48.8624267578125\n","Epoch: 3627/10000, Train Loss: 46.89243975552645, Valid Loss: 48.77997716267904\n","Epoch: 3628/10000, Train Loss: 46.743989424272016, Valid Loss: 48.94141515096029\n","Epoch: 3629/10000, Train Loss: 46.17786234075373, Valid Loss: 48.843823750813804\n","Epoch: 3630/10000, Train Loss: 46.669612190940164, Valid Loss: 48.97609074910482\n","Epoch: 3631/10000, Train Loss: 46.56479159268466, Valid Loss: 49.06298319498698\n","Epoch: 3632/10000, Train Loss: 46.77083136818626, Valid Loss: 48.92593892415365\n","Epoch: 3633/10000, Train Loss: 46.518544630570844, Valid Loss: 48.87479909261068\n","Epoch: 3634/10000, Train Loss: 46.60364532470703, Valid Loss: 48.88773854573568\n","Epoch: 3635/10000, Train Loss: 46.54481228915128, Valid Loss: 48.919944763183594\n","Epoch: 3636/10000, Train Loss: 46.60391408746893, Valid Loss: 48.75819651285807\n","Epoch: 3637/10000, Train Loss: 46.68298270485618, Valid Loss: 48.765069325764976\n","Epoch: 3638/10000, Train Loss: 46.63142290982333, Valid Loss: 48.86187871297201\n","Epoch: 3639/10000, Train Loss: 46.57150545987216, Valid Loss: 48.81787999471029\n","Epoch: 3640/10000, Train Loss: 46.60741077769887, Valid Loss: 48.92717488606771\n","Epoch: 3641/10000, Train Loss: 46.470423611727625, Valid Loss: 48.828731536865234\n","Epoch: 3642/10000, Train Loss: 46.73671687733043, Valid Loss: 48.69119644165039\n","Epoch: 3643/10000, Train Loss: 46.2400446805087, Valid Loss: 48.70499928792318\n","Epoch: 3644/10000, Train Loss: 46.63340863314542, Valid Loss: 48.61390686035156\n","Epoch: 3645/10000, Train Loss: 46.35302040793679, Valid Loss: 48.799261728922524\n","Epoch: 3646/10000, Train Loss: 46.855495106090196, Valid Loss: 48.885518391927086\n","Epoch: 3647/10000, Train Loss: 46.673517747358844, Valid Loss: 48.767592112223305\n","Epoch: 3648/10000, Train Loss: 46.413602655584164, Valid Loss: 48.68256378173828\n","Epoch: 3649/10000, Train Loss: 46.40858840942383, Valid Loss: 48.684956868489586\n","Epoch: 3650/10000, Train Loss: 46.46294888583097, Valid Loss: 49.05420684814453\n","Epoch: 3651/10000, Train Loss: 46.21256325461648, Valid Loss: 48.90890121459961\n","Epoch: 3652/10000, Train Loss: 46.25688795609908, Valid Loss: 48.88166300455729\n","Epoch: 3653/10000, Train Loss: 46.42710460316051, Valid Loss: 49.00186538696289\n","Epoch: 3654/10000, Train Loss: 46.54713890769265, Valid Loss: 48.78628794352213\n","Epoch: 3655/10000, Train Loss: 46.45825750177557, Valid Loss: 48.829644521077476\n","Epoch: 3656/10000, Train Loss: 46.26984786987305, Valid Loss: 48.59901682535807\n","Epoch: 3657/10000, Train Loss: 46.598502072420985, Valid Loss: 48.49483871459961\n","Epoch: 3658/10000, Train Loss: 46.448095841841265, Valid Loss: 48.59191131591797\n","Epoch: 3659/10000, Train Loss: 46.43539463390004, Valid Loss: 48.652472178141274\n","Epoch: 3660/10000, Train Loss: 46.43013936823065, Valid Loss: 48.58569081624349\n","Epoch: 3661/10000, Train Loss: 46.14934747869318, Valid Loss: 48.51178741455078\n","Epoch: 3662/10000, Train Loss: 46.44958288019354, Valid Loss: 48.535404205322266\n","Epoch: 3663/10000, Train Loss: 46.03222517533736, Valid Loss: 48.64176559448242\n","Epoch: 3664/10000, Train Loss: 46.27098222212358, Valid Loss: 48.54910659790039\n","Epoch: 3665/10000, Train Loss: 46.38287145441229, Valid Loss: 48.54720687866211\n","Epoch: 3666/10000, Train Loss: 46.407643751664594, Valid Loss: 48.53588740030924\n","Epoch: 3667/10000, Train Loss: 46.49787556041371, Valid Loss: 48.58711624145508\n","Epoch: 3668/10000, Train Loss: 46.01299702037465, Valid Loss: 48.55980936686198\n","Epoch: 3669/10000, Train Loss: 46.44311107288707, Valid Loss: 48.78323109944662\n","Epoch: 3670/10000, Train Loss: 46.2795691056685, Valid Loss: 48.48823928833008\n","Epoch: 3671/10000, Train Loss: 46.34186207164418, Valid Loss: 48.52021026611328\n","Epoch: 3672/10000, Train Loss: 45.993189725008875, Valid Loss: 48.5232187906901\n","Epoch: 3673/10000, Train Loss: 46.5364015752619, Valid Loss: 48.440497080485024\n","Epoch: 3674/10000, Train Loss: 46.62344741821289, Valid Loss: 48.54224141438802\n","Epoch: 3675/10000, Train Loss: 46.38679157603871, Valid Loss: 48.57157770792643\n","Epoch: 3676/10000, Train Loss: 45.90848922729492, Valid Loss: 48.66168085734049\n","Epoch: 3677/10000, Train Loss: 46.46338480169123, Valid Loss: 48.467613220214844\n","Epoch: 3678/10000, Train Loss: 46.31853623823686, Valid Loss: 48.54054387410482\n","Epoch: 3679/10000, Train Loss: 46.279236186634414, Valid Loss: 48.56336339314779\n","Epoch: 3680/10000, Train Loss: 46.29638879949396, Valid Loss: 48.61298370361328\n","Epoch: 3681/10000, Train Loss: 46.42864782159979, Valid Loss: 48.54580307006836\n","Epoch: 3682/10000, Train Loss: 46.23682056773793, Valid Loss: 48.35285186767578\n","Epoch: 3683/10000, Train Loss: 46.383270957253195, Valid Loss: 48.413597106933594\n","Epoch: 3684/10000, Train Loss: 46.37815787575462, Valid Loss: 48.497920989990234\n","Epoch: 3685/10000, Train Loss: 46.23653585260565, Valid Loss: 48.38895161946615\n","Epoch: 3686/10000, Train Loss: 45.96892200816762, Valid Loss: 48.570977528889976\n","Epoch: 3687/10000, Train Loss: 45.90075059370561, Valid Loss: 48.61039606730143\n","Epoch: 3688/10000, Train Loss: 46.17228698730469, Valid Loss: 48.57513682047526\n","Epoch: 3689/10000, Train Loss: 46.174870230934836, Valid Loss: 48.28969701131185\n","Epoch: 3690/10000, Train Loss: 46.33882106434215, Valid Loss: 48.43585332234701\n","Epoch: 3691/10000, Train Loss: 46.152727300470524, Valid Loss: 48.444079081217446\n","Epoch: 3692/10000, Train Loss: 46.22979008067738, Valid Loss: 48.37797292073568\n","Epoch: 3693/10000, Train Loss: 46.12055761163885, Valid Loss: 48.47186406453451\n","Epoch: 3694/10000, Train Loss: 46.24184383045543, Valid Loss: 48.543646494547524\n","Epoch: 3695/10000, Train Loss: 46.17498571222479, Valid Loss: 48.22945658365885\n","Epoch: 3696/10000, Train Loss: 45.8927678194913, Valid Loss: 48.331320444742836\n","Epoch: 3697/10000, Train Loss: 46.21901494806463, Valid Loss: 48.53661092122396\n","Epoch: 3698/10000, Train Loss: 46.33469668301669, Valid Loss: 48.316880544026695\n","Epoch: 3699/10000, Train Loss: 45.92712263627486, Valid Loss: 48.3076540629069\n","Epoch: 3700/10000, Train Loss: 46.00021396983754, Valid Loss: 48.34073257446289\n","Epoch: 3701/10000, Train Loss: 46.09845040061257, Valid Loss: 48.477883656819664\n","Epoch: 3702/10000, Train Loss: 46.26955379139293, Valid Loss: 48.133792877197266\n","Epoch: 3703/10000, Train Loss: 45.99202346801758, Valid Loss: 48.116930643717446\n","Epoch: 3704/10000, Train Loss: 46.169466192072086, Valid Loss: 48.28284200032552\n","Epoch: 3705/10000, Train Loss: 45.83346939086914, Valid Loss: 48.450008392333984\n","Epoch: 3706/10000, Train Loss: 45.984854611483485, Valid Loss: 48.43449783325195\n","Epoch: 3707/10000, Train Loss: 46.056542830033735, Valid Loss: 48.37905502319336\n","Epoch: 3708/10000, Train Loss: 46.246496720747515, Valid Loss: 48.41116205851237\n","Epoch: 3709/10000, Train Loss: 46.23377123746005, Valid Loss: 48.368896484375\n","Epoch: 3710/10000, Train Loss: 46.09187871759588, Valid Loss: 48.25569407145182\n","Epoch: 3711/10000, Train Loss: 46.16569519042969, Valid Loss: 48.349603017171226\n","Epoch: 3712/10000, Train Loss: 46.08369965986772, Valid Loss: 48.2635612487793\n","Epoch: 3713/10000, Train Loss: 45.7975002635609, Valid Loss: 48.28440856933594\n","Epoch: 3714/10000, Train Loss: 46.0127497586337, Valid Loss: 48.37109883626302\n","Epoch: 3715/10000, Train Loss: 46.00691465897994, Valid Loss: 48.466931660970054\n","Epoch: 3716/10000, Train Loss: 45.86964659257369, Valid Loss: 48.420467376708984\n","Epoch: 3717/10000, Train Loss: 46.04330964521928, Valid Loss: 48.571163177490234\n","Epoch: 3718/10000, Train Loss: 46.01043354381215, Valid Loss: 48.246585845947266\n","Epoch: 3719/10000, Train Loss: 46.364310177889735, Valid Loss: 48.2662099202474\n","Epoch: 3720/10000, Train Loss: 45.557614759965375, Valid Loss: 48.36658477783203\n","Epoch: 3721/10000, Train Loss: 45.96252510764382, Valid Loss: 48.23553466796875\n","Epoch: 3722/10000, Train Loss: 46.26708082719283, Valid Loss: 48.09374872843424\n","Epoch: 3723/10000, Train Loss: 46.052804079922765, Valid Loss: 48.18642934163412\n","Epoch: 3724/10000, Train Loss: 45.97138977050781, Valid Loss: 48.22671254475912\n","Epoch: 3725/10000, Train Loss: 45.749058810147375, Valid Loss: 48.23407872517904\n","Epoch: 3726/10000, Train Loss: 45.844560796564274, Valid Loss: 48.27364985148112\n","Epoch: 3727/10000, Train Loss: 45.78958962180398, Valid Loss: 48.28331629435221\n","Epoch: 3728/10000, Train Loss: 45.80188820578835, Valid Loss: 48.24375534057617\n","Epoch: 3729/10000, Train Loss: 46.06420621004972, Valid Loss: 48.19381332397461\n","Epoch: 3730/10000, Train Loss: 46.19553548639471, Valid Loss: 48.10472615559896\n","Epoch: 3731/10000, Train Loss: 45.76111810857599, Valid Loss: 48.09254837036133\n","Epoch: 3732/10000, Train Loss: 45.91273984042081, Valid Loss: 48.12988789876302\n","Epoch: 3733/10000, Train Loss: 45.752905412153765, Valid Loss: 48.17456944783529\n","Epoch: 3734/10000, Train Loss: 45.88332262906161, Valid Loss: 48.268304189046226\n","Epoch: 3735/10000, Train Loss: 45.898129203102805, Valid Loss: 48.312460581461586\n","Epoch: 3736/10000, Train Loss: 45.50433280251243, Valid Loss: 48.11607233683268\n","Epoch: 3737/10000, Train Loss: 46.02490893277255, Valid Loss: 48.0251350402832\n","Epoch: 3738/10000, Train Loss: 45.60453727028587, Valid Loss: 48.271629333496094\n","Epoch: 3739/10000, Train Loss: 45.97630622170188, Valid Loss: 48.073281606038414\n","Epoch: 3740/10000, Train Loss: 45.96289790760387, Valid Loss: 48.1971181233724\n","Epoch: 3741/10000, Train Loss: 45.70534341985529, Valid Loss: 48.14869689941406\n","Epoch: 3742/10000, Train Loss: 45.68381534923207, Valid Loss: 47.983411153157554\n","Epoch: 3743/10000, Train Loss: 45.89877041903409, Valid Loss: 48.07468032836914\n","Epoch: 3744/10000, Train Loss: 45.528371290727094, Valid Loss: 48.12213897705078\n","Epoch: 3745/10000, Train Loss: 45.72381661155007, Valid Loss: 48.22700119018555\n","Epoch: 3746/10000, Train Loss: 46.00925653631037, Valid Loss: 48.10905965169271\n","Epoch: 3747/10000, Train Loss: 45.84694463556463, Valid Loss: 48.273932139078774\n","Epoch: 3748/10000, Train Loss: 45.77061566439542, Valid Loss: 48.024237314860024\n","Epoch: 3749/10000, Train Loss: 45.778111544522375, Valid Loss: 48.04502614339193\n","Epoch: 3750/10000, Train Loss: 46.004735773259945, Valid Loss: 48.04540252685547\n","Epoch: 3751/10000, Train Loss: 45.73081727461381, Valid Loss: 48.13377126057943\n","Epoch: 3752/10000, Train Loss: 45.85435312444513, Valid Loss: 48.222113291422524\n","Epoch: 3753/10000, Train Loss: 45.93444269353693, Valid Loss: 47.94399388631185\n","Epoch: 3754/10000, Train Loss: 45.73023674704812, Valid Loss: 48.01194763183594\n","Epoch: 3755/10000, Train Loss: 45.7180571122603, Valid Loss: 48.17901738484701\n","Epoch: 3756/10000, Train Loss: 45.219553513960406, Valid Loss: 48.0026969909668\n","Epoch: 3757/10000, Train Loss: 45.37164445356889, Valid Loss: 48.04151407877604\n","Epoch: 3758/10000, Train Loss: 45.47921302101829, Valid Loss: 48.001694997151695\n","Epoch: 3759/10000, Train Loss: 45.79863045432351, Valid Loss: 48.22494888305664\n","Epoch: 3760/10000, Train Loss: 45.60034942626953, Valid Loss: 48.136383056640625\n","Epoch: 3761/10000, Train Loss: 45.678424488414414, Valid Loss: 48.104323069254555\n","Epoch: 3762/10000, Train Loss: 45.689243663441054, Valid Loss: 47.93320973714193\n","Epoch: 3763/10000, Train Loss: 45.70655129172585, Valid Loss: 47.95943959554037\n","Epoch: 3764/10000, Train Loss: 45.805449745871805, Valid Loss: 47.938088734944664\n","Epoch: 3765/10000, Train Loss: 45.870271162553266, Valid Loss: 47.8035634358724\n","Epoch: 3766/10000, Train Loss: 45.93471908569336, Valid Loss: 47.9790293375651\n","Epoch: 3767/10000, Train Loss: 45.5758302861994, Valid Loss: 47.87675476074219\n","Epoch: 3768/10000, Train Loss: 45.415508617054336, Valid Loss: 47.940975189208984\n","Epoch: 3769/10000, Train Loss: 45.45697576349432, Valid Loss: 48.099047342936196\n","Epoch: 3770/10000, Train Loss: 45.337412400679156, Valid Loss: 47.875413258870445\n","Epoch: 3771/10000, Train Loss: 45.952862132679336, Valid Loss: 47.99519475301107\n","Epoch: 3772/10000, Train Loss: 45.499116377397016, Valid Loss: 48.07083384195963\n","Epoch: 3773/10000, Train Loss: 45.21138659390536, Valid Loss: 47.886636098225914\n","Epoch: 3774/10000, Train Loss: 45.62538042935458, Valid Loss: 47.97759501139323\n","Epoch: 3775/10000, Train Loss: 45.60237919200551, Valid Loss: 47.75945027669271\n","Epoch: 3776/10000, Train Loss: 45.703697898171164, Valid Loss: 47.88828786214193\n","Epoch: 3777/10000, Train Loss: 45.60592061823065, Valid Loss: 47.979713439941406\n","Epoch: 3778/10000, Train Loss: 45.33159498734908, Valid Loss: 48.15439478556315\n","Epoch: 3779/10000, Train Loss: 45.54020760276101, Valid Loss: 47.94690068562826\n","Epoch: 3780/10000, Train Loss: 45.37127685546875, Valid Loss: 47.855552673339844\n","Epoch: 3781/10000, Train Loss: 45.7050236788663, Valid Loss: 47.81412251790365\n","Epoch: 3782/10000, Train Loss: 45.74844811179421, Valid Loss: 47.972900390625\n","Epoch: 3783/10000, Train Loss: 45.545472231778234, Valid Loss: 47.92914072672526\n","Epoch: 3784/10000, Train Loss: 45.07586947354403, Valid Loss: 47.95771280924479\n","Epoch: 3785/10000, Train Loss: 45.79884234341708, Valid Loss: 47.818224589029946\n","Epoch: 3786/10000, Train Loss: 45.51264537464488, Valid Loss: 47.928656260172524\n","Epoch: 3787/10000, Train Loss: 45.39108449762518, Valid Loss: 48.02561950683594\n","Epoch: 3788/10000, Train Loss: 45.51928294788707, Valid Loss: 47.81941350301107\n","Epoch: 3789/10000, Train Loss: 45.5696608803489, Valid Loss: 47.88210805257162\n","Epoch: 3790/10000, Train Loss: 45.43376229026101, Valid Loss: 47.711447397867836\n","Epoch: 3791/10000, Train Loss: 45.36858159845526, Valid Loss: 47.76775868733724\n","Epoch: 3792/10000, Train Loss: 45.49984012950551, Valid Loss: 47.78130213419596\n","Epoch: 3793/10000, Train Loss: 45.65294196388938, Valid Loss: 47.9634755452474\n","Epoch: 3794/10000, Train Loss: 45.37434283169833, Valid Loss: 47.90015411376953\n","Epoch: 3795/10000, Train Loss: 45.689889734441586, Valid Loss: 47.92747116088867\n","Epoch: 3796/10000, Train Loss: 45.39344891634855, Valid Loss: 47.966199239095054\n","Epoch: 3797/10000, Train Loss: 45.2504470131614, Valid Loss: 47.842611948649086\n","Epoch: 3798/10000, Train Loss: 45.6538533297452, Valid Loss: 47.76697667439779\n","Epoch: 3799/10000, Train Loss: 45.37498057972301, Valid Loss: 47.78398768107096\n","Epoch: 3800/10000, Train Loss: 45.454012090509586, Valid Loss: 47.765218098958336\n","Epoch: 3801/10000, Train Loss: 45.197847886519, Valid Loss: 47.61960093180338\n","Epoch: 3802/10000, Train Loss: 45.70681936090643, Valid Loss: 47.50314458211263\n","Epoch: 3803/10000, Train Loss: 45.457467165860265, Valid Loss: 47.64783732096354\n","Epoch: 3804/10000, Train Loss: 45.58424308083274, Valid Loss: 47.58114878336588\n","Epoch: 3805/10000, Train Loss: 45.57607026533647, Valid Loss: 47.76234436035156\n","Epoch: 3806/10000, Train Loss: 45.2815995649858, Valid Loss: 47.754835764567055\n","Epoch: 3807/10000, Train Loss: 45.79700469970703, Valid Loss: 47.76059214274088\n","Epoch: 3808/10000, Train Loss: 45.51802548495206, Valid Loss: 47.765210469563804\n","Epoch: 3809/10000, Train Loss: 45.201421217484906, Valid Loss: 47.71642939249674\n","Epoch: 3810/10000, Train Loss: 45.08705069802024, Valid Loss: 47.7949104309082\n","Epoch: 3811/10000, Train Loss: 44.97831309925426, Valid Loss: 47.72773361206055\n","Epoch: 3812/10000, Train Loss: 45.48142346468839, Valid Loss: 47.814571380615234\n","Epoch: 3813/10000, Train Loss: 45.52757505937056, Valid Loss: 47.77418518066406\n","Epoch: 3814/10000, Train Loss: 45.4197058244185, Valid Loss: 47.697059631347656\n","Epoch: 3815/10000, Train Loss: 45.4665079983798, Valid Loss: 47.704934438069664\n","Epoch: 3816/10000, Train Loss: 45.173103679310195, Valid Loss: 47.62089411417643\n","Epoch: 3817/10000, Train Loss: 45.20207353071733, Valid Loss: 47.62712478637695\n","Epoch: 3818/10000, Train Loss: 45.10431809858842, Valid Loss: 47.744893391927086\n","Epoch: 3819/10000, Train Loss: 45.326107718727805, Valid Loss: 47.78850809733073\n","Epoch: 3820/10000, Train Loss: 45.43354346535423, Valid Loss: 47.702351888020836\n","Epoch: 3821/10000, Train Loss: 45.18076463179155, Valid Loss: 47.65235900878906\n","Epoch: 3822/10000, Train Loss: 45.24616033380682, Valid Loss: 47.471787770589195\n","Epoch: 3823/10000, Train Loss: 45.60698422518644, Valid Loss: 47.55665079752604\n","Epoch: 3824/10000, Train Loss: 45.06503330577504, Valid Loss: 47.534722646077476\n","Epoch: 3825/10000, Train Loss: 45.38902733542702, Valid Loss: 47.544203440348305\n","Epoch: 3826/10000, Train Loss: 44.84322287819602, Valid Loss: 47.68165842692057\n","Epoch: 3827/10000, Train Loss: 45.26940189708363, Valid Loss: 47.5502675374349\n","Epoch: 3828/10000, Train Loss: 45.308712005615234, Valid Loss: 47.47584915161133\n","Epoch: 3829/10000, Train Loss: 45.03245371038263, Valid Loss: 47.671034495035805\n","Epoch: 3830/10000, Train Loss: 45.18547127463601, Valid Loss: 47.668200174967446\n","Epoch: 3831/10000, Train Loss: 44.973567962646484, Valid Loss: 47.60527674357096\n","Epoch: 3832/10000, Train Loss: 45.301725907759234, Valid Loss: 47.46408335367838\n","Epoch: 3833/10000, Train Loss: 45.137896451083094, Valid Loss: 47.365613301595054\n","Epoch: 3834/10000, Train Loss: 44.91452303799716, Valid Loss: 47.489793141682945\n","Epoch: 3835/10000, Train Loss: 45.21190227161754, Valid Loss: 47.763075510660805\n","Epoch: 3836/10000, Train Loss: 44.75051220980558, Valid Loss: 47.64049402872721\n","Epoch: 3837/10000, Train Loss: 45.10835994373668, Valid Loss: 47.452020009358726\n","Epoch: 3838/10000, Train Loss: 44.988894029097125, Valid Loss: 47.36386362711588\n","Epoch: 3839/10000, Train Loss: 45.187204187566586, Valid Loss: 47.47235361735026\n","Epoch: 3840/10000, Train Loss: 45.05953736738725, Valid Loss: 47.52143987019857\n","Epoch: 3841/10000, Train Loss: 45.12254333496094, Valid Loss: 47.52951176961263\n","Epoch: 3842/10000, Train Loss: 45.2387001731179, Valid Loss: 47.49535115559896\n","Epoch: 3843/10000, Train Loss: 44.88594748757102, Valid Loss: 47.387674967447914\n","Epoch: 3844/10000, Train Loss: 45.05141899802468, Valid Loss: 47.502237955729164\n","Epoch: 3845/10000, Train Loss: 45.34807239879262, Valid Loss: 47.56744893391927\n","Epoch: 3846/10000, Train Loss: 45.113501115278765, Valid Loss: 47.64259338378906\n","Epoch: 3847/10000, Train Loss: 45.51945911754262, Valid Loss: 47.494876861572266\n","Epoch: 3848/10000, Train Loss: 45.11438473788175, Valid Loss: 47.61108271280924\n","Epoch: 3849/10000, Train Loss: 44.70072937011719, Valid Loss: 47.326611836751304\n","Epoch: 3850/10000, Train Loss: 44.80801773071289, Valid Loss: 47.43272145589193\n","Epoch: 3851/10000, Train Loss: 44.963986136696555, Valid Loss: 47.633253733317055\n","Epoch: 3852/10000, Train Loss: 45.17506859519265, Valid Loss: 47.443233489990234\n","Epoch: 3853/10000, Train Loss: 45.02195288918235, Valid Loss: 47.42891057332357\n","Epoch: 3854/10000, Train Loss: 45.07455895163796, Valid Loss: 47.284112294514976\n","Epoch: 3855/10000, Train Loss: 45.35152955488725, Valid Loss: 47.46708679199219\n","Epoch: 3856/10000, Train Loss: 45.25025801225142, Valid Loss: 47.575416564941406\n","Epoch: 3857/10000, Train Loss: 45.027191162109375, Valid Loss: 47.317718505859375\n","Epoch: 3858/10000, Train Loss: 45.054888638583094, Valid Loss: 47.3731320699056\n","Epoch: 3859/10000, Train Loss: 44.855223569003016, Valid Loss: 47.35136159261068\n","Epoch: 3860/10000, Train Loss: 44.992023121226914, Valid Loss: 47.373853047688804\n","Epoch: 3861/10000, Train Loss: 44.90530499545011, Valid Loss: 47.30483373006185\n","Epoch: 3862/10000, Train Loss: 44.95362299138849, Valid Loss: 47.265342712402344\n","Epoch: 3863/10000, Train Loss: 44.97859920154918, Valid Loss: 47.507527669270836\n","Epoch: 3864/10000, Train Loss: 45.09241901744496, Valid Loss: 47.32565943400065\n","Epoch: 3865/10000, Train Loss: 44.92408440329812, Valid Loss: 47.40173848470052\n","Epoch: 3866/10000, Train Loss: 45.0897612138228, Valid Loss: 47.44489415486654\n","Epoch: 3867/10000, Train Loss: 45.103178544477984, Valid Loss: 47.36804326375326\n","Epoch: 3868/10000, Train Loss: 44.64372530850497, Valid Loss: 47.4198366800944\n","Epoch: 3869/10000, Train Loss: 45.112119154496625, Valid Loss: 47.45951716105143\n","Epoch: 3870/10000, Train Loss: 44.899398456920274, Valid Loss: 47.37833023071289\n","Epoch: 3871/10000, Train Loss: 44.90296242453835, Valid Loss: 47.472086588541664\n","Epoch: 3872/10000, Train Loss: 45.03458612615412, Valid Loss: 47.3666025797526\n","Epoch: 3873/10000, Train Loss: 44.65421052412553, Valid Loss: 47.30772908528646\n","Epoch: 3874/10000, Train Loss: 44.8922944502397, Valid Loss: 47.17196146647135\n","Epoch: 3875/10000, Train Loss: 44.78715133666992, Valid Loss: 47.25928243001302\n","Epoch: 3876/10000, Train Loss: 44.8954551003196, Valid Loss: 47.28105799357096\n","Epoch: 3877/10000, Train Loss: 44.43380910700018, Valid Loss: 47.337164560953774\n","Epoch: 3878/10000, Train Loss: 44.820444627241656, Valid Loss: 47.22506968180338\n","Epoch: 3879/10000, Train Loss: 44.576468381014735, Valid Loss: 47.31015650431315\n","Epoch: 3880/10000, Train Loss: 44.99442117864435, Valid Loss: 47.41610336303711\n","Epoch: 3881/10000, Train Loss: 44.56500174782493, Valid Loss: 47.286424001057945\n","Epoch: 3882/10000, Train Loss: 44.88253333351829, Valid Loss: 47.46671040852865\n","Epoch: 3883/10000, Train Loss: 44.92683375965465, Valid Loss: 47.176047007242836\n","Epoch: 3884/10000, Train Loss: 44.99370020086115, Valid Loss: 47.07023366292318\n","Epoch: 3885/10000, Train Loss: 44.81257941506126, Valid Loss: 47.301239013671875\n","Epoch: 3886/10000, Train Loss: 45.02330363880504, Valid Loss: 47.199057261149086\n","Epoch: 3887/10000, Train Loss: 44.68706512451172, Valid Loss: 47.34527587890625\n","Epoch: 3888/10000, Train Loss: 44.6731352372603, Valid Loss: 47.23522440592448\n","Epoch: 3889/10000, Train Loss: 44.87154804576527, Valid Loss: 47.275665283203125\n","Epoch: 3890/10000, Train Loss: 44.51480830799449, Valid Loss: 47.360983530680336\n","Epoch: 3891/10000, Train Loss: 44.87907270951705, Valid Loss: 47.12477493286133\n","Epoch: 3892/10000, Train Loss: 44.84089313853871, Valid Loss: 47.04910532633463\n","Epoch: 3893/10000, Train Loss: 44.65275157581676, Valid Loss: 47.01741027832031\n","Epoch: 3894/10000, Train Loss: 44.67359785600142, Valid Loss: 47.13400141398112\n","Epoch: 3895/10000, Train Loss: 44.65622919256037, Valid Loss: 47.02641805013021\n","Epoch: 3896/10000, Train Loss: 44.69129770452326, Valid Loss: 47.03632100423177\n","Epoch: 3897/10000, Train Loss: 44.494827617298476, Valid Loss: 47.347826639811196\n","Epoch: 3898/10000, Train Loss: 44.786402615633875, Valid Loss: 47.08274459838867\n","Epoch: 3899/10000, Train Loss: 44.71514476429332, Valid Loss: 47.2200075785319\n","Epoch: 3900/10000, Train Loss: 44.76629638671875, Valid Loss: 47.181260426839195\n","Epoch: 3901/10000, Train Loss: 44.702009027654476, Valid Loss: 47.40884272257487\n","Epoch: 3902/10000, Train Loss: 44.31021464954723, Valid Loss: 47.13287353515625\n","Epoch: 3903/10000, Train Loss: 44.73340745405717, Valid Loss: 47.21368535359701\n","Epoch: 3904/10000, Train Loss: 44.859248421408914, Valid Loss: 47.172289530436196\n","Epoch: 3905/10000, Train Loss: 44.70656238902699, Valid Loss: 47.22455342610677\n","Epoch: 3906/10000, Train Loss: 44.99161564220082, Valid Loss: 47.086405436197914\n","Epoch: 3907/10000, Train Loss: 44.543230230158024, Valid Loss: 47.29992167154948\n","Epoch: 3908/10000, Train Loss: 44.82103659889915, Valid Loss: 47.15920639038086\n","Epoch: 3909/10000, Train Loss: 44.700775146484375, Valid Loss: 47.23437627156576\n","Epoch: 3910/10000, Train Loss: 44.890163074840196, Valid Loss: 47.115272521972656\n","Epoch: 3911/10000, Train Loss: 44.40086711536754, Valid Loss: 47.199624379475914\n","Epoch: 3912/10000, Train Loss: 44.70174858786843, Valid Loss: 47.08735275268555\n","Epoch: 3913/10000, Train Loss: 44.80358609286222, Valid Loss: 47.1081657409668\n","Epoch: 3914/10000, Train Loss: 44.33058478615501, Valid Loss: 47.08647028605143\n","Epoch: 3915/10000, Train Loss: 44.67460840398615, Valid Loss: 46.93784968058268\n","Epoch: 3916/10000, Train Loss: 45.035705219615586, Valid Loss: 47.041909535725914\n","Epoch: 3917/10000, Train Loss: 44.5991887179288, Valid Loss: 47.284342447916664\n","Epoch: 3918/10000, Train Loss: 44.66798158125444, Valid Loss: 47.261088053385414\n","Epoch: 3919/10000, Train Loss: 44.6064206903631, Valid Loss: 47.23086420694987\n","Epoch: 3920/10000, Train Loss: 44.64671811190519, Valid Loss: 47.09355545043945\n","Epoch: 3921/10000, Train Loss: 44.70429819280451, Valid Loss: 47.17722956339518\n","Epoch: 3922/10000, Train Loss: 44.634119207208805, Valid Loss: 47.2127939860026\n","Epoch: 3923/10000, Train Loss: 44.669269214976914, Valid Loss: 46.9540646870931\n","Epoch: 3924/10000, Train Loss: 44.71400278264826, Valid Loss: 46.80232620239258\n","Epoch: 3925/10000, Train Loss: 44.46778418801048, Valid Loss: 46.753125508626304\n","Epoch: 3926/10000, Train Loss: 44.53157459605824, Valid Loss: 46.94430796305338\n","Epoch: 3927/10000, Train Loss: 44.409170324152164, Valid Loss: 47.08797073364258\n","Epoch: 3928/10000, Train Loss: 44.68893120505593, Valid Loss: 46.92909367879232\n","Epoch: 3929/10000, Train Loss: 44.417741948908024, Valid Loss: 46.960984547932945\n","Epoch: 3930/10000, Train Loss: 44.67240732366388, Valid Loss: 47.160806020100914\n","Epoch: 3931/10000, Train Loss: 44.30527114868164, Valid Loss: 47.093607584635414\n","Epoch: 3932/10000, Train Loss: 44.42610966075551, Valid Loss: 46.888275146484375\n","Epoch: 3933/10000, Train Loss: 44.6301813992587, Valid Loss: 46.89755884806315\n","Epoch: 3934/10000, Train Loss: 44.45697368275035, Valid Loss: 46.93273671468099\n","Epoch: 3935/10000, Train Loss: 44.35453935102983, Valid Loss: 46.91689809163412\n","Epoch: 3936/10000, Train Loss: 44.66403024846857, Valid Loss: 46.92293039957682\n","Epoch: 3937/10000, Train Loss: 44.352419419722125, Valid Loss: 46.93414815266927\n","Epoch: 3938/10000, Train Loss: 44.70850961858576, Valid Loss: 47.02232996622721\n","Epoch: 3939/10000, Train Loss: 44.60608673095703, Valid Loss: 46.88973871866862\n","Epoch: 3940/10000, Train Loss: 44.51924861561168, Valid Loss: 46.9783821105957\n","Epoch: 3941/10000, Train Loss: 44.26565863869407, Valid Loss: 46.77087529500326\n","Epoch: 3942/10000, Train Loss: 44.311460668390446, Valid Loss: 46.854576110839844\n","Epoch: 3943/10000, Train Loss: 44.31882060657848, Valid Loss: 46.750298817952476\n","Epoch: 3944/10000, Train Loss: 44.444150404496625, Valid Loss: 46.83423868815104\n","Epoch: 3945/10000, Train Loss: 44.402497031471945, Valid Loss: 46.86929448445638\n","Epoch: 3946/10000, Train Loss: 44.59163457697088, Valid Loss: 46.964884440104164\n","Epoch: 3947/10000, Train Loss: 44.305568348277696, Valid Loss: 47.107398986816406\n","Epoch: 3948/10000, Train Loss: 44.68275382302024, Valid Loss: 46.884115854899086\n","Epoch: 3949/10000, Train Loss: 44.54148934104226, Valid Loss: 46.72429402669271\n","Epoch: 3950/10000, Train Loss: 44.53162175958807, Valid Loss: 46.716565450032554\n","Epoch: 3951/10000, Train Loss: 44.142946069890804, Valid Loss: 46.76769765218099\n","Epoch: 3952/10000, Train Loss: 44.27238776467063, Valid Loss: 46.82706197102865\n","Epoch: 3953/10000, Train Loss: 44.10115016590465, Valid Loss: 46.82121276855469\n","Epoch: 3954/10000, Train Loss: 44.37951521439986, Valid Loss: 46.662026723225914\n","Epoch: 3955/10000, Train Loss: 44.119759646329015, Valid Loss: 46.610121409098305\n","Epoch: 3956/10000, Train Loss: 44.23691766912287, Valid Loss: 46.575215657552086\n","Epoch: 3957/10000, Train Loss: 44.08469078757546, Valid Loss: 46.75789260864258\n","Epoch: 3958/10000, Train Loss: 44.24455538662997, Valid Loss: 46.90063349405924\n","Epoch: 3959/10000, Train Loss: 44.14881792935458, Valid Loss: 46.77635701497396\n","Epoch: 3960/10000, Train Loss: 44.37181264703924, Valid Loss: 46.75144958496094\n","Epoch: 3961/10000, Train Loss: 43.89219249378551, Valid Loss: 46.85164006551107\n","Epoch: 3962/10000, Train Loss: 44.01251567493785, Valid Loss: 46.729104359944664\n","Epoch: 3963/10000, Train Loss: 44.160506855357774, Valid Loss: 46.83429209391276\n","Epoch: 3964/10000, Train Loss: 44.25401756980202, Valid Loss: 46.74380238850912\n","Epoch: 3965/10000, Train Loss: 44.528900840065695, Valid Loss: 46.60690689086914\n","Epoch: 3966/10000, Train Loss: 43.994759646329015, Valid Loss: 46.834799448649086\n","Epoch: 3967/10000, Train Loss: 44.28733097423207, Valid Loss: 46.7519276936849\n","Epoch: 3968/10000, Train Loss: 44.36226029829545, Valid Loss: 46.79226303100586\n","Epoch: 3969/10000, Train Loss: 44.373695373535156, Valid Loss: 46.65936152140299\n","Epoch: 3970/10000, Train Loss: 44.48802601207387, Valid Loss: 46.73361333211263\n","Epoch: 3971/10000, Train Loss: 44.1147856278853, Valid Loss: 46.76067606608073\n","Epoch: 3972/10000, Train Loss: 44.179835232821375, Valid Loss: 46.733890533447266\n","Epoch: 3973/10000, Train Loss: 44.23967881636186, Valid Loss: 46.615857442220054\n","Epoch: 3974/10000, Train Loss: 43.89403117786754, Valid Loss: 46.5906867980957\n","Epoch: 3975/10000, Train Loss: 44.07966301657937, Valid Loss: 46.366580963134766\n","Epoch: 3976/10000, Train Loss: 43.93149670687589, Valid Loss: 46.6453005472819\n","Epoch: 3977/10000, Train Loss: 44.35169809514826, Valid Loss: 46.8014030456543\n","Epoch: 3978/10000, Train Loss: 44.51052683049982, Valid Loss: 46.657580057779946\n","Epoch: 3979/10000, Train Loss: 44.17909067327326, Valid Loss: 46.804918924967446\n","Epoch: 3980/10000, Train Loss: 44.21126591075551, Valid Loss: 46.77825164794922\n","Epoch: 3981/10000, Train Loss: 44.07838613336737, Valid Loss: 46.887376149495445\n","Epoch: 3982/10000, Train Loss: 44.569825259121984, Valid Loss: 46.739087422688804\n","Epoch: 3983/10000, Train Loss: 44.37125639481978, Valid Loss: 46.55377070109049\n","Epoch: 3984/10000, Train Loss: 44.14180859652433, Valid Loss: 46.45174026489258\n","Epoch: 3985/10000, Train Loss: 44.44889415394176, Valid Loss: 46.62309900919596\n","Epoch: 3986/10000, Train Loss: 44.31606049971147, Valid Loss: 46.657432556152344\n","Epoch: 3987/10000, Train Loss: 43.9073881669478, Valid Loss: 46.823195139567055\n","Epoch: 3988/10000, Train Loss: 43.950678391890094, Valid Loss: 46.50417836507162\n","Epoch: 3989/10000, Train Loss: 43.99704083529386, Valid Loss: 46.583475748697914\n","Epoch: 3990/10000, Train Loss: 44.05135588212447, Valid Loss: 46.555528004964195\n","Epoch: 3991/10000, Train Loss: 43.70864209261808, Valid Loss: 46.5194460550944\n","Epoch: 3992/10000, Train Loss: 44.187942851673476, Valid Loss: 46.78745905558268\n","Epoch: 3993/10000, Train Loss: 44.18644644997337, Valid Loss: 46.58331807454427\n","Epoch: 3994/10000, Train Loss: 44.413307189941406, Valid Loss: 46.58576583862305\n","Epoch: 3995/10000, Train Loss: 43.92378408258612, Valid Loss: 46.88225809733073\n","Epoch: 3996/10000, Train Loss: 44.03723075173118, Valid Loss: 46.57806523640951\n","Epoch: 3997/10000, Train Loss: 43.85949498956854, Valid Loss: 46.68668746948242\n","Epoch: 3998/10000, Train Loss: 44.274901303378016, Valid Loss: 46.648626963297524\n","Epoch: 3999/10000, Train Loss: 44.05455884066495, Valid Loss: 46.50669733683268\n","Epoch: 4000/10000, Train Loss: 43.96717071533203, Valid Loss: 46.507633209228516\n","Epoch: 4001/10000, Train Loss: 43.912140586159445, Valid Loss: 46.55754725138346\n","Epoch: 4002/10000, Train Loss: 44.07373185591264, Valid Loss: 46.628500620524086\n","Epoch: 4003/10000, Train Loss: 43.81811246004972, Valid Loss: 46.647467295328774\n","Epoch: 4004/10000, Train Loss: 43.90065869418058, Valid Loss: 46.54716110229492\n","Epoch: 4005/10000, Train Loss: 43.56885528564453, Valid Loss: 46.80245463053385\n","Epoch: 4006/10000, Train Loss: 43.92523262717507, Valid Loss: 46.76615778605143\n","Epoch: 4007/10000, Train Loss: 43.672589388760656, Valid Loss: 46.546966552734375\n","Epoch: 4008/10000, Train Loss: 43.863036762584336, Valid Loss: 46.745262145996094\n","Epoch: 4009/10000, Train Loss: 44.05440243807706, Valid Loss: 46.49468104044596\n","Epoch: 4010/10000, Train Loss: 43.83534830266779, Valid Loss: 46.377480824788414\n","Epoch: 4011/10000, Train Loss: 44.008452675559305, Valid Loss: 46.507745107014976\n","Epoch: 4012/10000, Train Loss: 43.9952260797674, Valid Loss: 46.57484690348307\n","Epoch: 4013/10000, Train Loss: 43.619881023060195, Valid Loss: 46.521531422932945\n","Epoch: 4014/10000, Train Loss: 43.894295779141515, Valid Loss: 46.48895772298177\n","Epoch: 4015/10000, Train Loss: 44.30598241632635, Valid Loss: 46.437512715657554\n","Epoch: 4016/10000, Train Loss: 43.84888874400746, Valid Loss: 46.421548207600914\n","Epoch: 4017/10000, Train Loss: 43.967586517333984, Valid Loss: 46.373711903889976\n","Epoch: 4018/10000, Train Loss: 43.815394314852625, Valid Loss: 46.679857889811196\n","Epoch: 4019/10000, Train Loss: 43.561583432284266, Valid Loss: 46.40931193033854\n","Epoch: 4020/10000, Train Loss: 44.0300143848766, Valid Loss: 46.47386932373047\n","Epoch: 4021/10000, Train Loss: 43.960824099454015, Valid Loss: 46.529214223225914\n","Epoch: 4022/10000, Train Loss: 44.03742009943182, Valid Loss: 46.54468790690104\n","Epoch: 4023/10000, Train Loss: 43.72892691872337, Valid Loss: 46.44796625773112\n","Epoch: 4024/10000, Train Loss: 43.31538044322621, Valid Loss: 46.3748410542806\n","Epoch: 4025/10000, Train Loss: 43.86077603426847, Valid Loss: 46.40189107259115\n","Epoch: 4026/10000, Train Loss: 43.96764720569957, Valid Loss: 46.516249338785805\n","Epoch: 4027/10000, Train Loss: 43.45011659102006, Valid Loss: 46.566888173421226\n","Epoch: 4028/10000, Train Loss: 43.92596366188743, Valid Loss: 46.43960316975912\n","Epoch: 4029/10000, Train Loss: 43.81204327670011, Valid Loss: 46.17401250203451\n","Epoch: 4030/10000, Train Loss: 43.83435127951882, Valid Loss: 46.31404495239258\n","Epoch: 4031/10000, Train Loss: 43.818417982621625, Valid Loss: 46.191551208496094\n","Epoch: 4032/10000, Train Loss: 43.7355149009011, Valid Loss: 46.270913441975914\n","Epoch: 4033/10000, Train Loss: 43.91952549327504, Valid Loss: 46.44230270385742\n","Epoch: 4034/10000, Train Loss: 43.919197429310195, Valid Loss: 46.44339497884115\n","Epoch: 4035/10000, Train Loss: 43.51978891546076, Valid Loss: 46.367071787516274\n","Epoch: 4036/10000, Train Loss: 43.67387667569247, Valid Loss: 46.494738260904946\n","Epoch: 4037/10000, Train Loss: 43.71258128773082, Valid Loss: 46.466651916503906\n","Epoch: 4038/10000, Train Loss: 43.72667555375533, Valid Loss: 46.376146952311196\n","Epoch: 4039/10000, Train Loss: 43.68120366876776, Valid Loss: 46.31267547607422\n","Epoch: 4040/10000, Train Loss: 43.680720589377664, Valid Loss: 46.484387715657554\n","Epoch: 4041/10000, Train Loss: 43.95938422463157, Valid Loss: 46.52627309163412\n","Epoch: 4042/10000, Train Loss: 43.58003373579545, Valid Loss: 46.309488932291664\n","Epoch: 4043/10000, Train Loss: 43.25353345003995, Valid Loss: 46.26443608601888\n","Epoch: 4044/10000, Train Loss: 43.83026677911932, Valid Loss: 46.440250396728516\n","Epoch: 4045/10000, Train Loss: 43.587375987659804, Valid Loss: 46.27696100870768\n","Epoch: 4046/10000, Train Loss: 43.63866112448952, Valid Loss: 46.36753718058268\n","Epoch: 4047/10000, Train Loss: 43.61300763216886, Valid Loss: 46.5010732014974\n","Epoch: 4048/10000, Train Loss: 43.95622114701705, Valid Loss: 46.47559611002604\n","Epoch: 4049/10000, Train Loss: 43.56753782792525, Valid Loss: 46.31517664591471\n","Epoch: 4050/10000, Train Loss: 43.58903538097035, Valid Loss: 46.266221364339195\n","Epoch: 4051/10000, Train Loss: 43.823819940740414, Valid Loss: 46.170701344807945\n","Epoch: 4052/10000, Train Loss: 43.708337263627485, Valid Loss: 46.09692255655924\n","Epoch: 4053/10000, Train Loss: 43.40562889792702, Valid Loss: 46.16410700480143\n","Epoch: 4054/10000, Train Loss: 43.327307267622515, Valid Loss: 46.164756774902344\n","Epoch: 4055/10000, Train Loss: 43.446392406116836, Valid Loss: 46.299147288004555\n","Epoch: 4056/10000, Train Loss: 43.78680350563743, Valid Loss: 46.366085052490234\n","Epoch: 4057/10000, Train Loss: 43.62669476595792, Valid Loss: 46.18913269042969\n","Epoch: 4058/10000, Train Loss: 43.52046897194602, Valid Loss: 46.152941385904946\n","Epoch: 4059/10000, Train Loss: 43.481355840509586, Valid Loss: 46.2065798441569\n","Epoch: 4060/10000, Train Loss: 43.61176750876687, Valid Loss: 46.27791849772135\n","Epoch: 4061/10000, Train Loss: 43.5078818581321, Valid Loss: 46.28408686319987\n","Epoch: 4062/10000, Train Loss: 43.414263638583094, Valid Loss: 46.22805531819662\n","Epoch: 4063/10000, Train Loss: 43.70242760398171, Valid Loss: 46.10989634195963\n","Epoch: 4064/10000, Train Loss: 43.504359158602625, Valid Loss: 46.13689041137695\n","Epoch: 4065/10000, Train Loss: 43.683944355357774, Valid Loss: 45.89624913533529\n","Epoch: 4066/10000, Train Loss: 43.835420088334516, Valid Loss: 45.91397349039713\n","Epoch: 4067/10000, Train Loss: 43.594698125665836, Valid Loss: 46.089227040608726\n","Epoch: 4068/10000, Train Loss: 43.50896800648082, Valid Loss: 46.07197570800781\n","Epoch: 4069/10000, Train Loss: 43.52222407947887, Valid Loss: 46.07392883300781\n","Epoch: 4070/10000, Train Loss: 43.62098416415128, Valid Loss: 45.911495208740234\n","Epoch: 4071/10000, Train Loss: 43.65321003306996, Valid Loss: 46.21251678466797\n","Epoch: 4072/10000, Train Loss: 43.49367245760831, Valid Loss: 46.209625244140625\n","Epoch: 4073/10000, Train Loss: 43.846924868496984, Valid Loss: 46.274496714274086\n","Epoch: 4074/10000, Train Loss: 43.69713280417702, Valid Loss: 46.19644292195638\n","Epoch: 4075/10000, Train Loss: 43.55947702581232, Valid Loss: 46.17753473917643\n","Epoch: 4076/10000, Train Loss: 43.82796963778409, Valid Loss: 46.241171518961586\n","Epoch: 4077/10000, Train Loss: 43.1994909806685, Valid Loss: 46.21117909749349\n","Epoch: 4078/10000, Train Loss: 43.474700927734375, Valid Loss: 46.15380732218424\n","Epoch: 4079/10000, Train Loss: 43.356139096346766, Valid Loss: 46.0479990641276\n","Epoch: 4080/10000, Train Loss: 43.226815310391515, Valid Loss: 46.09765879313151\n","Epoch: 4081/10000, Train Loss: 43.341282931241125, Valid Loss: 46.135084788004555\n","Epoch: 4082/10000, Train Loss: 43.37882440740412, Valid Loss: 46.07731246948242\n","Epoch: 4083/10000, Train Loss: 43.49192740700462, Valid Loss: 46.13888295491537\n","Epoch: 4084/10000, Train Loss: 43.40517044067383, Valid Loss: 46.068251291910805\n","Epoch: 4085/10000, Train Loss: 43.06744246049361, Valid Loss: 46.04373677571615\n","Epoch: 4086/10000, Train Loss: 43.48798647793856, Valid Loss: 46.00761922200521\n","Epoch: 4087/10000, Train Loss: 43.28311816128817, Valid Loss: 46.02691523234049\n","Epoch: 4088/10000, Train Loss: 43.582971052689985, Valid Loss: 45.9320182800293\n","Epoch: 4089/10000, Train Loss: 43.302105990323156, Valid Loss: 45.992515563964844\n","Epoch: 4090/10000, Train Loss: 43.45860186490145, Valid Loss: 45.98144785563151\n","Epoch: 4091/10000, Train Loss: 43.16104646162553, Valid Loss: 45.92497253417969\n","Epoch: 4092/10000, Train Loss: 43.64907386086204, Valid Loss: 46.18863423665365\n","Epoch: 4093/10000, Train Loss: 43.450438412753016, Valid Loss: 46.02610651652018\n","Epoch: 4094/10000, Train Loss: 43.27252127907493, Valid Loss: 45.97683970133463\n","Epoch: 4095/10000, Train Loss: 43.242888017134234, Valid Loss: 46.035928090413414\n","Epoch: 4096/10000, Train Loss: 43.543419577858664, Valid Loss: 45.76884206136068\n","Epoch: 4097/10000, Train Loss: 43.12002112648704, Valid Loss: 46.10525639851888\n","Epoch: 4098/10000, Train Loss: 43.20685577392578, Valid Loss: 46.0759531656901\n","Epoch: 4099/10000, Train Loss: 43.00104383988814, Valid Loss: 45.91365305582682\n","Epoch: 4100/10000, Train Loss: 43.261161457408555, Valid Loss: 45.95843251546224\n","Epoch: 4101/10000, Train Loss: 43.047968430952594, Valid Loss: 45.93394088745117\n","Epoch: 4102/10000, Train Loss: 43.00004022771662, Valid Loss: 45.94929885864258\n","Epoch: 4103/10000, Train Loss: 43.230268304998226, Valid Loss: 45.841129302978516\n","Epoch: 4104/10000, Train Loss: 43.245987285267226, Valid Loss: 45.93308639526367\n","Epoch: 4105/10000, Train Loss: 43.268218300559305, Valid Loss: 45.93352381388346\n","Epoch: 4106/10000, Train Loss: 43.02830123901367, Valid Loss: 45.89421844482422\n","Epoch: 4107/10000, Train Loss: 43.16764033924449, Valid Loss: 45.76691563924154\n","Epoch: 4108/10000, Train Loss: 42.91151428222656, Valid Loss: 45.847418467203774\n","Epoch: 4109/10000, Train Loss: 43.09557515924627, Valid Loss: 45.80454889933268\n","Epoch: 4110/10000, Train Loss: 42.98988862471147, Valid Loss: 45.84278361002604\n","Epoch: 4111/10000, Train Loss: 43.23495032570579, Valid Loss: 45.8869260152181\n","Epoch: 4112/10000, Train Loss: 43.2192549272017, Valid Loss: 46.008993784586586\n","Epoch: 4113/10000, Train Loss: 43.31851543079723, Valid Loss: 46.127386728922524\n","Epoch: 4114/10000, Train Loss: 43.014923789284445, Valid Loss: 46.03863398234049\n","Epoch: 4115/10000, Train Loss: 42.74235361272638, Valid Loss: 45.842681884765625\n","Epoch: 4116/10000, Train Loss: 42.94068423184481, Valid Loss: 45.80637741088867\n","Epoch: 4117/10000, Train Loss: 43.15153988924894, Valid Loss: 45.777079264322914\n","Epoch: 4118/10000, Train Loss: 43.683255975896664, Valid Loss: 45.9989980061849\n","Epoch: 4119/10000, Train Loss: 42.98844979026101, Valid Loss: 45.94261169433594\n","Epoch: 4120/10000, Train Loss: 42.81361285122958, Valid Loss: 45.82244110107422\n","Epoch: 4121/10000, Train Loss: 43.19715811989524, Valid Loss: 45.96090443929037\n","Epoch: 4122/10000, Train Loss: 43.20479375665838, Valid Loss: 45.89985911051432\n","Epoch: 4123/10000, Train Loss: 43.08724316683683, Valid Loss: 45.72827021280924\n","Epoch: 4124/10000, Train Loss: 43.42519031871449, Valid Loss: 45.88449478149414\n","Epoch: 4125/10000, Train Loss: 43.06132333928888, Valid Loss: 45.712782541910805\n","Epoch: 4126/10000, Train Loss: 43.089085665616125, Valid Loss: 45.9942881266276\n","Epoch: 4127/10000, Train Loss: 43.057274558327414, Valid Loss: 45.87239201863607\n","Epoch: 4128/10000, Train Loss: 43.405507521195844, Valid Loss: 45.79373677571615\n","Epoch: 4129/10000, Train Loss: 43.11771600896662, Valid Loss: 45.583388010660805\n","Epoch: 4130/10000, Train Loss: 43.081937269731, Valid Loss: 45.538368225097656\n","Epoch: 4131/10000, Train Loss: 43.2561430497603, Valid Loss: 45.79046122233073\n","Epoch: 4132/10000, Train Loss: 43.170453158291906, Valid Loss: 45.968947092692055\n","Epoch: 4133/10000, Train Loss: 42.805804859508164, Valid Loss: 45.77636210123698\n","Epoch: 4134/10000, Train Loss: 43.12994246049361, Valid Loss: 45.83401107788086\n","Epoch: 4135/10000, Train Loss: 42.981198050759055, Valid Loss: 45.74415842692057\n","Epoch: 4136/10000, Train Loss: 43.015686381946914, Valid Loss: 45.78923034667969\n","Epoch: 4137/10000, Train Loss: 43.059411482377485, Valid Loss: 45.755593617757164\n","Epoch: 4138/10000, Train Loss: 43.168979991566054, Valid Loss: 45.83679326375326\n","Epoch: 4139/10000, Train Loss: 42.996212699196555, Valid Loss: 45.87353515625\n","Epoch: 4140/10000, Train Loss: 43.172809254039414, Valid Loss: 45.787726084391274\n","Epoch: 4141/10000, Train Loss: 42.554487054998226, Valid Loss: 45.56423314412435\n","Epoch: 4142/10000, Train Loss: 43.0982700694691, Valid Loss: 45.76914850870768\n","Epoch: 4143/10000, Train Loss: 43.27188907970082, Valid Loss: 45.56013107299805\n","Epoch: 4144/10000, Train Loss: 42.85222278941762, Valid Loss: 45.60428237915039\n","Epoch: 4145/10000, Train Loss: 42.57727189497514, Valid Loss: 45.75396728515625\n","Epoch: 4146/10000, Train Loss: 42.84956151788885, Valid Loss: 45.63004811604818\n","Epoch: 4147/10000, Train Loss: 43.032174197110265, Valid Loss: 45.797096252441406\n","Epoch: 4148/10000, Train Loss: 43.57283158735795, Valid Loss: 45.79822031656901\n","Epoch: 4149/10000, Train Loss: 42.79365158081055, Valid Loss: 45.597076416015625\n","Epoch: 4150/10000, Train Loss: 43.35068477283824, Valid Loss: 45.80348205566406\n","Epoch: 4151/10000, Train Loss: 43.24608716097745, Valid Loss: 45.841967264811196\n","Epoch: 4152/10000, Train Loss: 42.836906086314805, Valid Loss: 45.65669377644857\n","Epoch: 4153/10000, Train Loss: 42.765261910178445, Valid Loss: 45.606133778889976\n","Epoch: 4154/10000, Train Loss: 42.63795575228605, Valid Loss: 45.706451416015625\n","Epoch: 4155/10000, Train Loss: 43.08273350108754, Valid Loss: 45.89048512776693\n","Epoch: 4156/10000, Train Loss: 42.90391540527344, Valid Loss: 45.75835418701172\n","Epoch: 4157/10000, Train Loss: 42.622529463334516, Valid Loss: 45.51100158691406\n","Epoch: 4158/10000, Train Loss: 42.520934711803086, Valid Loss: 45.39086023966471\n","Epoch: 4159/10000, Train Loss: 42.98000439730558, Valid Loss: 45.63709386189779\n","Epoch: 4160/10000, Train Loss: 42.8431791825728, Valid Loss: 45.55483881632487\n","Epoch: 4161/10000, Train Loss: 42.59414152665572, Valid Loss: 45.79664993286133\n","Epoch: 4162/10000, Train Loss: 42.980186462402344, Valid Loss: 45.71491622924805\n","Epoch: 4163/10000, Train Loss: 43.043331146240234, Valid Loss: 45.54502487182617\n","Epoch: 4164/10000, Train Loss: 43.01779278841886, Valid Loss: 45.626505533854164\n","Epoch: 4165/10000, Train Loss: 43.31782601096413, Valid Loss: 45.840771993001304\n","Epoch: 4166/10000, Train Loss: 42.91547948663885, Valid Loss: 45.60525258382162\n","Epoch: 4167/10000, Train Loss: 42.83387340198863, Valid Loss: 45.562758127848305\n","Epoch: 4168/10000, Train Loss: 42.66798574274237, Valid Loss: 45.66482289632162\n","Epoch: 4169/10000, Train Loss: 42.69891496138139, Valid Loss: 45.715248107910156\n","Epoch: 4170/10000, Train Loss: 43.0791823647239, Valid Loss: 45.64236958821615\n","Epoch: 4171/10000, Train Loss: 42.75562806562944, Valid Loss: 45.314857482910156\n","Epoch: 4172/10000, Train Loss: 42.59489857066762, Valid Loss: 45.526634216308594\n","Epoch: 4173/10000, Train Loss: 42.92718367143111, Valid Loss: 45.67245864868164\n","Epoch: 4174/10000, Train Loss: 42.57727813720703, Valid Loss: 45.39380900065104\n","Epoch: 4175/10000, Train Loss: 42.80813251842152, Valid Loss: 45.51112365722656\n","Epoch: 4176/10000, Train Loss: 42.91524540294301, Valid Loss: 45.486925760904946\n","Epoch: 4177/10000, Train Loss: 42.580408269708805, Valid Loss: 45.83882522583008\n","Epoch: 4178/10000, Train Loss: 42.716300617564805, Valid Loss: 45.548788706461586\n","Epoch: 4179/10000, Train Loss: 42.799047296697445, Valid Loss: 45.48569997151693\n","Epoch: 4180/10000, Train Loss: 42.556718999689274, Valid Loss: 45.52099355061849\n","Epoch: 4181/10000, Train Loss: 42.86456714976918, Valid Loss: 45.47494252522787\n","Epoch: 4182/10000, Train Loss: 42.40241518887606, Valid Loss: 45.50755310058594\n","Epoch: 4183/10000, Train Loss: 42.69762073863637, Valid Loss: 45.437154134114586\n","Epoch: 4184/10000, Train Loss: 42.88005898215554, Valid Loss: 45.595689137776695\n","Epoch: 4185/10000, Train Loss: 42.4673923145641, Valid Loss: 45.561744689941406\n","Epoch: 4186/10000, Train Loss: 42.37622555819425, Valid Loss: 45.611253102620445\n","Epoch: 4187/10000, Train Loss: 42.620488600297406, Valid Loss: 45.31849670410156\n","Epoch: 4188/10000, Train Loss: 42.657380537553266, Valid Loss: 45.592149098714195\n","Epoch: 4189/10000, Train Loss: 42.4699838811701, Valid Loss: 45.506613413492836\n","Epoch: 4190/10000, Train Loss: 42.58949141068892, Valid Loss: 45.56360371907552\n","Epoch: 4191/10000, Train Loss: 42.63853627985174, Valid Loss: 45.51941935221354\n","Epoch: 4192/10000, Train Loss: 42.734921888871625, Valid Loss: 45.33240000406901\n","Epoch: 4193/10000, Train Loss: 42.53265380859375, Valid Loss: 45.4228515625\n","Epoch: 4194/10000, Train Loss: 42.67021734064276, Valid Loss: 45.44850285847982\n","Epoch: 4195/10000, Train Loss: 42.53296869451349, Valid Loss: 45.180520375569664\n","Epoch: 4196/10000, Train Loss: 42.2540036981756, Valid Loss: 45.19198354085287\n","Epoch: 4197/10000, Train Loss: 42.45668896761808, Valid Loss: 45.364925384521484\n","Epoch: 4198/10000, Train Loss: 43.0928708856756, Valid Loss: 45.371447245279946\n","Epoch: 4199/10000, Train Loss: 42.53059179132635, Valid Loss: 45.33214823404948\n","Epoch: 4200/10000, Train Loss: 42.57243693958629, Valid Loss: 45.09221394856771\n","Epoch: 4201/10000, Train Loss: 42.1245266307484, Valid Loss: 45.09267934163412\n","Epoch: 4202/10000, Train Loss: 42.70808237249201, Valid Loss: 45.15937169392904\n","Epoch: 4203/10000, Train Loss: 42.330417979847304, Valid Loss: 45.40290196736654\n","Epoch: 4204/10000, Train Loss: 42.30121751265092, Valid Loss: 45.399314880371094\n","Epoch: 4205/10000, Train Loss: 42.00224789706144, Valid Loss: 45.32080332438151\n","Epoch: 4206/10000, Train Loss: 42.21604850075462, Valid Loss: 45.28521855672201\n","Epoch: 4207/10000, Train Loss: 42.533639040860265, Valid Loss: 45.402697245279946\n","Epoch: 4208/10000, Train Loss: 42.84179063276811, Valid Loss: 45.393089294433594\n","Epoch: 4209/10000, Train Loss: 42.682703885165125, Valid Loss: 45.38934580485026\n","Epoch: 4210/10000, Train Loss: 42.38582715121183, Valid Loss: 45.236045837402344\n","Epoch: 4211/10000, Train Loss: 42.422867168079726, Valid Loss: 45.16065470377604\n","Epoch: 4212/10000, Train Loss: 42.41513096202504, Valid Loss: 45.131813049316406\n","Epoch: 4213/10000, Train Loss: 41.915614041415125, Valid Loss: 45.29249699910482\n","Epoch: 4214/10000, Train Loss: 42.445173090154476, Valid Loss: 45.48507563273112\n","Epoch: 4215/10000, Train Loss: 42.40773807872426, Valid Loss: 45.24799728393555\n","Epoch: 4216/10000, Train Loss: 42.35161590576172, Valid Loss: 45.19843292236328\n","Epoch: 4217/10000, Train Loss: 42.4927170493386, Valid Loss: 45.304482777913414\n","Epoch: 4218/10000, Train Loss: 42.765466863458805, Valid Loss: 45.2266960144043\n","Epoch: 4219/10000, Train Loss: 42.337956862016156, Valid Loss: 45.473584493001304\n","Epoch: 4220/10000, Train Loss: 42.611221660267226, Valid Loss: 45.25098546346029\n","Epoch: 4221/10000, Train Loss: 42.61872516978871, Valid Loss: 45.312432607014976\n","Epoch: 4222/10000, Train Loss: 42.32909497347745, Valid Loss: 45.30443445841471\n","Epoch: 4223/10000, Train Loss: 42.554839394309305, Valid Loss: 45.202841440836586\n","Epoch: 4224/10000, Train Loss: 42.639972339976914, Valid Loss: 45.100842793782554\n","Epoch: 4225/10000, Train Loss: 42.40032404119318, Valid Loss: 45.29141743977865\n","Epoch: 4226/10000, Train Loss: 42.50767690485174, Valid Loss: 45.18394978841146\n","Epoch: 4227/10000, Train Loss: 41.95896322076971, Valid Loss: 45.33983612060547\n","Epoch: 4228/10000, Train Loss: 42.600466294722125, Valid Loss: 45.29079055786133\n","Epoch: 4229/10000, Train Loss: 42.583715265447445, Valid Loss: 45.143182118733726\n","Epoch: 4230/10000, Train Loss: 42.20870624889027, Valid Loss: 45.149522145589195\n","Epoch: 4231/10000, Train Loss: 42.41390748457475, Valid Loss: 45.277435302734375\n","Epoch: 4232/10000, Train Loss: 42.13238664106889, Valid Loss: 45.19663619995117\n","Epoch: 4233/10000, Train Loss: 42.63463315096769, Valid Loss: 45.33537928263346\n","Epoch: 4234/10000, Train Loss: 42.15548463301225, Valid Loss: 45.28862508138021\n","Epoch: 4235/10000, Train Loss: 42.08096903020685, Valid Loss: 45.22627639770508\n","Epoch: 4236/10000, Train Loss: 41.946101448752664, Valid Loss: 45.20558166503906\n","Epoch: 4237/10000, Train Loss: 42.02561222423207, Valid Loss: 45.09421157836914\n","Epoch: 4238/10000, Train Loss: 42.32742136174982, Valid Loss: 45.13794072469076\n","Epoch: 4239/10000, Train Loss: 42.01613512906161, Valid Loss: 45.174187978108726\n","Epoch: 4240/10000, Train Loss: 42.150847695090555, Valid Loss: 45.18877156575521\n","Epoch: 4241/10000, Train Loss: 42.44226698441939, Valid Loss: 45.06110763549805\n","Epoch: 4242/10000, Train Loss: 42.38797239823775, Valid Loss: 45.00253041585287\n","Epoch: 4243/10000, Train Loss: 42.3195686340332, Valid Loss: 45.126363118489586\n","Epoch: 4244/10000, Train Loss: 42.25428217107599, Valid Loss: 45.02123769124349\n","Epoch: 4245/10000, Train Loss: 42.154659964821555, Valid Loss: 45.147412618001304\n","Epoch: 4246/10000, Train Loss: 42.18301669034091, Valid Loss: 45.17074203491211\n","Epoch: 4247/10000, Train Loss: 42.64976605502042, Valid Loss: 45.137351989746094\n","Epoch: 4248/10000, Train Loss: 42.86067858609286, Valid Loss: 45.11308924357096\n","Epoch: 4249/10000, Train Loss: 41.986293445933946, Valid Loss: 44.97351582845052\n","Epoch: 4250/10000, Train Loss: 42.10512854836204, Valid Loss: 45.03369267781576\n","Epoch: 4251/10000, Train Loss: 42.21664185957475, Valid Loss: 44.947592417399086\n","Epoch: 4252/10000, Train Loss: 42.40900837291371, Valid Loss: 45.210280100504555\n","Epoch: 4253/10000, Train Loss: 42.22204312411222, Valid Loss: 45.080718994140625\n","Epoch: 4254/10000, Train Loss: 42.32329420609908, Valid Loss: 45.13091913859049\n","Epoch: 4255/10000, Train Loss: 42.244719071821734, Valid Loss: 45.0848388671875\n","Epoch: 4256/10000, Train Loss: 42.227320584383875, Valid Loss: 45.10624313354492\n","Epoch: 4257/10000, Train Loss: 42.066276203502305, Valid Loss: 44.97029113769531\n","Epoch: 4258/10000, Train Loss: 42.26373499090021, Valid Loss: 45.03256607055664\n","Epoch: 4259/10000, Train Loss: 42.25619853626598, Valid Loss: 45.30069478352865\n","Epoch: 4260/10000, Train Loss: 42.04877749356356, Valid Loss: 45.1147829691569\n","Epoch: 4261/10000, Train Loss: 42.06586386940696, Valid Loss: 45.06324259440104\n","Epoch: 4262/10000, Train Loss: 42.09767150878906, Valid Loss: 44.73737080891927\n","Epoch: 4263/10000, Train Loss: 42.12030029296875, Valid Loss: 44.82904815673828\n","Epoch: 4264/10000, Train Loss: 42.154237573797054, Valid Loss: 45.024208068847656\n","Epoch: 4265/10000, Train Loss: 42.06549072265625, Valid Loss: 44.8717295328776\n","Epoch: 4266/10000, Train Loss: 42.56079656427557, Valid Loss: 44.92495346069336\n","Epoch: 4267/10000, Train Loss: 41.88166011463512, Valid Loss: 44.8429323832194\n","Epoch: 4268/10000, Train Loss: 42.169410705566406, Valid Loss: 45.03946050008138\n","Epoch: 4269/10000, Train Loss: 42.19701177423651, Valid Loss: 44.8972053527832\n","Epoch: 4270/10000, Train Loss: 42.16074648770419, Valid Loss: 44.942675272623696\n","Epoch: 4271/10000, Train Loss: 41.76810559359464, Valid Loss: 44.8053944905599\n","Epoch: 4272/10000, Train Loss: 42.37272054498846, Valid Loss: 44.96125920613607\n","Epoch: 4273/10000, Train Loss: 42.19908211447976, Valid Loss: 44.73707580566406\n","Epoch: 4274/10000, Train Loss: 41.96220467307351, Valid Loss: 45.030321756998696\n","Epoch: 4275/10000, Train Loss: 41.56925999034535, Valid Loss: 45.08192571004232\n","Epoch: 4276/10000, Train Loss: 41.375994595614344, Valid Loss: 45.08876164754232\n","Epoch: 4277/10000, Train Loss: 42.11311340332031, Valid Loss: 45.03529485066732\n","Epoch: 4278/10000, Train Loss: 42.029288205233485, Valid Loss: 44.991902669270836\n","Epoch: 4279/10000, Train Loss: 42.1005200472745, Valid Loss: 45.056905110677086\n","Epoch: 4280/10000, Train Loss: 41.792576876553625, Valid Loss: 44.82577133178711\n","Epoch: 4281/10000, Train Loss: 42.119192990389735, Valid Loss: 44.98265711466471\n","Epoch: 4282/10000, Train Loss: 42.00688240744851, Valid Loss: 44.831677754720054\n","Epoch: 4283/10000, Train Loss: 42.140416232022375, Valid Loss: 45.05639139811198\n","Epoch: 4284/10000, Train Loss: 42.32402454723012, Valid Loss: 44.94492721557617\n","Epoch: 4285/10000, Train Loss: 41.773597023703836, Valid Loss: 44.95333480834961\n","Epoch: 4286/10000, Train Loss: 42.22749016501687, Valid Loss: 45.00711568196615\n","Epoch: 4287/10000, Train Loss: 42.189762809059836, Valid Loss: 45.05703481038412\n","Epoch: 4288/10000, Train Loss: 41.870981043035336, Valid Loss: 44.91467030843099\n","Epoch: 4289/10000, Train Loss: 41.99771360917525, Valid Loss: 44.863277435302734\n","Epoch: 4290/10000, Train Loss: 42.18458869240501, Valid Loss: 44.636487325032554\n","Epoch: 4291/10000, Train Loss: 42.08333552967418, Valid Loss: 44.65602238972982\n","Epoch: 4292/10000, Train Loss: 41.97108459472656, Valid Loss: 44.65033721923828\n","Epoch: 4293/10000, Train Loss: 41.84573086825284, Valid Loss: 44.76119867960612\n","Epoch: 4294/10000, Train Loss: 41.99613813920455, Valid Loss: 44.89680480957031\n","Epoch: 4295/10000, Train Loss: 41.71541838212447, Valid Loss: 44.835489908854164\n","Epoch: 4296/10000, Train Loss: 41.91056130149148, Valid Loss: 44.716234842936196\n","Epoch: 4297/10000, Train Loss: 42.15110709450462, Valid Loss: 44.73887634277344\n","Epoch: 4298/10000, Train Loss: 41.8219521262429, Valid Loss: 44.66501108805338\n","Epoch: 4299/10000, Train Loss: 41.902755390514024, Valid Loss: 44.80815505981445\n","Epoch: 4300/10000, Train Loss: 42.18896276300604, Valid Loss: 44.7944221496582\n","Epoch: 4301/10000, Train Loss: 41.951309550892226, Valid Loss: 44.859806060791016\n","Epoch: 4302/10000, Train Loss: 41.899849978360265, Valid Loss: 44.86568832397461\n","Epoch: 4303/10000, Train Loss: 42.272226160222836, Valid Loss: 44.84394454956055\n","Epoch: 4304/10000, Train Loss: 41.95821311257102, Valid Loss: 44.63864771525065\n","Epoch: 4305/10000, Train Loss: 42.083866812966086, Valid Loss: 44.77112833658854\n","Epoch: 4306/10000, Train Loss: 41.628056959672406, Valid Loss: 44.621421813964844\n","Epoch: 4307/10000, Train Loss: 41.868036790327594, Valid Loss: 44.66956456502279\n","Epoch: 4308/10000, Train Loss: 41.558340939608485, Valid Loss: 44.50042851765951\n","Epoch: 4309/10000, Train Loss: 41.55865131724965, Valid Loss: 44.497100830078125\n","Epoch: 4310/10000, Train Loss: 41.43640414151278, Valid Loss: 44.52582550048828\n","Epoch: 4311/10000, Train Loss: 41.63413342562589, Valid Loss: 44.84700393676758\n","Epoch: 4312/10000, Train Loss: 42.18453320589933, Valid Loss: 44.80708440144857\n","Epoch: 4313/10000, Train Loss: 42.10456986860795, Valid Loss: 44.95832316080729\n","Epoch: 4314/10000, Train Loss: 41.63957144997337, Valid Loss: 44.924678802490234\n","Epoch: 4315/10000, Train Loss: 41.63439351862127, Valid Loss: 44.87381490071615\n","Epoch: 4316/10000, Train Loss: 41.64982917092063, Valid Loss: 44.80981699625651\n","Epoch: 4317/10000, Train Loss: 41.84660720825195, Valid Loss: 44.7361946105957\n","Epoch: 4318/10000, Train Loss: 41.84310392899947, Valid Loss: 44.73552449544271\n","Epoch: 4319/10000, Train Loss: 41.818600394509055, Valid Loss: 44.615116119384766\n","Epoch: 4320/10000, Train Loss: 41.849628101695664, Valid Loss: 44.59533818562826\n","Epoch: 4321/10000, Train Loss: 41.588927182284266, Valid Loss: 44.81918589274088\n","Epoch: 4322/10000, Train Loss: 41.47733653675426, Valid Loss: 44.58360926310221\n","Epoch: 4323/10000, Train Loss: 41.78525577891957, Valid Loss: 44.6650644938151\n","Epoch: 4324/10000, Train Loss: 41.593929290771484, Valid Loss: 44.52710723876953\n","Epoch: 4325/10000, Train Loss: 41.4830769625577, Valid Loss: 44.668043772379555\n","Epoch: 4326/10000, Train Loss: 41.2379264831543, Valid Loss: 44.56396611531576\n","Epoch: 4327/10000, Train Loss: 41.546422784978695, Valid Loss: 44.43111801147461\n","Epoch: 4328/10000, Train Loss: 41.77648440274325, Valid Loss: 44.39867273966471\n","Epoch: 4329/10000, Train Loss: 41.43142596158114, Valid Loss: 44.55526351928711\n","Epoch: 4330/10000, Train Loss: 41.988158832896836, Valid Loss: 44.7281239827474\n","Epoch: 4331/10000, Train Loss: 41.542152404785156, Valid Loss: 44.41708246866862\n","Epoch: 4332/10000, Train Loss: 41.5312465320934, Valid Loss: 44.69546635945638\n","Epoch: 4333/10000, Train Loss: 41.51777302135121, Valid Loss: 44.69716135660807\n","Epoch: 4334/10000, Train Loss: 41.69547618519176, Valid Loss: 44.52364857991537\n","Epoch: 4335/10000, Train Loss: 41.898142381147906, Valid Loss: 44.54504140218099\n","Epoch: 4336/10000, Train Loss: 42.0552583174272, Valid Loss: 44.50061925252279\n","Epoch: 4337/10000, Train Loss: 41.65689121593129, Valid Loss: 44.55939865112305\n","Epoch: 4338/10000, Train Loss: 41.70385950261896, Valid Loss: 44.70732498168945\n","Epoch: 4339/10000, Train Loss: 41.626160014759414, Valid Loss: 44.75022888183594\n","Epoch: 4340/10000, Train Loss: 41.66809220747514, Valid Loss: 44.533321380615234\n","Epoch: 4341/10000, Train Loss: 41.61374248157848, Valid Loss: 44.70987065633138\n","Epoch: 4342/10000, Train Loss: 42.09202020818537, Valid Loss: 44.680712381998696\n","Epoch: 4343/10000, Train Loss: 41.403660167347304, Valid Loss: 44.62602869669596\n","Epoch: 4344/10000, Train Loss: 41.13488284024325, Valid Loss: 44.6012929280599\n","Epoch: 4345/10000, Train Loss: 41.55681124600497, Valid Loss: 44.68276341756185\n","Epoch: 4346/10000, Train Loss: 41.72918839888139, Valid Loss: 44.624951680501304\n","Epoch: 4347/10000, Train Loss: 41.55337142944336, Valid Loss: 44.341531117757164\n","Epoch: 4348/10000, Train Loss: 41.707545193758875, Valid Loss: 44.51652908325195\n","Epoch: 4349/10000, Train Loss: 41.70823773470792, Valid Loss: 44.395623524983726\n","Epoch: 4350/10000, Train Loss: 41.74086553400213, Valid Loss: 44.678141276041664\n","Epoch: 4351/10000, Train Loss: 41.83613170276988, Valid Loss: 44.610364278157554\n","Epoch: 4352/10000, Train Loss: 41.430726138028234, Valid Loss: 44.52514775594076\n","Epoch: 4353/10000, Train Loss: 41.381893157958984, Valid Loss: 44.5822499593099\n","Epoch: 4354/10000, Train Loss: 41.67064736106179, Valid Loss: 44.66598765055338\n","Epoch: 4355/10000, Train Loss: 41.77588861638849, Valid Loss: 44.60126622517904\n","Epoch: 4356/10000, Train Loss: 41.43407613580877, Valid Loss: 44.585043589274086\n","Epoch: 4357/10000, Train Loss: 41.22897685657848, Valid Loss: 44.485364278157554\n","Epoch: 4358/10000, Train Loss: 41.41388216885653, Valid Loss: 44.427014668782554\n","Epoch: 4359/10000, Train Loss: 41.832768873734906, Valid Loss: 44.52305348714193\n","Epoch: 4360/10000, Train Loss: 41.44078376076438, Valid Loss: 44.42892201741537\n","Epoch: 4361/10000, Train Loss: 41.27256393432617, Valid Loss: 44.304466247558594\n","Epoch: 4362/10000, Train Loss: 41.63431375676935, Valid Loss: 44.233113606770836\n","Epoch: 4363/10000, Train Loss: 41.2047285600142, Valid Loss: 44.1084836324056\n","Epoch: 4364/10000, Train Loss: 41.04571117054332, Valid Loss: 44.61860148111979\n","Epoch: 4365/10000, Train Loss: 41.57152626731179, Valid Loss: 44.4949836730957\n","Epoch: 4366/10000, Train Loss: 41.22841436212713, Valid Loss: 44.27454503377279\n","Epoch: 4367/10000, Train Loss: 41.50517099553888, Valid Loss: 44.58400344848633\n","Epoch: 4368/10000, Train Loss: 41.358722339976914, Valid Loss: 44.30127716064453\n","Epoch: 4369/10000, Train Loss: 41.56277986006303, Valid Loss: 44.50768152872721\n","Epoch: 4370/10000, Train Loss: 41.8495320406827, Valid Loss: 44.4814567565918\n","Epoch: 4371/10000, Train Loss: 41.03690962357955, Valid Loss: 44.511555989583336\n","Epoch: 4372/10000, Train Loss: 41.10558527166193, Valid Loss: 44.48086420694987\n","Epoch: 4373/10000, Train Loss: 41.34950672496449, Valid Loss: 44.503509521484375\n","Epoch: 4374/10000, Train Loss: 41.516293265602805, Valid Loss: 44.55146916707357\n","Epoch: 4375/10000, Train Loss: 41.250365864146836, Valid Loss: 44.49021021525065\n","Epoch: 4376/10000, Train Loss: 41.35229908336293, Valid Loss: 44.32561492919922\n","Epoch: 4377/10000, Train Loss: 41.46971997347745, Valid Loss: 44.29008356730143\n","Epoch: 4378/10000, Train Loss: 41.40994609485973, Valid Loss: 44.431644439697266\n","Epoch: 4379/10000, Train Loss: 41.67656326293945, Valid Loss: 44.411633809407554\n","Epoch: 4380/10000, Train Loss: 41.28522422096946, Valid Loss: 44.364602406819664\n","Epoch: 4381/10000, Train Loss: 41.3526611328125, Valid Loss: 44.433406829833984\n","Epoch: 4382/10000, Train Loss: 41.62650576504794, Valid Loss: 44.288336435953774\n","Epoch: 4383/10000, Train Loss: 41.278258930553086, Valid Loss: 44.328268686930336\n","Epoch: 4384/10000, Train Loss: 41.20340971513228, Valid Loss: 44.25263214111328\n","Epoch: 4385/10000, Train Loss: 41.126618818803266, Valid Loss: 44.39636357625326\n","Epoch: 4386/10000, Train Loss: 41.348493402654476, Valid Loss: 44.3988889058431\n","Epoch: 4387/10000, Train Loss: 41.113238941539414, Valid Loss: 44.15912628173828\n","Epoch: 4388/10000, Train Loss: 41.41579818725586, Valid Loss: 44.214003245035805\n","Epoch: 4389/10000, Train Loss: 41.01124017888849, Valid Loss: 44.20204416910807\n","Epoch: 4390/10000, Train Loss: 41.471374164928086, Valid Loss: 44.256125132242836\n","Epoch: 4391/10000, Train Loss: 41.052715648304336, Valid Loss: 44.36424763997396\n","Epoch: 4392/10000, Train Loss: 41.29172065041282, Valid Loss: 44.49547576904297\n","Epoch: 4393/10000, Train Loss: 41.370113372802734, Valid Loss: 44.3662961324056\n","Epoch: 4394/10000, Train Loss: 40.79337484186346, Valid Loss: 44.281229654947914\n","Epoch: 4395/10000, Train Loss: 41.0201828696511, Valid Loss: 44.419081370035805\n","Epoch: 4396/10000, Train Loss: 41.01270363547585, Valid Loss: 44.27813466389974\n","Epoch: 4397/10000, Train Loss: 41.449470866810195, Valid Loss: 44.412217458089195\n","Epoch: 4398/10000, Train Loss: 41.045507951216265, Valid Loss: 44.48621114095052\n","Epoch: 4399/10000, Train Loss: 41.16458095203746, Valid Loss: 44.27423985799154\n","Epoch: 4400/10000, Train Loss: 41.50595543601296, Valid Loss: 44.37609354654948\n","Epoch: 4401/10000, Train Loss: 41.40306784889915, Valid Loss: 44.25144958496094\n","Epoch: 4402/10000, Train Loss: 41.26510516079989, Valid Loss: 44.26616541544596\n","Epoch: 4403/10000, Train Loss: 41.5203295621005, Valid Loss: 44.25025304158529\n","Epoch: 4404/10000, Train Loss: 41.678886066783555, Valid Loss: 44.24381891886393\n","Epoch: 4405/10000, Train Loss: 41.28161413019354, Valid Loss: 44.30749257405599\n","Epoch: 4406/10000, Train Loss: 40.99863815307617, Valid Loss: 44.32333501180013\n","Epoch: 4407/10000, Train Loss: 40.98590226606889, Valid Loss: 44.311407725016274\n","Epoch: 4408/10000, Train Loss: 41.37357781150124, Valid Loss: 44.29518381754557\n","Epoch: 4409/10000, Train Loss: 41.45514054731889, Valid Loss: 44.14791615804037\n","Epoch: 4410/10000, Train Loss: 41.367065082896836, Valid Loss: 44.24283345540365\n","Epoch: 4411/10000, Train Loss: 41.109318819913, Valid Loss: 43.97724151611328\n","Epoch: 4412/10000, Train Loss: 41.45109245993874, Valid Loss: 44.02829106648763\n","Epoch: 4413/10000, Train Loss: 41.51670733365145, Valid Loss: 44.25707499186198\n","Epoch: 4414/10000, Train Loss: 41.12604938853871, Valid Loss: 44.04790242513021\n","Epoch: 4415/10000, Train Loss: 41.21487322720614, Valid Loss: 44.09862518310547\n","Epoch: 4416/10000, Train Loss: 40.904917283491656, Valid Loss: 44.25095876057943\n","Epoch: 4417/10000, Train Loss: 41.019897114146836, Valid Loss: 43.96765645345052\n","Epoch: 4418/10000, Train Loss: 41.30437885631215, Valid Loss: 44.289312998453774\n","Epoch: 4419/10000, Train Loss: 41.11872482299805, Valid Loss: 44.23871358235677\n","Epoch: 4420/10000, Train Loss: 41.35546597567472, Valid Loss: 44.16071573893229\n","Epoch: 4421/10000, Train Loss: 41.468163230202414, Valid Loss: 44.20752843221029\n","Epoch: 4422/10000, Train Loss: 41.174686431884766, Valid Loss: 44.117889404296875\n","Epoch: 4423/10000, Train Loss: 41.37998962402344, Valid Loss: 44.063323974609375\n","Epoch: 4424/10000, Train Loss: 40.959366191517226, Valid Loss: 44.26546986897787\n","Epoch: 4425/10000, Train Loss: 40.6473239551891, Valid Loss: 44.111358642578125\n","Epoch: 4426/10000, Train Loss: 41.16871712424538, Valid Loss: 44.06860224405924\n","Epoch: 4427/10000, Train Loss: 41.012113050981, Valid Loss: 44.115492502848305\n","Epoch: 4428/10000, Train Loss: 40.96849372170188, Valid Loss: 44.23740895589193\n","Epoch: 4429/10000, Train Loss: 41.064678538929336, Valid Loss: 44.09885025024414\n","Epoch: 4430/10000, Train Loss: 40.54783873124556, Valid Loss: 43.98508326212565\n","Epoch: 4431/10000, Train Loss: 40.63590413873846, Valid Loss: 44.035569508870445\n","Epoch: 4432/10000, Train Loss: 40.80204079367898, Valid Loss: 44.217936197916664\n","Epoch: 4433/10000, Train Loss: 40.67722355235707, Valid Loss: 43.938299814860024\n","Epoch: 4434/10000, Train Loss: 41.27072455666282, Valid Loss: 43.9113883972168\n","Epoch: 4435/10000, Train Loss: 41.14955798062411, Valid Loss: 44.049065907796226\n","Epoch: 4436/10000, Train Loss: 40.96692449396307, Valid Loss: 44.06543223063151\n","Epoch: 4437/10000, Train Loss: 41.067190343683414, Valid Loss: 44.10102971394857\n","Epoch: 4438/10000, Train Loss: 41.09522906216708, Valid Loss: 44.008113861083984\n","Epoch: 4439/10000, Train Loss: 41.195155057040125, Valid Loss: 43.85567855834961\n","Epoch: 4440/10000, Train Loss: 40.93262551047585, Valid Loss: 43.991780598958336\n","Epoch: 4441/10000, Train Loss: 41.14182420210405, Valid Loss: 43.91131846110026\n","Epoch: 4442/10000, Train Loss: 40.85647132179954, Valid Loss: 43.98270161946615\n","Epoch: 4443/10000, Train Loss: 40.804607738148086, Valid Loss: 44.0651741027832\n","Epoch: 4444/10000, Train Loss: 41.08402876420455, Valid Loss: 43.95668411254883\n","Epoch: 4445/10000, Train Loss: 40.99766817959872, Valid Loss: 43.910430908203125\n","Epoch: 4446/10000, Train Loss: 41.24786099520597, Valid Loss: 43.982861836751304\n","Epoch: 4447/10000, Train Loss: 40.72162073308771, Valid Loss: 43.99827575683594\n","Epoch: 4448/10000, Train Loss: 40.93510749123313, Valid Loss: 43.947513580322266\n","Epoch: 4449/10000, Train Loss: 40.89342360063033, Valid Loss: 44.10765838623047\n","Epoch: 4450/10000, Train Loss: 40.776865525679156, Valid Loss: 44.1892458597819\n","Epoch: 4451/10000, Train Loss: 40.913157029585406, Valid Loss: 44.00288645426432\n","Epoch: 4452/10000, Train Loss: 40.75815339521928, Valid Loss: 44.00303395589193\n","Epoch: 4453/10000, Train Loss: 40.81141523881392, Valid Loss: 44.08420054117838\n","Epoch: 4454/10000, Train Loss: 40.37730858542702, Valid Loss: 43.94572321573893\n","Epoch: 4455/10000, Train Loss: 40.89978998357599, Valid Loss: 43.91546122233073\n","Epoch: 4456/10000, Train Loss: 40.74276005138051, Valid Loss: 43.92630132039388\n","Epoch: 4457/10000, Train Loss: 40.40849581631747, Valid Loss: 43.89540990193685\n","Epoch: 4458/10000, Train Loss: 40.69269977916371, Valid Loss: 43.96104303995768\n","Epoch: 4459/10000, Train Loss: 40.82366215098988, Valid Loss: 44.15125274658203\n","Epoch: 4460/10000, Train Loss: 40.74121648615057, Valid Loss: 44.032135009765625\n","Epoch: 4461/10000, Train Loss: 40.87569184736772, Valid Loss: 43.959930419921875\n","Epoch: 4462/10000, Train Loss: 40.84094966541637, Valid Loss: 43.964272816975914\n","Epoch: 4463/10000, Train Loss: 40.353820453990586, Valid Loss: 43.93824259440104\n","Epoch: 4464/10000, Train Loss: 40.69482629949396, Valid Loss: 43.89300791422526\n","Epoch: 4465/10000, Train Loss: 41.293056141246446, Valid Loss: 43.670772552490234\n","Epoch: 4466/10000, Train Loss: 40.48236673528498, Valid Loss: 43.92667897542318\n","Epoch: 4467/10000, Train Loss: 40.67413052645597, Valid Loss: 43.85169982910156\n","Epoch: 4468/10000, Train Loss: 40.74064150723544, Valid Loss: 43.884073893229164\n","Epoch: 4469/10000, Train Loss: 40.599401300603695, Valid Loss: 43.88195292154948\n","Epoch: 4470/10000, Train Loss: 40.79393976384943, Valid Loss: 43.89347712198893\n","Epoch: 4471/10000, Train Loss: 40.676051053133875, Valid Loss: 43.89573287963867\n","Epoch: 4472/10000, Train Loss: 40.911194194446914, Valid Loss: 43.788265228271484\n","Epoch: 4473/10000, Train Loss: 40.88453535600142, Valid Loss: 43.751504262288414\n","Epoch: 4474/10000, Train Loss: 40.82021643898704, Valid Loss: 43.77714411417643\n","Epoch: 4475/10000, Train Loss: 41.15007643266158, Valid Loss: 43.91718673706055\n","Epoch: 4476/10000, Train Loss: 40.876849781383164, Valid Loss: 43.865342458089195\n","Epoch: 4477/10000, Train Loss: 40.51959297873757, Valid Loss: 43.9020741780599\n","Epoch: 4478/10000, Train Loss: 40.70111708207564, Valid Loss: 43.918426513671875\n","Epoch: 4479/10000, Train Loss: 40.87414620139382, Valid Loss: 43.985198974609375\n","Epoch: 4480/10000, Train Loss: 41.06191981922496, Valid Loss: 43.898085276285805\n","Epoch: 4481/10000, Train Loss: 40.94929261641069, Valid Loss: 43.76325607299805\n","Epoch: 4482/10000, Train Loss: 40.51633002541282, Valid Loss: 43.964900970458984\n","Epoch: 4483/10000, Train Loss: 40.65861545909535, Valid Loss: 43.849814097086586\n","Epoch: 4484/10000, Train Loss: 40.31883551857688, Valid Loss: 43.764547983805336\n","Epoch: 4485/10000, Train Loss: 40.62830977006392, Valid Loss: 43.71328481038412\n","Epoch: 4486/10000, Train Loss: 40.68979714133523, Valid Loss: 43.92742665608724\n","Epoch: 4487/10000, Train Loss: 40.592919783158735, Valid Loss: 43.753396352132164\n","Epoch: 4488/10000, Train Loss: 40.48306517167525, Valid Loss: 43.9566281636556\n","Epoch: 4489/10000, Train Loss: 41.05644989013672, Valid Loss: 43.909837086995445\n","Epoch: 4490/10000, Train Loss: 40.75845649025657, Valid Loss: 43.82076899210612\n","Epoch: 4491/10000, Train Loss: 40.57261657714844, Valid Loss: 43.817124684651695\n","Epoch: 4492/10000, Train Loss: 40.18644124811346, Valid Loss: 43.75799433390299\n","Epoch: 4493/10000, Train Loss: 40.9884182323109, Valid Loss: 44.01245880126953\n","Epoch: 4494/10000, Train Loss: 40.8078745061701, Valid Loss: 43.83209482828776\n","Epoch: 4495/10000, Train Loss: 41.108761527321555, Valid Loss: 43.653889973958336\n","Epoch: 4496/10000, Train Loss: 40.45009335604581, Valid Loss: 43.53133900960287\n","Epoch: 4497/10000, Train Loss: 40.47844834761186, Valid Loss: 43.81886545817057\n","Epoch: 4498/10000, Train Loss: 40.36494411121715, Valid Loss: 43.56481170654297\n","Epoch: 4499/10000, Train Loss: 40.89762739701705, Valid Loss: 43.74161148071289\n","Epoch: 4500/10000, Train Loss: 40.8154463334517, Valid Loss: 43.714098612467446\n","Epoch: 4501/10000, Train Loss: 40.282194657759234, Valid Loss: 43.64918009440104\n","Epoch: 4502/10000, Train Loss: 40.592598308216445, Valid Loss: 43.794315338134766\n","Epoch: 4503/10000, Train Loss: 41.08745262839577, Valid Loss: 43.711168924967446\n","Epoch: 4504/10000, Train Loss: 40.752526023171164, Valid Loss: 43.8699951171875\n","Epoch: 4505/10000, Train Loss: 41.00295049493963, Valid Loss: 43.76868438720703\n","Epoch: 4506/10000, Train Loss: 40.223224293101914, Valid Loss: 43.84398523966471\n","Epoch: 4507/10000, Train Loss: 40.475435430353336, Valid Loss: 43.81567509969076\n","Epoch: 4508/10000, Train Loss: 40.48919608376243, Valid Loss: 43.73449198404948\n","Epoch: 4509/10000, Train Loss: 40.115813515403055, Valid Loss: 43.756011962890625\n","Epoch: 4510/10000, Train Loss: 40.50525491887873, Valid Loss: 43.70017751057943\n","Epoch: 4511/10000, Train Loss: 40.59467142278498, Valid Loss: 43.81597773234049\n","Epoch: 4512/10000, Train Loss: 40.396602630615234, Valid Loss: 43.886131286621094\n","Epoch: 4513/10000, Train Loss: 40.57438798384233, Valid Loss: 43.42261250813802\n","Epoch: 4514/10000, Train Loss: 40.74654180353338, Valid Loss: 43.73753356933594\n","Epoch: 4515/10000, Train Loss: 40.67738272927024, Valid Loss: 43.92171732584635\n","Epoch: 4516/10000, Train Loss: 40.45142260464755, Valid Loss: 43.79364903767904\n","Epoch: 4517/10000, Train Loss: 40.437665072354406, Valid Loss: 43.68220647176107\n","Epoch: 4518/10000, Train Loss: 40.30210876464844, Valid Loss: 43.711100260416664\n","Epoch: 4519/10000, Train Loss: 40.44172495061701, Valid Loss: 43.50634256998698\n","Epoch: 4520/10000, Train Loss: 40.43614300814542, Valid Loss: 43.785020192464195\n","Epoch: 4521/10000, Train Loss: 40.079835024746984, Valid Loss: 43.566210428873696\n","Epoch: 4522/10000, Train Loss: 40.59771728515625, Valid Loss: 43.618367513020836\n","Epoch: 4523/10000, Train Loss: 40.37597066705877, Valid Loss: 43.75867462158203\n","Epoch: 4524/10000, Train Loss: 40.221858978271484, Valid Loss: 43.60417175292969\n","Epoch: 4525/10000, Train Loss: 40.16387349909002, Valid Loss: 43.56256230672201\n","Epoch: 4526/10000, Train Loss: 40.26892714066939, Valid Loss: 43.451577504475914\n","Epoch: 4527/10000, Train Loss: 40.7174037586559, Valid Loss: 43.496968587239586\n","Epoch: 4528/10000, Train Loss: 40.23455879905007, Valid Loss: 43.48434066772461\n","Epoch: 4529/10000, Train Loss: 40.39556815407493, Valid Loss: 43.557169596354164\n","Epoch: 4530/10000, Train Loss: 40.83200350674716, Valid Loss: 43.5678965250651\n","Epoch: 4531/10000, Train Loss: 40.25145270607688, Valid Loss: 43.60604731241862\n","Epoch: 4532/10000, Train Loss: 40.201941750266336, Valid Loss: 43.39635721842448\n","Epoch: 4533/10000, Train Loss: 40.451783960515804, Valid Loss: 43.6153933207194\n","Epoch: 4534/10000, Train Loss: 40.219979372891515, Valid Loss: 43.72003682454427\n","Epoch: 4535/10000, Train Loss: 40.65523251620206, Valid Loss: 43.46312967936198\n","Epoch: 4536/10000, Train Loss: 40.26326647671786, Valid Loss: 43.31916173299154\n","Epoch: 4537/10000, Train Loss: 40.23969962380149, Valid Loss: 43.47724151611328\n","Epoch: 4538/10000, Train Loss: 40.305516329678625, Valid Loss: 43.395870208740234\n","Epoch: 4539/10000, Train Loss: 40.299222772771664, Valid Loss: 43.593649546305336\n","Epoch: 4540/10000, Train Loss: 40.13226387717507, Valid Loss: 43.48527399698893\n","Epoch: 4541/10000, Train Loss: 40.24381637573242, Valid Loss: 43.595541636149086\n","Epoch: 4542/10000, Train Loss: 40.38316449252042, Valid Loss: 43.68027114868164\n","Epoch: 4543/10000, Train Loss: 40.51918272538619, Valid Loss: 43.51424662272135\n","Epoch: 4544/10000, Train Loss: 39.98142346468839, Valid Loss: 43.60808563232422\n","Epoch: 4545/10000, Train Loss: 40.37217330932617, Valid Loss: 43.584601084391274\n","Epoch: 4546/10000, Train Loss: 40.52897713401101, Valid Loss: 43.544663747151695\n","Epoch: 4547/10000, Train Loss: 40.10909756747159, Valid Loss: 43.41341018676758\n","Epoch: 4548/10000, Train Loss: 40.603287089954726, Valid Loss: 43.449520111083984\n","Epoch: 4549/10000, Train Loss: 40.299523093483664, Valid Loss: 43.572827657063804\n","Epoch: 4550/10000, Train Loss: 40.15562855113637, Valid Loss: 43.476731618245445\n","Epoch: 4551/10000, Train Loss: 40.35802806507457, Valid Loss: 43.482958475748696\n","Epoch: 4552/10000, Train Loss: 40.3866362138228, Valid Loss: 43.488250732421875\n","Epoch: 4553/10000, Train Loss: 40.16318824074485, Valid Loss: 43.37079620361328\n","Epoch: 4554/10000, Train Loss: 40.17794071544301, Valid Loss: 43.45335133870443\n","Epoch: 4555/10000, Train Loss: 40.34244814786044, Valid Loss: 43.483778635660805\n","Epoch: 4556/10000, Train Loss: 39.946774222634055, Valid Loss: 43.544122060139976\n","Epoch: 4557/10000, Train Loss: 40.43097513372248, Valid Loss: 43.43770090738932\n","Epoch: 4558/10000, Train Loss: 40.24975169788707, Valid Loss: 43.57339731852213\n","Epoch: 4559/10000, Train Loss: 40.418611006303266, Valid Loss: 43.4159901936849\n","Epoch: 4560/10000, Train Loss: 40.018464521928266, Valid Loss: 43.386496225992836\n","Epoch: 4561/10000, Train Loss: 40.055140408602625, Valid Loss: 43.51748530069987\n","Epoch: 4562/10000, Train Loss: 40.16141960837624, Valid Loss: 43.624366760253906\n","Epoch: 4563/10000, Train Loss: 40.190062436190516, Valid Loss: 43.45584487915039\n","Epoch: 4564/10000, Train Loss: 39.95249245383523, Valid Loss: 43.499542236328125\n","Epoch: 4565/10000, Train Loss: 40.015416925603695, Valid Loss: 43.30705897013346\n","Epoch: 4566/10000, Train Loss: 40.18096368963068, Valid Loss: 43.46328862508138\n","Epoch: 4567/10000, Train Loss: 40.055279124866836, Valid Loss: 43.254748026529946\n","Epoch: 4568/10000, Train Loss: 40.104955499822445, Valid Loss: 43.31897226969401\n","Epoch: 4569/10000, Train Loss: 39.87247016213157, Valid Loss: 43.134952545166016\n","Epoch: 4570/10000, Train Loss: 39.900575464422054, Valid Loss: 43.24623489379883\n","Epoch: 4571/10000, Train Loss: 40.013976010409266, Valid Loss: 43.300610860188804\n","Epoch: 4572/10000, Train Loss: 40.02854607321999, Valid Loss: 43.59118398030599\n","Epoch: 4573/10000, Train Loss: 39.793631466952235, Valid Loss: 43.438594818115234\n","Epoch: 4574/10000, Train Loss: 40.17147445678711, Valid Loss: 43.46330769856771\n","Epoch: 4575/10000, Train Loss: 39.94858724420721, Valid Loss: 43.44048182169596\n","Epoch: 4576/10000, Train Loss: 40.18691149624911, Valid Loss: 43.10183842976888\n","Epoch: 4577/10000, Train Loss: 40.05543968894265, Valid Loss: 43.197305043538414\n","Epoch: 4578/10000, Train Loss: 39.88655679876154, Valid Loss: 43.238667805989586\n","Epoch: 4579/10000, Train Loss: 40.07849953391335, Valid Loss: 43.26102193196615\n","Epoch: 4580/10000, Train Loss: 40.071036945689805, Valid Loss: 43.3810666402181\n","Epoch: 4581/10000, Train Loss: 40.02343125776811, Valid Loss: 43.293312072753906\n","Epoch: 4582/10000, Train Loss: 39.736975929953836, Valid Loss: 43.39672342936198\n","Epoch: 4583/10000, Train Loss: 39.91498149525035, Valid Loss: 43.39732360839844\n","Epoch: 4584/10000, Train Loss: 40.02869241887873, Valid Loss: 43.187887827555336\n","Epoch: 4585/10000, Train Loss: 39.884992426091976, Valid Loss: 43.284202575683594\n","Epoch: 4586/10000, Train Loss: 40.010955810546875, Valid Loss: 43.34228006998698\n","Epoch: 4587/10000, Train Loss: 40.08031012795188, Valid Loss: 43.249334971110024\n","Epoch: 4588/10000, Train Loss: 40.01963181929155, Valid Loss: 43.10234069824219\n","Epoch: 4589/10000, Train Loss: 39.236473777077414, Valid Loss: 43.33248392740885\n","Epoch: 4590/10000, Train Loss: 40.022052418101914, Valid Loss: 43.49040603637695\n","Epoch: 4591/10000, Train Loss: 40.228266282515094, Valid Loss: 43.32394027709961\n","Epoch: 4592/10000, Train Loss: 39.78020616011186, Valid Loss: 43.363502502441406\n","Epoch: 4593/10000, Train Loss: 40.329139015891336, Valid Loss: 43.17718505859375\n","Epoch: 4594/10000, Train Loss: 39.92340434681285, Valid Loss: 43.314431508382164\n","Epoch: 4595/10000, Train Loss: 39.70268006758256, Valid Loss: 43.27194086710612\n","Epoch: 4596/10000, Train Loss: 40.10520761663263, Valid Loss: 43.14565912882487\n","Epoch: 4597/10000, Train Loss: 40.28186312588778, Valid Loss: 43.24130376180013\n","Epoch: 4598/10000, Train Loss: 40.60249085859819, Valid Loss: 43.266466776529946\n","Epoch: 4599/10000, Train Loss: 39.9253175908869, Valid Loss: 43.35310745239258\n","Epoch: 4600/10000, Train Loss: 39.826085177334875, Valid Loss: 43.2109743754069\n","Epoch: 4601/10000, Train Loss: 39.813372525301844, Valid Loss: 43.12818272908529\n","Epoch: 4602/10000, Train Loss: 39.546517458829015, Valid Loss: 43.27236557006836\n","Epoch: 4603/10000, Train Loss: 39.83386820012873, Valid Loss: 43.204140981038414\n","Epoch: 4604/10000, Train Loss: 40.0553391196511, Valid Loss: 43.295066833496094\n","Epoch: 4605/10000, Train Loss: 39.895691958340734, Valid Loss: 43.399085998535156\n","Epoch: 4606/10000, Train Loss: 40.56913202459162, Valid Loss: 43.14448547363281\n","Epoch: 4607/10000, Train Loss: 39.652313926003195, Valid Loss: 43.08858744303385\n","Epoch: 4608/10000, Train Loss: 39.64372080022638, Valid Loss: 43.09112294514974\n","Epoch: 4609/10000, Train Loss: 40.198444019664414, Valid Loss: 42.98460261027018\n","Epoch: 4610/10000, Train Loss: 40.29259664362127, Valid Loss: 43.16479365030924\n","Epoch: 4611/10000, Train Loss: 39.87952284379439, Valid Loss: 43.348880767822266\n","Epoch: 4612/10000, Train Loss: 40.327881206165664, Valid Loss: 43.334275563557945\n","Epoch: 4613/10000, Train Loss: 39.73165789517489, Valid Loss: 43.20420710245768\n","Epoch: 4614/10000, Train Loss: 39.84102041071112, Valid Loss: 43.01796086629232\n","Epoch: 4615/10000, Train Loss: 40.32752193104137, Valid Loss: 43.277427673339844\n","Epoch: 4616/10000, Train Loss: 40.176029898903586, Valid Loss: 43.100790659586586\n","Epoch: 4617/10000, Train Loss: 39.71529180353338, Valid Loss: 43.188514709472656\n","Epoch: 4618/10000, Train Loss: 40.2307014465332, Valid Loss: 43.179813385009766\n","Epoch: 4619/10000, Train Loss: 39.856416875665836, Valid Loss: 43.039815266927086\n","Epoch: 4620/10000, Train Loss: 40.029497320001774, Valid Loss: 42.98357009887695\n","Epoch: 4621/10000, Train Loss: 40.03686246004972, Valid Loss: 43.0304209391276\n","Epoch: 4622/10000, Train Loss: 40.02291072498668, Valid Loss: 43.21062342325846\n","Epoch: 4623/10000, Train Loss: 39.677194421941586, Valid Loss: 43.26377487182617\n","Epoch: 4624/10000, Train Loss: 39.58929720791903, Valid Loss: 43.31961186726888\n","Epoch: 4625/10000, Train Loss: 39.4295487837358, Valid Loss: 43.233296712239586\n","Epoch: 4626/10000, Train Loss: 39.44757669622248, Valid Loss: 42.962066650390625\n","Epoch: 4627/10000, Train Loss: 39.453831065784804, Valid Loss: 43.10917282104492\n","Epoch: 4628/10000, Train Loss: 39.83187207308683, Valid Loss: 43.03345743815104\n","Epoch: 4629/10000, Train Loss: 39.45148814808238, Valid Loss: 43.0804812113444\n","Epoch: 4630/10000, Train Loss: 40.18220069191673, Valid Loss: 43.17582321166992\n","Epoch: 4631/10000, Train Loss: 39.916480324485086, Valid Loss: 43.183231353759766\n","Epoch: 4632/10000, Train Loss: 39.437808990478516, Valid Loss: 43.040540059407554\n","Epoch: 4633/10000, Train Loss: 39.719656857577235, Valid Loss: 43.038473765055336\n","Epoch: 4634/10000, Train Loss: 39.23196445811879, Valid Loss: 43.287680308024086\n","Epoch: 4635/10000, Train Loss: 39.91594245217063, Valid Loss: 43.18615595499674\n","Epoch: 4636/10000, Train Loss: 39.97682120583274, Valid Loss: 43.12544504801432\n","Epoch: 4637/10000, Train Loss: 39.61840681596236, Valid Loss: 43.121744791666664\n","Epoch: 4638/10000, Train Loss: 39.55314636230469, Valid Loss: 42.9477793375651\n","Epoch: 4639/10000, Train Loss: 39.47733931107955, Valid Loss: 43.01735305786133\n","Epoch: 4640/10000, Train Loss: 39.33442410555753, Valid Loss: 43.12229029337565\n","Epoch: 4641/10000, Train Loss: 39.75584862448952, Valid Loss: 43.05494817097982\n","Epoch: 4642/10000, Train Loss: 39.61339603770863, Valid Loss: 43.017686208089195\n","Epoch: 4643/10000, Train Loss: 39.3511848449707, Valid Loss: 43.02226257324219\n","Epoch: 4644/10000, Train Loss: 39.83584213256836, Valid Loss: 43.003360748291016\n","Epoch: 4645/10000, Train Loss: 39.65393968061967, Valid Loss: 42.99635442097982\n","Epoch: 4646/10000, Train Loss: 39.63418301669034, Valid Loss: 43.05561447143555\n","Epoch: 4647/10000, Train Loss: 39.675947015935726, Valid Loss: 43.02497863769531\n","Epoch: 4648/10000, Train Loss: 39.88091416792436, Valid Loss: 43.136104583740234\n","Epoch: 4649/10000, Train Loss: 39.56671211936257, Valid Loss: 42.91226704915365\n","Epoch: 4650/10000, Train Loss: 39.45328036221591, Valid Loss: 42.79913202921549\n","Epoch: 4651/10000, Train Loss: 39.57367706298828, Valid Loss: 42.97118377685547\n","Epoch: 4652/10000, Train Loss: 39.6688100641424, Valid Loss: 43.0348866780599\n","Epoch: 4653/10000, Train Loss: 39.78223245794123, Valid Loss: 42.99983469645182\n","Epoch: 4654/10000, Train Loss: 39.54125699129972, Valid Loss: 43.14653396606445\n","Epoch: 4655/10000, Train Loss: 39.80430949818004, Valid Loss: 43.17835362752279\n","Epoch: 4656/10000, Train Loss: 39.469744595614344, Valid Loss: 43.08564249674479\n","Epoch: 4657/10000, Train Loss: 39.689165288751774, Valid Loss: 43.0959726969401\n","Epoch: 4658/10000, Train Loss: 39.55666073885831, Valid Loss: 42.86473846435547\n","Epoch: 4659/10000, Train Loss: 39.62217018821023, Valid Loss: 43.08539835611979\n","Epoch: 4660/10000, Train Loss: 39.6268855008212, Valid Loss: 43.018141428629555\n","Epoch: 4661/10000, Train Loss: 39.62092278220437, Valid Loss: 43.01296742757162\n","Epoch: 4662/10000, Train Loss: 39.47441031716087, Valid Loss: 42.977621714274086\n","Epoch: 4663/10000, Train Loss: 39.51112781871449, Valid Loss: 43.04036204020182\n","Epoch: 4664/10000, Train Loss: 39.584815979003906, Valid Loss: 42.84107971191406\n","Epoch: 4665/10000, Train Loss: 39.358495538884945, Valid Loss: 42.734965006510414\n","Epoch: 4666/10000, Train Loss: 39.73853891546076, Valid Loss: 42.81962585449219\n","Epoch: 4667/10000, Train Loss: 39.816299785267226, Valid Loss: 42.895468393961586\n","Epoch: 4668/10000, Train Loss: 39.54518786343661, Valid Loss: 42.96523793538412\n","Epoch: 4669/10000, Train Loss: 39.54502140391957, Valid Loss: 42.90583038330078\n","Epoch: 4670/10000, Train Loss: 39.436852888627485, Valid Loss: 42.89379374186198\n","Epoch: 4671/10000, Train Loss: 39.6565354087136, Valid Loss: 42.818705240885414\n","Epoch: 4672/10000, Train Loss: 39.388488422740586, Valid Loss: 42.81544876098633\n","Epoch: 4673/10000, Train Loss: 39.44817005504262, Valid Loss: 42.53319422403971\n","Epoch: 4674/10000, Train Loss: 39.697474392977625, Valid Loss: 42.8179931640625\n","Epoch: 4675/10000, Train Loss: 39.528808940540664, Valid Loss: 42.96140670776367\n","Epoch: 4676/10000, Train Loss: 39.01614067771218, Valid Loss: 42.83209991455078\n","Epoch: 4677/10000, Train Loss: 39.472411762584336, Valid Loss: 42.93251419067383\n","Epoch: 4678/10000, Train Loss: 39.21145803278143, Valid Loss: 42.82323328653971\n","Epoch: 4679/10000, Train Loss: 39.22276375510476, Valid Loss: 42.783459981282554\n","Epoch: 4680/10000, Train Loss: 39.40239056673917, Valid Loss: 42.90004221598307\n","Epoch: 4681/10000, Train Loss: 39.45208150690252, Valid Loss: 42.896429697672524\n","Epoch: 4682/10000, Train Loss: 39.71123227206144, Valid Loss: 42.76578013102213\n","Epoch: 4683/10000, Train Loss: 39.607185710560195, Valid Loss: 42.884847005208336\n","Epoch: 4684/10000, Train Loss: 39.64905825528231, Valid Loss: 43.03911209106445\n","Epoch: 4685/10000, Train Loss: 39.36876019564542, Valid Loss: 42.96147918701172\n","Epoch: 4686/10000, Train Loss: 39.51176903464577, Valid Loss: 42.872247060139976\n","Epoch: 4687/10000, Train Loss: 39.423615889115766, Valid Loss: 42.72025934855143\n","Epoch: 4688/10000, Train Loss: 39.4189321344549, Valid Loss: 42.67169443766276\n","Epoch: 4689/10000, Train Loss: 39.00152241099965, Valid Loss: 42.78657531738281\n","Epoch: 4690/10000, Train Loss: 39.46662972190163, Valid Loss: 42.81010945638021\n","Epoch: 4691/10000, Train Loss: 39.08273835615678, Valid Loss: 42.93819808959961\n","Epoch: 4692/10000, Train Loss: 39.66090462424538, Valid Loss: 42.76718012491862\n","Epoch: 4693/10000, Train Loss: 39.7069091796875, Valid Loss: 42.6879768371582\n","Epoch: 4694/10000, Train Loss: 38.6661938753995, Valid Loss: 42.675767262776695\n","Epoch: 4695/10000, Train Loss: 39.908146944913, Valid Loss: 42.84031677246094\n","Epoch: 4696/10000, Train Loss: 39.37068904529918, Valid Loss: 42.7980702718099\n","Epoch: 4697/10000, Train Loss: 39.44693825461648, Valid Loss: 42.946693420410156\n","Epoch: 4698/10000, Train Loss: 39.46305326981978, Valid Loss: 42.6943244934082\n","Epoch: 4699/10000, Train Loss: 39.37500624223189, Valid Loss: 42.60455830891927\n","Epoch: 4700/10000, Train Loss: 39.301575747403234, Valid Loss: 42.73483530680338\n","Epoch: 4701/10000, Train Loss: 39.26302129572088, Valid Loss: 42.74003982543945\n","Epoch: 4702/10000, Train Loss: 39.57851201837713, Valid Loss: 42.73641586303711\n","Epoch: 4703/10000, Train Loss: 39.13788916847923, Valid Loss: 42.92062759399414\n","Epoch: 4704/10000, Train Loss: 39.281597484241836, Valid Loss: 42.741040547688804\n","Epoch: 4705/10000, Train Loss: 39.563614238392226, Valid Loss: 42.791605631510414\n","Epoch: 4706/10000, Train Loss: 39.45147011496804, Valid Loss: 43.0683848063151\n","Epoch: 4707/10000, Train Loss: 39.258641329678625, Valid Loss: 42.91866938273112\n","Epoch: 4708/10000, Train Loss: 39.0897893038663, Valid Loss: 42.94295883178711\n","Epoch: 4709/10000, Train Loss: 39.45397741144354, Valid Loss: 42.74037424723307\n","Epoch: 4710/10000, Train Loss: 38.87034537575462, Valid Loss: 42.692274729410805\n","Epoch: 4711/10000, Train Loss: 38.91830166903409, Valid Loss: 42.52951176961263\n","Epoch: 4712/10000, Train Loss: 39.640663146972656, Valid Loss: 42.63565444946289\n","Epoch: 4713/10000, Train Loss: 39.14404088800604, Valid Loss: 42.690442403157554\n","Epoch: 4714/10000, Train Loss: 39.416913812810726, Valid Loss: 42.60437520345052\n","Epoch: 4715/10000, Train Loss: 39.135182814164594, Valid Loss: 42.42285664876302\n","Epoch: 4716/10000, Train Loss: 39.14158318259499, Valid Loss: 42.385214487711586\n","Epoch: 4717/10000, Train Loss: 39.522917314009234, Valid Loss: 42.62013626098633\n","Epoch: 4718/10000, Train Loss: 39.59101798317649, Valid Loss: 42.59990692138672\n","Epoch: 4719/10000, Train Loss: 39.63101647116921, Valid Loss: 42.5778439839681\n","Epoch: 4720/10000, Train Loss: 38.99706060236151, Valid Loss: 42.58674621582031\n","Epoch: 4721/10000, Train Loss: 39.4061823758212, Valid Loss: 42.6254514058431\n","Epoch: 4722/10000, Train Loss: 39.41958895596591, Valid Loss: 42.5668830871582\n","Epoch: 4723/10000, Train Loss: 39.16691797429865, Valid Loss: 42.536661783854164\n","Epoch: 4724/10000, Train Loss: 39.0077729658647, Valid Loss: 42.74249776204427\n","Epoch: 4725/10000, Train Loss: 39.179987473921344, Valid Loss: 42.69990539550781\n","Epoch: 4726/10000, Train Loss: 39.08606650612571, Valid Loss: 42.729766845703125\n","Epoch: 4727/10000, Train Loss: 39.37169716574929, Valid Loss: 42.45079040527344\n","Epoch: 4728/10000, Train Loss: 38.98329474709251, Valid Loss: 42.664520263671875\n","Epoch: 4729/10000, Train Loss: 39.20337989113548, Valid Loss: 42.7248280843099\n","Epoch: 4730/10000, Train Loss: 39.052559245716445, Valid Loss: 42.45155715942383\n","Epoch: 4731/10000, Train Loss: 39.049012964422054, Valid Loss: 42.752891540527344\n","Epoch: 4732/10000, Train Loss: 39.62438756769354, Valid Loss: 42.697418212890625\n","Epoch: 4733/10000, Train Loss: 39.446664636785336, Valid Loss: 42.6124636332194\n","Epoch: 4734/10000, Train Loss: 39.11635242808949, Valid Loss: 42.46767807006836\n","Epoch: 4735/10000, Train Loss: 38.769836772571914, Valid Loss: 42.5526377360026\n","Epoch: 4736/10000, Train Loss: 39.17481751875444, Valid Loss: 42.53412628173828\n","Epoch: 4737/10000, Train Loss: 39.288575952703304, Valid Loss: 42.52806599934896\n","Epoch: 4738/10000, Train Loss: 38.96025154807351, Valid Loss: 42.380619049072266\n","Epoch: 4739/10000, Train Loss: 38.91641512784091, Valid Loss: 42.620506286621094\n","Epoch: 4740/10000, Train Loss: 39.23726619373668, Valid Loss: 42.53045145670573\n","Epoch: 4741/10000, Train Loss: 39.06882442127574, Valid Loss: 42.42246119181315\n","Epoch: 4742/10000, Train Loss: 38.84799367731268, Valid Loss: 42.573038736979164\n","Epoch: 4743/10000, Train Loss: 38.72915996204723, Valid Loss: 42.79337819417318\n","Epoch: 4744/10000, Train Loss: 38.92412289706144, Valid Loss: 42.469398498535156\n","Epoch: 4745/10000, Train Loss: 38.862296017733485, Valid Loss: 42.31545893351237\n","Epoch: 4746/10000, Train Loss: 39.01851376620206, Valid Loss: 42.52416737874349\n","Epoch: 4747/10000, Train Loss: 38.95332648537376, Valid Loss: 42.46919631958008\n","Epoch: 4748/10000, Train Loss: 38.96867682717063, Valid Loss: 42.637831370035805\n","Epoch: 4749/10000, Train Loss: 39.137448050759055, Valid Loss: 42.53010177612305\n","Epoch: 4750/10000, Train Loss: 38.970970847389914, Valid Loss: 42.55518086751302\n","Epoch: 4751/10000, Train Loss: 39.16300374811346, Valid Loss: 42.47386932373047\n","Epoch: 4752/10000, Train Loss: 38.81690840287642, Valid Loss: 42.456817626953125\n","Epoch: 4753/10000, Train Loss: 39.04984248768199, Valid Loss: 42.48991012573242\n","Epoch: 4754/10000, Train Loss: 38.90431733564897, Valid Loss: 42.612345377604164\n","Epoch: 4755/10000, Train Loss: 39.20584834705699, Valid Loss: 42.68852742513021\n","Epoch: 4756/10000, Train Loss: 39.12835103815252, Valid Loss: 42.48904291788737\n","Epoch: 4757/10000, Train Loss: 38.812780206853695, Valid Loss: 42.473897298177086\n","Epoch: 4758/10000, Train Loss: 38.9929067438299, Valid Loss: 42.53033955891927\n","Epoch: 4759/10000, Train Loss: 38.77853775024414, Valid Loss: 42.531497955322266\n","Epoch: 4760/10000, Train Loss: 39.26078068126332, Valid Loss: 42.520547231038414\n","Epoch: 4761/10000, Train Loss: 39.31820852106268, Valid Loss: 42.49004109700521\n","Epoch: 4762/10000, Train Loss: 39.03561574762518, Valid Loss: 42.55322392781576\n","Epoch: 4763/10000, Train Loss: 38.75501944802024, Valid Loss: 42.50154113769531\n","Epoch: 4764/10000, Train Loss: 39.14175137606534, Valid Loss: 42.4843381245931\n","Epoch: 4765/10000, Train Loss: 38.6077915538441, Valid Loss: 42.491616566975914\n","Epoch: 4766/10000, Train Loss: 38.82741511951793, Valid Loss: 42.48501968383789\n","Epoch: 4767/10000, Train Loss: 38.94353658502752, Valid Loss: 42.35534540812174\n","Epoch: 4768/10000, Train Loss: 38.989988500421696, Valid Loss: 42.23173522949219\n","Epoch: 4769/10000, Train Loss: 38.58885747736151, Valid Loss: 42.39415740966797\n","Epoch: 4770/10000, Train Loss: 39.18470486727628, Valid Loss: 42.41750971476237\n","Epoch: 4771/10000, Train Loss: 39.21974043412642, Valid Loss: 42.47527186075846\n","Epoch: 4772/10000, Train Loss: 38.89653361927379, Valid Loss: 42.50044377644857\n","Epoch: 4773/10000, Train Loss: 38.74341028386896, Valid Loss: 42.49297587076823\n","Epoch: 4774/10000, Train Loss: 38.536264939741656, Valid Loss: 42.29253133138021\n","Epoch: 4775/10000, Train Loss: 39.005163712935015, Valid Loss: 42.43683878580729\n","Epoch: 4776/10000, Train Loss: 38.84580750898881, Valid Loss: 42.531365712483726\n","Epoch: 4777/10000, Train Loss: 38.35305335304954, Valid Loss: 42.56667836507162\n","Epoch: 4778/10000, Train Loss: 38.74947773326527, Valid Loss: 42.44256337483724\n","Epoch: 4779/10000, Train Loss: 38.99653174660423, Valid Loss: 42.43108113606771\n","Epoch: 4780/10000, Train Loss: 39.04993161288175, Valid Loss: 42.22094217936198\n","Epoch: 4781/10000, Train Loss: 38.5053957158869, Valid Loss: 42.30374272664388\n","Epoch: 4782/10000, Train Loss: 38.63205614956942, Valid Loss: 42.27969233194987\n","Epoch: 4783/10000, Train Loss: 38.71705523404208, Valid Loss: 42.38609186808268\n","Epoch: 4784/10000, Train Loss: 38.94198504361239, Valid Loss: 42.19118881225586\n","Epoch: 4785/10000, Train Loss: 38.98271213878285, Valid Loss: 42.18964385986328\n","Epoch: 4786/10000, Train Loss: 38.8366303877397, Valid Loss: 42.13422648111979\n","Epoch: 4787/10000, Train Loss: 38.167969790371984, Valid Loss: 42.306512196858726\n","Epoch: 4788/10000, Train Loss: 38.875059301202946, Valid Loss: 42.20123036702474\n","Epoch: 4789/10000, Train Loss: 38.79307868263938, Valid Loss: 42.346380869547524\n","Epoch: 4790/10000, Train Loss: 38.56617181951349, Valid Loss: 42.36152648925781\n","Epoch: 4791/10000, Train Loss: 38.8792478388006, Valid Loss: 42.28464889526367\n","Epoch: 4792/10000, Train Loss: 38.445130434903234, Valid Loss: 42.378587086995445\n","Epoch: 4793/10000, Train Loss: 38.69780800559304, Valid Loss: 42.21198399861654\n","Epoch: 4794/10000, Train Loss: 38.84366954456676, Valid Loss: 42.517462412516274\n","Epoch: 4795/10000, Train Loss: 38.50775874744762, Valid Loss: 42.172011057535805\n","Epoch: 4796/10000, Train Loss: 38.61543586037376, Valid Loss: 42.26531855265299\n","Epoch: 4797/10000, Train Loss: 38.64400308782404, Valid Loss: 42.5039176940918\n","Epoch: 4798/10000, Train Loss: 38.85530159690163, Valid Loss: 42.63391876220703\n","Epoch: 4799/10000, Train Loss: 38.97053597190163, Valid Loss: 42.59832000732422\n","Epoch: 4800/10000, Train Loss: 38.72090079567649, Valid Loss: 42.536059061686196\n","Epoch: 4801/10000, Train Loss: 38.35243641246449, Valid Loss: 42.61008834838867\n","Epoch: 4802/10000, Train Loss: 38.50974655151367, Valid Loss: 42.527828216552734\n","Epoch: 4803/10000, Train Loss: 38.83319299871271, Valid Loss: 42.410901387532554\n","Epoch: 4804/10000, Train Loss: 38.46621426669034, Valid Loss: 42.11417134602865\n","Epoch: 4805/10000, Train Loss: 39.14137198708274, Valid Loss: 42.296461741129555\n","Epoch: 4806/10000, Train Loss: 38.50725902210582, Valid Loss: 42.226996103922524\n","Epoch: 4807/10000, Train Loss: 38.77045267278498, Valid Loss: 42.234720865885414\n","Epoch: 4808/10000, Train Loss: 38.24948501586914, Valid Loss: 42.26770146687826\n","Epoch: 4809/10000, Train Loss: 38.56124981966886, Valid Loss: 41.888946533203125\n","Epoch: 4810/10000, Train Loss: 38.40209544788707, Valid Loss: 42.17790095011393\n","Epoch: 4811/10000, Train Loss: 38.84428232366388, Valid Loss: 42.20956293741862\n","Epoch: 4812/10000, Train Loss: 38.80958106301048, Valid Loss: 42.16986846923828\n","Epoch: 4813/10000, Train Loss: 38.246904546564274, Valid Loss: 42.40764872233073\n","Epoch: 4814/10000, Train Loss: 38.406701521439985, Valid Loss: 42.30012893676758\n","Epoch: 4815/10000, Train Loss: 38.30620436234908, Valid Loss: 42.287802378336586\n","Epoch: 4816/10000, Train Loss: 38.76681067726829, Valid Loss: 42.383471171061196\n","Epoch: 4817/10000, Train Loss: 38.12300352616744, Valid Loss: 42.339054107666016\n","Epoch: 4818/10000, Train Loss: 38.57689770785245, Valid Loss: 42.23683547973633\n","Epoch: 4819/10000, Train Loss: 38.79454976862127, Valid Loss: 42.18571090698242\n","Epoch: 4820/10000, Train Loss: 38.53765279596502, Valid Loss: 42.12130991617838\n","Epoch: 4821/10000, Train Loss: 38.75283778797496, Valid Loss: 42.316009521484375\n","Epoch: 4822/10000, Train Loss: 38.5397834777832, Valid Loss: 42.145222981770836\n","Epoch: 4823/10000, Train Loss: 38.55420892888849, Valid Loss: 42.132040659586586\n","Epoch: 4824/10000, Train Loss: 38.61461847478693, Valid Loss: 42.2230224609375\n","Epoch: 4825/10000, Train Loss: 38.316655592484906, Valid Loss: 42.23841349283854\n","Epoch: 4826/10000, Train Loss: 38.72043887051669, Valid Loss: 41.94982147216797\n","Epoch: 4827/10000, Train Loss: 38.581969868053086, Valid Loss: 41.88006846110026\n","Epoch: 4828/10000, Train Loss: 38.7096079046076, Valid Loss: 42.07195281982422\n","Epoch: 4829/10000, Train Loss: 38.719317349520594, Valid Loss: 42.069451649983726\n","Epoch: 4830/10000, Train Loss: 38.45897085016424, Valid Loss: 42.15072758992513\n","Epoch: 4831/10000, Train Loss: 38.150171453302555, Valid Loss: 42.078189849853516\n","Epoch: 4832/10000, Train Loss: 38.6191291809082, Valid Loss: 42.301684061686196\n","Epoch: 4833/10000, Train Loss: 38.59982646595348, Valid Loss: 42.23060989379883\n","Epoch: 4834/10000, Train Loss: 38.61866136030717, Valid Loss: 42.24558893839518\n","Epoch: 4835/10000, Train Loss: 38.43124701760032, Valid Loss: 42.00311533610026\n","Epoch: 4836/10000, Train Loss: 38.41161519830877, Valid Loss: 41.99380874633789\n","Epoch: 4837/10000, Train Loss: 38.44305142489347, Valid Loss: 42.148138682047524\n","Epoch: 4838/10000, Train Loss: 38.768806804310195, Valid Loss: 42.26469167073568\n","Epoch: 4839/10000, Train Loss: 38.396142439408735, Valid Loss: 42.09389623006185\n","Epoch: 4840/10000, Train Loss: 38.70719840309837, Valid Loss: 42.0851198832194\n","Epoch: 4841/10000, Train Loss: 38.30344148115678, Valid Loss: 42.04323959350586\n","Epoch: 4842/10000, Train Loss: 38.2656215320934, Valid Loss: 41.98236974080404\n","Epoch: 4843/10000, Train Loss: 38.54268472844904, Valid Loss: 41.97227350870768\n","Epoch: 4844/10000, Train Loss: 38.65719708529386, Valid Loss: 41.94462331136068\n","Epoch: 4845/10000, Train Loss: 38.44743728637695, Valid Loss: 41.91778818766276\n","Epoch: 4846/10000, Train Loss: 38.1825478293679, Valid Loss: 42.13753128051758\n","Epoch: 4847/10000, Train Loss: 38.203010905872695, Valid Loss: 42.0769157409668\n","Epoch: 4848/10000, Train Loss: 38.27501851862127, Valid Loss: 42.03739674886068\n","Epoch: 4849/10000, Train Loss: 38.35175808993253, Valid Loss: 41.8497683207194\n","Epoch: 4850/10000, Train Loss: 38.766512090509586, Valid Loss: 41.88878504435221\n","Epoch: 4851/10000, Train Loss: 38.88247299194336, Valid Loss: 42.04673767089844\n","Epoch: 4852/10000, Train Loss: 38.58754522150213, Valid Loss: 42.098358154296875\n","Epoch: 4853/10000, Train Loss: 38.236379796808414, Valid Loss: 41.95650863647461\n","Epoch: 4854/10000, Train Loss: 38.627745541659266, Valid Loss: 42.08471425374349\n","Epoch: 4855/10000, Train Loss: 38.409869107333094, Valid Loss: 42.092873891194664\n","Epoch: 4856/10000, Train Loss: 38.68142318725586, Valid Loss: 41.92444356282552\n","Epoch: 4857/10000, Train Loss: 38.298181707208805, Valid Loss: 41.886070251464844\n","Epoch: 4858/10000, Train Loss: 38.46909609707919, Valid Loss: 41.794490814208984\n","Epoch: 4859/10000, Train Loss: 38.307110873135656, Valid Loss: 41.92354202270508\n","Epoch: 4860/10000, Train Loss: 38.73963130604137, Valid Loss: 41.99822870890299\n","Epoch: 4861/10000, Train Loss: 38.45683149857955, Valid Loss: 42.14973068237305\n","Epoch: 4862/10000, Train Loss: 37.782409321178086, Valid Loss: 42.02926890055338\n","Epoch: 4863/10000, Train Loss: 38.32020672884855, Valid Loss: 42.03796895345052\n","Epoch: 4864/10000, Train Loss: 38.1568437056108, Valid Loss: 41.92719268798828\n","Epoch: 4865/10000, Train Loss: 38.409176566384055, Valid Loss: 41.82464472452799\n","Epoch: 4866/10000, Train Loss: 38.220792596990414, Valid Loss: 42.06390380859375\n","Epoch: 4867/10000, Train Loss: 38.03402744640004, Valid Loss: 41.9245859781901\n","Epoch: 4868/10000, Train Loss: 38.689733331853695, Valid Loss: 42.14822133382162\n","Epoch: 4869/10000, Train Loss: 38.30026591907848, Valid Loss: 41.87394714355469\n","Epoch: 4870/10000, Train Loss: 38.51491338556463, Valid Loss: 41.94993591308594\n","Epoch: 4871/10000, Train Loss: 38.111910039728336, Valid Loss: 41.884239196777344\n","Epoch: 4872/10000, Train Loss: 38.045407728715375, Valid Loss: 42.11617660522461\n","Epoch: 4873/10000, Train Loss: 38.28415229103782, Valid Loss: 42.12712097167969\n","Epoch: 4874/10000, Train Loss: 38.318749861283735, Valid Loss: 42.125694274902344\n","Epoch: 4875/10000, Train Loss: 38.46376627141779, Valid Loss: 41.9557139078776\n","Epoch: 4876/10000, Train Loss: 38.083377838134766, Valid Loss: 41.8759511311849\n","Epoch: 4877/10000, Train Loss: 38.31568041714755, Valid Loss: 41.81079355875651\n","Epoch: 4878/10000, Train Loss: 38.057922710071914, Valid Loss: 41.89218012491862\n","Epoch: 4879/10000, Train Loss: 38.158822839910336, Valid Loss: 41.998914082845054\n","Epoch: 4880/10000, Train Loss: 37.96334804188121, Valid Loss: 41.99926630655924\n","Epoch: 4881/10000, Train Loss: 38.24153553355824, Valid Loss: 42.21040598551432\n","Epoch: 4882/10000, Train Loss: 38.248788660222836, Valid Loss: 42.10002899169922\n","Epoch: 4883/10000, Train Loss: 38.60322397405451, Valid Loss: 42.03533808390299\n","Epoch: 4884/10000, Train Loss: 37.82368399880149, Valid Loss: 42.12411244710287\n","Epoch: 4885/10000, Train Loss: 38.3080000443892, Valid Loss: 42.05584589640299\n","Epoch: 4886/10000, Train Loss: 38.46846528486772, Valid Loss: 41.795998891194664\n","Epoch: 4887/10000, Train Loss: 38.39673337069425, Valid Loss: 42.04398091634115\n","Epoch: 4888/10000, Train Loss: 37.885896856134586, Valid Loss: 41.930458068847656\n","Epoch: 4889/10000, Train Loss: 38.14208013361151, Valid Loss: 41.783529917399086\n","Epoch: 4890/10000, Train Loss: 38.45437309958718, Valid Loss: 41.72295633951823\n","Epoch: 4891/10000, Train Loss: 37.698673248291016, Valid Loss: 41.776405334472656\n","Epoch: 4892/10000, Train Loss: 38.48930566961115, Valid Loss: 42.02760569254557\n","Epoch: 4893/10000, Train Loss: 38.221586054021664, Valid Loss: 42.00914510091146\n","Epoch: 4894/10000, Train Loss: 38.21570483121005, Valid Loss: 41.90853627522787\n","Epoch: 4895/10000, Train Loss: 38.27611819180575, Valid Loss: 41.78738530476888\n","Epoch: 4896/10000, Train Loss: 38.730955297296696, Valid Loss: 41.83389409383138\n","Epoch: 4897/10000, Train Loss: 37.74750726873224, Valid Loss: 41.922401428222656\n","Epoch: 4898/10000, Train Loss: 38.32497718117454, Valid Loss: 41.782952626546226\n","Epoch: 4899/10000, Train Loss: 38.202240683815695, Valid Loss: 41.79516347249349\n","Epoch: 4900/10000, Train Loss: 37.934919183904476, Valid Loss: 41.637158711751304\n","Epoch: 4901/10000, Train Loss: 38.199043620716445, Valid Loss: 41.77724838256836\n","Epoch: 4902/10000, Train Loss: 38.34241138805043, Valid Loss: 41.85742060343424\n","Epoch: 4903/10000, Train Loss: 37.90227057717063, Valid Loss: 41.947601318359375\n","Epoch: 4904/10000, Train Loss: 38.38143574107777, Valid Loss: 42.07940800984701\n","Epoch: 4905/10000, Train Loss: 38.133343783291906, Valid Loss: 41.75835673014323\n","Epoch: 4906/10000, Train Loss: 38.024789636785336, Valid Loss: 41.46061452229818\n","Epoch: 4907/10000, Train Loss: 38.35780819979581, Valid Loss: 41.76927693684896\n","Epoch: 4908/10000, Train Loss: 38.212461644952946, Valid Loss: 41.88522211710612\n","Epoch: 4909/10000, Train Loss: 38.56233874234286, Valid Loss: 41.91987609863281\n","Epoch: 4910/10000, Train Loss: 38.15958161787553, Valid Loss: 41.75287755330404\n","Epoch: 4911/10000, Train Loss: 37.72932434082031, Valid Loss: 41.843098958333336\n","Epoch: 4912/10000, Train Loss: 38.18497154929421, Valid Loss: 41.5115966796875\n","Epoch: 4913/10000, Train Loss: 38.103939749977805, Valid Loss: 41.5728874206543\n","Epoch: 4914/10000, Train Loss: 37.836605072021484, Valid Loss: 41.78020095825195\n","Epoch: 4915/10000, Train Loss: 38.02535351839933, Valid Loss: 41.790855407714844\n","Epoch: 4916/10000, Train Loss: 37.8814170143821, Valid Loss: 41.755401611328125\n","Epoch: 4917/10000, Train Loss: 37.96016242287376, Valid Loss: 41.6619987487793\n","Epoch: 4918/10000, Train Loss: 37.62724755027077, Valid Loss: 41.869276682535805\n","Epoch: 4919/10000, Train Loss: 38.16600383411754, Valid Loss: 41.80401102701823\n","Epoch: 4920/10000, Train Loss: 38.551274039528586, Valid Loss: 41.87008285522461\n","Epoch: 4921/10000, Train Loss: 37.86719166148793, Valid Loss: 41.80280431111654\n","Epoch: 4922/10000, Train Loss: 37.730869640003554, Valid Loss: 41.75073496500651\n","Epoch: 4923/10000, Train Loss: 37.63851755315607, Valid Loss: 41.57817586263021\n","Epoch: 4924/10000, Train Loss: 38.17877474698153, Valid Loss: 41.792039235432945\n","Epoch: 4925/10000, Train Loss: 38.10658784346147, Valid Loss: 41.69308853149414\n","Epoch: 4926/10000, Train Loss: 37.257184115323156, Valid Loss: 41.735713958740234\n","Epoch: 4927/10000, Train Loss: 37.655127785422586, Valid Loss: 42.01483917236328\n","Epoch: 4928/10000, Train Loss: 37.79233308271928, Valid Loss: 41.7257932027181\n","Epoch: 4929/10000, Train Loss: 38.040049119429156, Valid Loss: 41.863015492757164\n","Epoch: 4930/10000, Train Loss: 37.93746705488725, Valid Loss: 41.770121256510414\n","Epoch: 4931/10000, Train Loss: 37.62938031283292, Valid Loss: 41.78410720825195\n","Epoch: 4932/10000, Train Loss: 37.727295962246984, Valid Loss: 41.72541046142578\n","Epoch: 4933/10000, Train Loss: 37.7643269625577, Valid Loss: 41.767765045166016\n","Epoch: 4934/10000, Train Loss: 37.790657390247695, Valid Loss: 41.776241302490234\n","Epoch: 4935/10000, Train Loss: 38.3522817438299, Valid Loss: 41.706921895345054\n","Epoch: 4936/10000, Train Loss: 37.65651113336737, Valid Loss: 41.713521321614586\n","Epoch: 4937/10000, Train Loss: 38.02401560003107, Valid Loss: 41.91204706827799\n","Epoch: 4938/10000, Train Loss: 38.07276985862038, Valid Loss: 41.80332565307617\n","Epoch: 4939/10000, Train Loss: 37.96954761851918, Valid Loss: 41.83340708414713\n","Epoch: 4940/10000, Train Loss: 37.89997447620738, Valid Loss: 41.73108800252279\n","Epoch: 4941/10000, Train Loss: 37.6496186689897, Valid Loss: 41.736810048421226\n","Epoch: 4942/10000, Train Loss: 38.30148627541282, Valid Loss: 41.68024190266927\n","Epoch: 4943/10000, Train Loss: 37.96208225597035, Valid Loss: 41.69266891479492\n","Epoch: 4944/10000, Train Loss: 37.7460112138228, Valid Loss: 41.81110763549805\n","Epoch: 4945/10000, Train Loss: 37.7216269753196, Valid Loss: 41.72906621297201\n","Epoch: 4946/10000, Train Loss: 37.65992494062944, Valid Loss: 41.363897959391274\n","Epoch: 4947/10000, Train Loss: 37.56710572676225, Valid Loss: 41.74286651611328\n","Epoch: 4948/10000, Train Loss: 37.64046721024947, Valid Loss: 41.54490280151367\n","Epoch: 4949/10000, Train Loss: 38.09542049061168, Valid Loss: 41.57449086507162\n","Epoch: 4950/10000, Train Loss: 37.97511014071378, Valid Loss: 41.529720306396484\n","Epoch: 4951/10000, Train Loss: 38.14148087935014, Valid Loss: 41.546024322509766\n","Epoch: 4952/10000, Train Loss: 37.88832092285156, Valid Loss: 41.560431162516274\n","Epoch: 4953/10000, Train Loss: 37.57291759144176, Valid Loss: 41.639146169026695\n","Epoch: 4954/10000, Train Loss: 37.56824562766335, Valid Loss: 41.81241226196289\n","Epoch: 4955/10000, Train Loss: 38.13089925592596, Valid Loss: 41.709014892578125\n","Epoch: 4956/10000, Train Loss: 38.1149656122381, Valid Loss: 41.61708196004232\n","Epoch: 4957/10000, Train Loss: 37.592553572221235, Valid Loss: 41.603633880615234\n","Epoch: 4958/10000, Train Loss: 37.996002197265625, Valid Loss: 41.4332160949707\n","Epoch: 4959/10000, Train Loss: 38.08983022516424, Valid Loss: 41.39078013102213\n","Epoch: 4960/10000, Train Loss: 37.52131271362305, Valid Loss: 41.63568623860677\n","Epoch: 4961/10000, Train Loss: 38.398784984241836, Valid Loss: 41.69446055094401\n","Epoch: 4962/10000, Train Loss: 37.35249120538885, Valid Loss: 41.644432067871094\n","Epoch: 4963/10000, Train Loss: 37.70960686423562, Valid Loss: 41.66237131754557\n","Epoch: 4964/10000, Train Loss: 37.54301521994851, Valid Loss: 41.55776850382487\n","Epoch: 4965/10000, Train Loss: 38.368384621360086, Valid Loss: 41.51527659098307\n","Epoch: 4966/10000, Train Loss: 37.250055833296344, Valid Loss: 41.58980941772461\n","Epoch: 4967/10000, Train Loss: 38.099544525146484, Valid Loss: 41.50370661417643\n","Epoch: 4968/10000, Train Loss: 37.710968017578125, Valid Loss: 41.455544789632164\n","Epoch: 4969/10000, Train Loss: 37.589425173672765, Valid Loss: 41.52007929484049\n","Epoch: 4970/10000, Train Loss: 37.694256175648086, Valid Loss: 41.62281799316406\n","Epoch: 4971/10000, Train Loss: 37.829307556152344, Valid Loss: 41.63751475016276\n","Epoch: 4972/10000, Train Loss: 38.16258170387962, Valid Loss: 41.56263097127279\n","Epoch: 4973/10000, Train Loss: 38.05342656915838, Valid Loss: 41.31829325358073\n","Epoch: 4974/10000, Train Loss: 37.78682015158913, Valid Loss: 41.47813924153646\n","Epoch: 4975/10000, Train Loss: 37.61444091796875, Valid Loss: 41.39274215698242\n","Epoch: 4976/10000, Train Loss: 37.52438458529386, Valid Loss: 41.497076670328774\n","Epoch: 4977/10000, Train Loss: 37.502967834472656, Valid Loss: 41.59735234578451\n","Epoch: 4978/10000, Train Loss: 38.000322515314274, Valid Loss: 41.44922637939453\n","Epoch: 4979/10000, Train Loss: 37.449304060502485, Valid Loss: 41.54770024617513\n","Epoch: 4980/10000, Train Loss: 37.38785136829723, Valid Loss: 41.373976389567055\n","Epoch: 4981/10000, Train Loss: 37.60363110628995, Valid Loss: 41.50844065348307\n","Epoch: 4982/10000, Train Loss: 37.43748543479226, Valid Loss: 41.48053741455078\n","Epoch: 4983/10000, Train Loss: 37.625697049227625, Valid Loss: 41.42728042602539\n","Epoch: 4984/10000, Train Loss: 37.52457948164506, Valid Loss: 41.52334213256836\n","Epoch: 4985/10000, Train Loss: 37.54075934670188, Valid Loss: 41.62905502319336\n","Epoch: 4986/10000, Train Loss: 37.84627498279918, Valid Loss: 41.50683085123698\n","Epoch: 4987/10000, Train Loss: 37.3319206237793, Valid Loss: 41.46310170491537\n","Epoch: 4988/10000, Train Loss: 37.104324687610976, Valid Loss: 41.48546346028646\n","Epoch: 4989/10000, Train Loss: 37.54555823586204, Valid Loss: 41.604366302490234\n","Epoch: 4990/10000, Train Loss: 37.480656363747336, Valid Loss: 41.452195485432945\n","Epoch: 4991/10000, Train Loss: 37.388024763627485, Valid Loss: 41.41991297403971\n","Epoch: 4992/10000, Train Loss: 37.583376450972125, Valid Loss: 41.430520375569664\n","Epoch: 4993/10000, Train Loss: 37.91415439952504, Valid Loss: 41.577013651529946\n","Epoch: 4994/10000, Train Loss: 37.999144467440516, Valid Loss: 41.626322428385414\n","Epoch: 4995/10000, Train Loss: 37.594159906560726, Valid Loss: 41.388720194498696\n","Epoch: 4996/10000, Train Loss: 37.05162048339844, Valid Loss: 41.36589431762695\n","Epoch: 4997/10000, Train Loss: 37.71560772982511, Valid Loss: 41.69158935546875\n","Epoch: 4998/10000, Train Loss: 37.489018873734906, Valid Loss: 41.6797981262207\n","Epoch: 4999/10000, Train Loss: 37.8901762528853, Valid Loss: 41.5257453918457\n","Epoch: 5000/10000, Train Loss: 37.44212688099254, Valid Loss: 41.40510813395182\n","Epoch: 5001/10000, Train Loss: 37.349113117564805, Valid Loss: 41.668076833089195\n","Epoch: 5002/10000, Train Loss: 37.69163651899858, Valid Loss: 41.39908345540365\n","Epoch: 5003/10000, Train Loss: 37.1741117997603, Valid Loss: 41.148193359375\n","Epoch: 5004/10000, Train Loss: 38.07765197753906, Valid Loss: 41.27609507242838\n","Epoch: 5005/10000, Train Loss: 37.608543395996094, Valid Loss: 41.46843338012695\n","Epoch: 5006/10000, Train Loss: 37.52512498335405, Valid Loss: 41.649557749430336\n","Epoch: 5007/10000, Train Loss: 37.6949296431108, Valid Loss: 41.652809143066406\n","Epoch: 5008/10000, Train Loss: 37.51261173595082, Valid Loss: 41.45335261027018\n","Epoch: 5009/10000, Train Loss: 36.934636549516156, Valid Loss: 41.45727030436198\n","Epoch: 5010/10000, Train Loss: 37.31470697576349, Valid Loss: 41.39132563273112\n","Epoch: 5011/10000, Train Loss: 37.66136100075462, Valid Loss: 41.36573918660482\n","Epoch: 5012/10000, Train Loss: 37.456762140447445, Valid Loss: 41.24371337890625\n","Epoch: 5013/10000, Train Loss: 37.723088351163, Valid Loss: 41.30804443359375\n","Epoch: 5014/10000, Train Loss: 37.57147147438743, Valid Loss: 41.350268046061196\n","Epoch: 5015/10000, Train Loss: 37.31108648126776, Valid Loss: 41.2608642578125\n","Epoch: 5016/10000, Train Loss: 37.149508042769, Valid Loss: 41.33487192789713\n","Epoch: 5017/10000, Train Loss: 37.26681900024414, Valid Loss: 41.390289306640625\n","Epoch: 5018/10000, Train Loss: 37.07331640070135, Valid Loss: 41.31502787272135\n","Epoch: 5019/10000, Train Loss: 37.71739092740145, Valid Loss: 41.25927861531576\n","Epoch: 5020/10000, Train Loss: 37.29636764526367, Valid Loss: 41.30369313557943\n","Epoch: 5021/10000, Train Loss: 37.3161208412864, Valid Loss: 41.291263580322266\n","Epoch: 5022/10000, Train Loss: 37.32442717118697, Valid Loss: 41.551316579182945\n","Epoch: 5023/10000, Train Loss: 37.42835374311967, Valid Loss: 41.446798960367836\n","Epoch: 5024/10000, Train Loss: 37.568422837690875, Valid Loss: 41.46700541178385\n","Epoch: 5025/10000, Train Loss: 37.47056094082919, Valid Loss: 41.20791753133138\n","Epoch: 5026/10000, Train Loss: 37.1978083523837, Valid Loss: 41.12766901652018\n","Epoch: 5027/10000, Train Loss: 37.03206461126154, Valid Loss: 41.3375498453776\n","Epoch: 5028/10000, Train Loss: 37.17534637451172, Valid Loss: 41.25359598795573\n","Epoch: 5029/10000, Train Loss: 37.7834437977184, Valid Loss: 41.121297200520836\n","Epoch: 5030/10000, Train Loss: 37.305761163884945, Valid Loss: 41.31947708129883\n","Epoch: 5031/10000, Train Loss: 37.49360240589488, Valid Loss: 41.1904551188151\n","Epoch: 5032/10000, Train Loss: 37.51924514770508, Valid Loss: 41.25671641031901\n","Epoch: 5033/10000, Train Loss: 37.68162952769887, Valid Loss: 40.97272491455078\n","Epoch: 5034/10000, Train Loss: 37.378713087602094, Valid Loss: 41.170701344807945\n","Epoch: 5035/10000, Train Loss: 37.38102895563299, Valid Loss: 41.37750371297201\n","Epoch: 5036/10000, Train Loss: 37.278644214976914, Valid Loss: 41.306549072265625\n","Epoch: 5037/10000, Train Loss: 37.35750475796786, Valid Loss: 41.32194137573242\n","Epoch: 5038/10000, Train Loss: 37.30683413418856, Valid Loss: 41.33470916748047\n","Epoch: 5039/10000, Train Loss: 37.283997622403234, Valid Loss: 41.291394551595054\n","Epoch: 5040/10000, Train Loss: 37.04892904108221, Valid Loss: 41.16381327311198\n","Epoch: 5041/10000, Train Loss: 36.86153134432706, Valid Loss: 41.39175923665365\n","Epoch: 5042/10000, Train Loss: 37.366978038441054, Valid Loss: 41.30302302042643\n","Epoch: 5043/10000, Train Loss: 37.78019332885742, Valid Loss: 41.213419596354164\n","Epoch: 5044/10000, Train Loss: 38.00312319668856, Valid Loss: 41.16132481892904\n","Epoch: 5045/10000, Train Loss: 37.09095694802024, Valid Loss: 41.233811696370445\n","Epoch: 5046/10000, Train Loss: 37.32597455111417, Valid Loss: 41.083011627197266\n","Epoch: 5047/10000, Train Loss: 37.37011649391868, Valid Loss: 41.28788503011068\n","Epoch: 5048/10000, Train Loss: 37.207801125266336, Valid Loss: 41.07782745361328\n","Epoch: 5049/10000, Train Loss: 37.313669724897906, Valid Loss: 41.277634938557945\n","Epoch: 5050/10000, Train Loss: 36.89777304909446, Valid Loss: 41.307446797688804\n","Epoch: 5051/10000, Train Loss: 37.05896828391335, Valid Loss: 41.26742299397787\n","Epoch: 5052/10000, Train Loss: 37.468318939208984, Valid Loss: 41.223244984944664\n","Epoch: 5053/10000, Train Loss: 37.4144533330744, Valid Loss: 41.096795399983726\n","Epoch: 5054/10000, Train Loss: 37.13918339122426, Valid Loss: 41.14791742960612\n","Epoch: 5055/10000, Train Loss: 36.85077251087535, Valid Loss: 41.04692713419596\n","Epoch: 5056/10000, Train Loss: 37.137915177778765, Valid Loss: 41.09397633870443\n","Epoch: 5057/10000, Train Loss: 37.4288083856756, Valid Loss: 41.029799143473305\n","Epoch: 5058/10000, Train Loss: 36.88071719082919, Valid Loss: 41.0900993347168\n","Epoch: 5059/10000, Train Loss: 36.78070345791903, Valid Loss: 41.105508168538414\n","Epoch: 5060/10000, Train Loss: 37.44558611783114, Valid Loss: 41.243508656819664\n","Epoch: 5061/10000, Train Loss: 37.19209081476385, Valid Loss: 41.239280700683594\n","Epoch: 5062/10000, Train Loss: 37.125856226140804, Valid Loss: 41.261365254720054\n","Epoch: 5063/10000, Train Loss: 36.96269780939276, Valid Loss: 41.16677983601888\n","Epoch: 5064/10000, Train Loss: 36.96573222767223, Valid Loss: 41.246002197265625\n","Epoch: 5065/10000, Train Loss: 37.39317564530806, Valid Loss: 41.21680577596029\n","Epoch: 5066/10000, Train Loss: 37.16475850885565, Valid Loss: 41.505533854166664\n","Epoch: 5067/10000, Train Loss: 36.93593285300515, Valid Loss: 41.35154469807943\n","Epoch: 5068/10000, Train Loss: 37.1162223815918, Valid Loss: 41.145164489746094\n","Epoch: 5069/10000, Train Loss: 36.78493465076793, Valid Loss: 41.185410817464195\n","Epoch: 5070/10000, Train Loss: 36.841292988170274, Valid Loss: 41.15271886189779\n","Epoch: 5071/10000, Train Loss: 37.98044274070046, Valid Loss: 41.013651529947914\n","Epoch: 5072/10000, Train Loss: 36.9755859375, Valid Loss: 41.05828857421875\n","Epoch: 5073/10000, Train Loss: 36.95590591430664, Valid Loss: 40.96406682332357\n","Epoch: 5074/10000, Train Loss: 36.910160064697266, Valid Loss: 41.061744689941406\n","Epoch: 5075/10000, Train Loss: 37.36739869551225, Valid Loss: 41.09567896525065\n","Epoch: 5076/10000, Train Loss: 36.8978236805309, Valid Loss: 41.127312978108726\n","Epoch: 5077/10000, Train Loss: 36.90885786576705, Valid Loss: 41.097896575927734\n","Epoch: 5078/10000, Train Loss: 36.6150315024636, Valid Loss: 40.971482594807945\n","Epoch: 5079/10000, Train Loss: 37.03252272172408, Valid Loss: 41.005069732666016\n","Epoch: 5080/10000, Train Loss: 37.6448201266202, Valid Loss: 41.082664489746094\n","Epoch: 5081/10000, Train Loss: 37.05447838523171, Valid Loss: 41.2013905843099\n","Epoch: 5082/10000, Train Loss: 36.789090936834164, Valid Loss: 41.075094858805336\n","Epoch: 5083/10000, Train Loss: 37.071598052978516, Valid Loss: 41.09333292643229\n","Epoch: 5084/10000, Train Loss: 37.09290279041637, Valid Loss: 41.11442438761393\n","Epoch: 5085/10000, Train Loss: 37.05977179787376, Valid Loss: 41.04680252075195\n","Epoch: 5086/10000, Train Loss: 37.64393997192383, Valid Loss: 41.173519134521484\n","Epoch: 5087/10000, Train Loss: 37.072785810990766, Valid Loss: 41.403316497802734\n","Epoch: 5088/10000, Train Loss: 36.7680119601163, Valid Loss: 41.29624557495117\n","Epoch: 5089/10000, Train Loss: 37.52593439275568, Valid Loss: 41.152016957600914\n","Epoch: 5090/10000, Train Loss: 37.05389196222479, Valid Loss: 41.10456085205078\n","Epoch: 5091/10000, Train Loss: 36.929753737016156, Valid Loss: 41.179412841796875\n","Epoch: 5092/10000, Train Loss: 37.070032986727625, Valid Loss: 41.01336415608724\n","Epoch: 5093/10000, Train Loss: 37.53772180730646, Valid Loss: 40.81930796305338\n","Epoch: 5094/10000, Train Loss: 37.402131514115766, Valid Loss: 41.04794438680013\n","Epoch: 5095/10000, Train Loss: 36.66193840720437, Valid Loss: 41.13683954874674\n","Epoch: 5096/10000, Train Loss: 37.194029721346766, Valid Loss: 41.12761688232422\n","Epoch: 5097/10000, Train Loss: 36.9413781599565, Valid Loss: 41.02582295735677\n","Epoch: 5098/10000, Train Loss: 37.209931113503195, Valid Loss: 41.115074157714844\n","Epoch: 5099/10000, Train Loss: 36.81452387029474, Valid Loss: 40.953758239746094\n","Epoch: 5100/10000, Train Loss: 37.50290229103782, Valid Loss: 40.86468251546224\n","Epoch: 5101/10000, Train Loss: 36.984183918346055, Valid Loss: 40.766222635904946\n","Epoch: 5102/10000, Train Loss: 37.219730377197266, Valid Loss: 41.00288391113281\n","Epoch: 5103/10000, Train Loss: 37.05971284346147, Valid Loss: 40.836535135904946\n","Epoch: 5104/10000, Train Loss: 36.99970522793856, Valid Loss: 41.13690312703451\n","Epoch: 5105/10000, Train Loss: 37.1225832158869, Valid Loss: 41.0038096110026\n","Epoch: 5106/10000, Train Loss: 37.1318772055886, Valid Loss: 41.030808766682945\n","Epoch: 5107/10000, Train Loss: 37.15226364135742, Valid Loss: 41.1402333577474\n","Epoch: 5108/10000, Train Loss: 37.34700428355824, Valid Loss: 41.12649154663086\n","Epoch: 5109/10000, Train Loss: 36.52836123379794, Valid Loss: 40.822462717692055\n","Epoch: 5110/10000, Train Loss: 37.179257132790305, Valid Loss: 40.973714192708336\n","Epoch: 5111/10000, Train Loss: 37.08867159756747, Valid Loss: 41.04265848795573\n","Epoch: 5112/10000, Train Loss: 36.71574401855469, Valid Loss: 40.971195220947266\n","Epoch: 5113/10000, Train Loss: 36.637812874533914, Valid Loss: 40.977333068847656\n","Epoch: 5114/10000, Train Loss: 36.88290058482777, Valid Loss: 40.94709904988607\n","Epoch: 5115/10000, Train Loss: 37.012547579678625, Valid Loss: 40.877271016438804\n","Epoch: 5116/10000, Train Loss: 37.04185555197976, Valid Loss: 40.96847788492838\n","Epoch: 5117/10000, Train Loss: 37.43421797318892, Valid Loss: 40.77062733968099\n","Epoch: 5118/10000, Train Loss: 37.087251836603336, Valid Loss: 40.96327336629232\n","Epoch: 5119/10000, Train Loss: 36.6232383034446, Valid Loss: 40.92669169108073\n","Epoch: 5120/10000, Train Loss: 36.95698304609819, Valid Loss: 40.83831024169922\n","Epoch: 5121/10000, Train Loss: 36.97507650201971, Valid Loss: 40.923638661702476\n","Epoch: 5122/10000, Train Loss: 37.47933439774947, Valid Loss: 40.9906374613444\n","Epoch: 5123/10000, Train Loss: 37.22258481112394, Valid Loss: 40.90430450439453\n","Epoch: 5124/10000, Train Loss: 36.87658032503995, Valid Loss: 40.915992736816406\n","Epoch: 5125/10000, Train Loss: 36.454470200972125, Valid Loss: 41.06670125325521\n","Epoch: 5126/10000, Train Loss: 36.65481393987482, Valid Loss: 40.92436854044596\n","Epoch: 5127/10000, Train Loss: 36.77718457308683, Valid Loss: 40.82967758178711\n","Epoch: 5128/10000, Train Loss: 36.92239969426935, Valid Loss: 40.84735616048177\n","Epoch: 5129/10000, Train Loss: 36.57310416481712, Valid Loss: 40.73359807332357\n","Epoch: 5130/10000, Train Loss: 36.82866356589577, Valid Loss: 40.8862419128418\n","Epoch: 5131/10000, Train Loss: 37.001404155384414, Valid Loss: 40.73395538330078\n","Epoch: 5132/10000, Train Loss: 36.87042583118785, Valid Loss: 40.98847961425781\n","Epoch: 5133/10000, Train Loss: 36.7307805148038, Valid Loss: 40.8447380065918\n","Epoch: 5134/10000, Train Loss: 36.975237759676844, Valid Loss: 40.79990005493164\n","Epoch: 5135/10000, Train Loss: 36.820279901677914, Valid Loss: 40.91704559326172\n","Epoch: 5136/10000, Train Loss: 37.03250572898171, Valid Loss: 40.75197092692057\n","Epoch: 5137/10000, Train Loss: 36.71586123379794, Valid Loss: 40.8337516784668\n","Epoch: 5138/10000, Train Loss: 36.77962875366211, Valid Loss: 40.90234502156576\n","Epoch: 5139/10000, Train Loss: 36.98191937533292, Valid Loss: 40.90685526529948\n","Epoch: 5140/10000, Train Loss: 36.4808384288441, Valid Loss: 40.8445676167806\n","Epoch: 5141/10000, Train Loss: 36.32821759310636, Valid Loss: 40.908346811930336\n","Epoch: 5142/10000, Train Loss: 36.77587301080877, Valid Loss: 40.90531794230143\n","Epoch: 5143/10000, Train Loss: 36.98933271928267, Valid Loss: 40.80920155843099\n","Epoch: 5144/10000, Train Loss: 37.12698607011275, Valid Loss: 40.87694422403971\n","Epoch: 5145/10000, Train Loss: 36.91092508489435, Valid Loss: 40.89118194580078\n","Epoch: 5146/10000, Train Loss: 37.00464283336293, Valid Loss: 40.75576655069987\n","Epoch: 5147/10000, Train Loss: 36.701137195933946, Valid Loss: 40.865918477376304\n","Epoch: 5148/10000, Train Loss: 36.69663828069513, Valid Loss: 41.0058479309082\n","Epoch: 5149/10000, Train Loss: 36.460635445334695, Valid Loss: 40.93877156575521\n","Epoch: 5150/10000, Train Loss: 36.57064715298739, Valid Loss: 40.93853251139323\n","Epoch: 5151/10000, Train Loss: 36.55330970070579, Valid Loss: 40.827534993489586\n","Epoch: 5152/10000, Train Loss: 37.21912453391335, Valid Loss: 40.72467295328776\n","Epoch: 5153/10000, Train Loss: 36.59248143976385, Valid Loss: 40.805562337239586\n","Epoch: 5154/10000, Train Loss: 36.90039270574396, Valid Loss: 40.720375061035156\n","Epoch: 5155/10000, Train Loss: 36.57520640980113, Valid Loss: 40.87089284261068\n","Epoch: 5156/10000, Train Loss: 36.982831781560726, Valid Loss: 40.72411219278971\n","Epoch: 5157/10000, Train Loss: 36.95456660877574, Valid Loss: 40.77050272623698\n","Epoch: 5158/10000, Train Loss: 36.16621884432706, Valid Loss: 40.85469055175781\n","Epoch: 5159/10000, Train Loss: 36.43524724786932, Valid Loss: 40.94990539550781\n","Epoch: 5160/10000, Train Loss: 36.18807705965909, Valid Loss: 40.93142827351888\n","Epoch: 5161/10000, Train Loss: 36.385921478271484, Valid Loss: 40.87494913736979\n","Epoch: 5162/10000, Train Loss: 36.987747539173476, Valid Loss: 40.829758961995445\n","Epoch: 5163/10000, Train Loss: 36.693856326016515, Valid Loss: 40.97076288859049\n","Epoch: 5164/10000, Train Loss: 36.77513538707387, Valid Loss: 40.67089970906576\n","Epoch: 5165/10000, Train Loss: 36.55965354225852, Valid Loss: 40.8634287516276\n","Epoch: 5166/10000, Train Loss: 36.328155517578125, Valid Loss: 40.794891357421875\n","Epoch: 5167/10000, Train Loss: 36.40076411854137, Valid Loss: 40.849690755208336\n","Epoch: 5168/10000, Train Loss: 36.38972785256126, Valid Loss: 40.64146296183268\n","Epoch: 5169/10000, Train Loss: 36.69088433005593, Valid Loss: 40.716514587402344\n","Epoch: 5170/10000, Train Loss: 36.444997267289594, Valid Loss: 40.77915700276693\n","Epoch: 5171/10000, Train Loss: 36.7335055958141, Valid Loss: 40.9427235921224\n","Epoch: 5172/10000, Train Loss: 36.54564319957387, Valid Loss: 40.93327713012695\n","Epoch: 5173/10000, Train Loss: 36.68650921908292, Valid Loss: 40.97597885131836\n","Epoch: 5174/10000, Train Loss: 36.12432861328125, Valid Loss: 40.64521789550781\n","Epoch: 5175/10000, Train Loss: 36.4377274946733, Valid Loss: 40.75879414876302\n","Epoch: 5176/10000, Train Loss: 36.47703899036754, Valid Loss: 40.65505345662435\n","Epoch: 5177/10000, Train Loss: 36.60875424471769, Valid Loss: 40.60883458455404\n","Epoch: 5178/10000, Train Loss: 36.214631514115766, Valid Loss: 40.53708521525065\n","Epoch: 5179/10000, Train Loss: 36.36430046775124, Valid Loss: 40.59975560506185\n","Epoch: 5180/10000, Train Loss: 36.49317099831321, Valid Loss: 40.65033086140951\n","Epoch: 5181/10000, Train Loss: 36.74338288740678, Valid Loss: 40.85186004638672\n","Epoch: 5182/10000, Train Loss: 36.97422096946023, Valid Loss: 40.815284729003906\n","Epoch: 5183/10000, Train Loss: 36.44073902476918, Valid Loss: 40.6649538675944\n","Epoch: 5184/10000, Train Loss: 36.40938880226829, Valid Loss: 40.718345642089844\n","Epoch: 5185/10000, Train Loss: 36.557128559459336, Valid Loss: 40.681260426839195\n","Epoch: 5186/10000, Train Loss: 36.064132343639024, Valid Loss: 40.587843577067055\n","Epoch: 5187/10000, Train Loss: 36.355710463090375, Valid Loss: 40.67298889160156\n","Epoch: 5188/10000, Train Loss: 36.45816698941317, Valid Loss: 40.6140988667806\n","Epoch: 5189/10000, Train Loss: 36.73624524203214, Valid Loss: 40.7003173828125\n","Epoch: 5190/10000, Train Loss: 36.20234922929244, Valid Loss: 40.772440592447914\n","Epoch: 5191/10000, Train Loss: 36.13366491144354, Valid Loss: 40.735477447509766\n","Epoch: 5192/10000, Train Loss: 36.396282542835586, Valid Loss: 40.79165776570638\n","Epoch: 5193/10000, Train Loss: 36.3344182101163, Valid Loss: 40.835872650146484\n","Epoch: 5194/10000, Train Loss: 36.11024891246449, Valid Loss: 40.74581400553385\n","Epoch: 5195/10000, Train Loss: 36.69259366122159, Valid Loss: 40.460609436035156\n","Epoch: 5196/10000, Train Loss: 36.401392156427555, Valid Loss: 40.393611907958984\n","Epoch: 5197/10000, Train Loss: 36.265235207297586, Valid Loss: 40.43606440226237\n","Epoch: 5198/10000, Train Loss: 36.17337556318803, Valid Loss: 40.58211898803711\n","Epoch: 5199/10000, Train Loss: 36.665494745427914, Valid Loss: 40.77328109741211\n","Epoch: 5200/10000, Train Loss: 36.46854296597567, Valid Loss: 40.67550277709961\n","Epoch: 5201/10000, Train Loss: 36.21151074496183, Valid Loss: 40.65653737386068\n","Epoch: 5202/10000, Train Loss: 36.63230306451971, Valid Loss: 40.60169347127279\n","Epoch: 5203/10000, Train Loss: 36.58635295521129, Valid Loss: 40.54841105143229\n","Epoch: 5204/10000, Train Loss: 36.59377219460227, Valid Loss: 40.40909322102865\n","Epoch: 5205/10000, Train Loss: 36.76223304054954, Valid Loss: 40.55864461263021\n","Epoch: 5206/10000, Train Loss: 36.4373779296875, Valid Loss: 40.69036610921224\n","Epoch: 5207/10000, Train Loss: 36.22634540904652, Valid Loss: 40.62908172607422\n","Epoch: 5208/10000, Train Loss: 36.09050924127752, Valid Loss: 40.70043436686198\n","Epoch: 5209/10000, Train Loss: 36.81916254216974, Valid Loss: 40.619397481282554\n","Epoch: 5210/10000, Train Loss: 36.44250002774325, Valid Loss: 40.52550760904948\n","Epoch: 5211/10000, Train Loss: 36.435791362415664, Valid Loss: 40.577308654785156\n","Epoch: 5212/10000, Train Loss: 36.39271198619496, Valid Loss: 40.51195780436198\n","Epoch: 5213/10000, Train Loss: 36.38796546242454, Valid Loss: 40.515116373697914\n","Epoch: 5214/10000, Train Loss: 35.73418634588068, Valid Loss: 40.6352793375651\n","Epoch: 5215/10000, Train Loss: 36.399511163884945, Valid Loss: 40.60597483317057\n","Epoch: 5216/10000, Train Loss: 36.66823335127397, Valid Loss: 40.692325592041016\n","Epoch: 5217/10000, Train Loss: 36.72371500188654, Valid Loss: 40.662740071614586\n","Epoch: 5218/10000, Train Loss: 35.9563120061701, Valid Loss: 40.508530934651695\n","Epoch: 5219/10000, Train Loss: 36.234194322065875, Valid Loss: 40.50010426839193\n","Epoch: 5220/10000, Train Loss: 36.635558041659266, Valid Loss: 40.397359212239586\n","Epoch: 5221/10000, Train Loss: 36.5125285061923, Valid Loss: 40.73485565185547\n","Epoch: 5222/10000, Train Loss: 36.178226470947266, Valid Loss: 40.56144587198893\n","Epoch: 5223/10000, Train Loss: 36.7046345797452, Valid Loss: 40.511112213134766\n","Epoch: 5224/10000, Train Loss: 36.37236092307351, Valid Loss: 40.52269999186198\n","Epoch: 5225/10000, Train Loss: 36.19117806174538, Valid Loss: 40.53987503051758\n","Epoch: 5226/10000, Train Loss: 36.1992600180886, Valid Loss: 40.409018198649086\n","Epoch: 5227/10000, Train Loss: 36.214311773126774, Valid Loss: 40.60255813598633\n","Epoch: 5228/10000, Train Loss: 36.29883887551048, Valid Loss: 40.773695627848305\n","Epoch: 5229/10000, Train Loss: 36.12458870627663, Valid Loss: 40.67229461669922\n","Epoch: 5230/10000, Train Loss: 36.39395661787553, Valid Loss: 40.53259404500326\n","Epoch: 5231/10000, Train Loss: 36.22465203025124, Valid Loss: 40.66422653198242\n","Epoch: 5232/10000, Train Loss: 36.29221031882546, Valid Loss: 40.52585220336914\n","Epoch: 5233/10000, Train Loss: 36.424260572953656, Valid Loss: 40.52328618367513\n","Epoch: 5234/10000, Train Loss: 35.8384843306108, Valid Loss: 40.57816823323568\n","Epoch: 5235/10000, Train Loss: 35.930877685546875, Valid Loss: 40.48491287231445\n","Epoch: 5236/10000, Train Loss: 35.80528675426137, Valid Loss: 40.51512908935547\n","Epoch: 5237/10000, Train Loss: 36.185503179376774, Valid Loss: 40.449780782063804\n","Epoch: 5238/10000, Train Loss: 36.44989152388139, Valid Loss: 40.52431106567383\n","Epoch: 5239/10000, Train Loss: 35.87961474331942, Valid Loss: 40.410536448160805\n","Epoch: 5240/10000, Train Loss: 36.80565816705877, Valid Loss: 40.52093633015951\n","Epoch: 5241/10000, Train Loss: 36.874590787020594, Valid Loss: 40.551414489746094\n","Epoch: 5242/10000, Train Loss: 36.708147222345524, Valid Loss: 40.563385009765625\n","Epoch: 5243/10000, Train Loss: 36.10209066217596, Valid Loss: 40.4622688293457\n","Epoch: 5244/10000, Train Loss: 36.23067092895508, Valid Loss: 40.334946950276695\n","Epoch: 5245/10000, Train Loss: 36.31062837080522, Valid Loss: 40.64357248942057\n","Epoch: 5246/10000, Train Loss: 36.03883188421076, Valid Loss: 40.33503341674805\n","Epoch: 5247/10000, Train Loss: 36.10184027931907, Valid Loss: 40.353982289632164\n","Epoch: 5248/10000, Train Loss: 36.16906079378995, Valid Loss: 40.52376174926758\n","Epoch: 5249/10000, Train Loss: 36.19664244218306, Valid Loss: 40.52517827351888\n","Epoch: 5250/10000, Train Loss: 36.12077782370827, Valid Loss: 40.44732793172201\n","Epoch: 5251/10000, Train Loss: 36.09023319591176, Valid Loss: 40.489054361979164\n","Epoch: 5252/10000, Train Loss: 36.331795779141515, Valid Loss: 40.60332234700521\n","Epoch: 5253/10000, Train Loss: 36.02941409024325, Valid Loss: 40.50140126546224\n","Epoch: 5254/10000, Train Loss: 36.07044358686967, Valid Loss: 40.442498524983726\n","Epoch: 5255/10000, Train Loss: 36.46612271395597, Valid Loss: 40.390237172444664\n","Epoch: 5256/10000, Train Loss: 36.22635338523171, Valid Loss: 40.38535690307617\n","Epoch: 5257/10000, Train Loss: 35.70497616854581, Valid Loss: 40.35325368245443\n","Epoch: 5258/10000, Train Loss: 35.67348029396751, Valid Loss: 40.40008672078451\n","Epoch: 5259/10000, Train Loss: 36.068086797540836, Valid Loss: 40.521522521972656\n","Epoch: 5260/10000, Train Loss: 35.76455307006836, Valid Loss: 40.39464441935221\n","Epoch: 5261/10000, Train Loss: 36.02495297518644, Valid Loss: 40.33673604329427\n","Epoch: 5262/10000, Train Loss: 36.41143729469993, Valid Loss: 40.394762674967446\n","Epoch: 5263/10000, Train Loss: 36.022268468683414, Valid Loss: 40.40107091267904\n","Epoch: 5264/10000, Train Loss: 35.99901563471014, Valid Loss: 40.5057373046875\n","Epoch: 5265/10000, Train Loss: 35.904953869906336, Valid Loss: 40.383487701416016\n","Epoch: 5266/10000, Train Loss: 36.39334453235973, Valid Loss: 40.24585469563802\n","Epoch: 5267/10000, Train Loss: 35.6712681163441, Valid Loss: 40.51792017618815\n","Epoch: 5268/10000, Train Loss: 36.29936703768644, Valid Loss: 40.41515858968099\n","Epoch: 5269/10000, Train Loss: 36.52327104048295, Valid Loss: 40.446661631266274\n","Epoch: 5270/10000, Train Loss: 35.85609921542081, Valid Loss: 40.39352544148763\n","Epoch: 5271/10000, Train Loss: 35.69748392972079, Valid Loss: 40.46509297688802\n","Epoch: 5272/10000, Train Loss: 36.062813845547765, Valid Loss: 40.55217742919922\n","Epoch: 5273/10000, Train Loss: 36.18037241155451, Valid Loss: 40.32099405924479\n","Epoch: 5274/10000, Train Loss: 36.31186571988192, Valid Loss: 40.35752741495768\n","Epoch: 5275/10000, Train Loss: 35.80299204046076, Valid Loss: 40.24227650960287\n","Epoch: 5276/10000, Train Loss: 36.178945714777164, Valid Loss: 40.34500249226888\n","Epoch: 5277/10000, Train Loss: 36.213126789439805, Valid Loss: 40.322644551595054\n","Epoch: 5278/10000, Train Loss: 35.996726989746094, Valid Loss: 40.43360265096029\n","Epoch: 5279/10000, Train Loss: 35.869270671497695, Valid Loss: 40.514933268229164\n","Epoch: 5280/10000, Train Loss: 35.92303120006215, Valid Loss: 40.280171712239586\n","Epoch: 5281/10000, Train Loss: 35.949546813964844, Valid Loss: 40.21788660685221\n","Epoch: 5282/10000, Train Loss: 36.04659670049494, Valid Loss: 40.26454544067383\n","Epoch: 5283/10000, Train Loss: 35.97501754760742, Valid Loss: 40.1952018737793\n","Epoch: 5284/10000, Train Loss: 35.97645950317383, Valid Loss: 40.17364629109701\n","Epoch: 5285/10000, Train Loss: 35.75449822165749, Valid Loss: 40.278237660725914\n","Epoch: 5286/10000, Train Loss: 35.61087140170011, Valid Loss: 40.10851033528646\n","Epoch: 5287/10000, Train Loss: 36.236420371315695, Valid Loss: 40.13377253214518\n","Epoch: 5288/10000, Train Loss: 35.98341092196378, Valid Loss: 40.20878219604492\n","Epoch: 5289/10000, Train Loss: 36.079459103670985, Valid Loss: 40.14718373616537\n","Epoch: 5290/10000, Train Loss: 36.0356313532049, Valid Loss: 40.39555994669596\n","Epoch: 5291/10000, Train Loss: 35.88769600608132, Valid Loss: 40.26226298014323\n","Epoch: 5292/10000, Train Loss: 36.2489409013228, Valid Loss: 40.206564585367836\n","Epoch: 5293/10000, Train Loss: 36.613340551202946, Valid Loss: 40.27859624226888\n","Epoch: 5294/10000, Train Loss: 36.15410648692738, Valid Loss: 40.12039693196615\n","Epoch: 5295/10000, Train Loss: 35.976295471191406, Valid Loss: 40.15121841430664\n","Epoch: 5296/10000, Train Loss: 35.88825087113814, Valid Loss: 40.449225107828774\n","Epoch: 5297/10000, Train Loss: 35.95376621593129, Valid Loss: 40.372535705566406\n","Epoch: 5298/10000, Train Loss: 36.45650933005593, Valid Loss: 40.142523447672524\n","Epoch: 5299/10000, Train Loss: 36.07152141224254, Valid Loss: 40.09032948811849\n","Epoch: 5300/10000, Train Loss: 36.313288255171344, Valid Loss: 40.32052357991537\n","Epoch: 5301/10000, Train Loss: 35.78071386163885, Valid Loss: 40.43780008951823\n","Epoch: 5302/10000, Train Loss: 35.73023154518821, Valid Loss: 40.45583470662435\n","Epoch: 5303/10000, Train Loss: 35.88514362681996, Valid Loss: 40.28945668538412\n","Epoch: 5304/10000, Train Loss: 35.54254427823153, Valid Loss: 40.18452072143555\n","Epoch: 5305/10000, Train Loss: 36.12169924649325, Valid Loss: 40.17059326171875\n","Epoch: 5306/10000, Train Loss: 36.014096693559125, Valid Loss: 40.274820963541664\n","Epoch: 5307/10000, Train Loss: 35.58381722190163, Valid Loss: 40.18557612101237\n","Epoch: 5308/10000, Train Loss: 35.783350857821375, Valid Loss: 40.243726094563804\n","Epoch: 5309/10000, Train Loss: 36.04012541337447, Valid Loss: 40.24597676595052\n","Epoch: 5310/10000, Train Loss: 36.08672020652077, Valid Loss: 40.27992248535156\n","Epoch: 5311/10000, Train Loss: 35.63320576060902, Valid Loss: 40.18572743733724\n","Epoch: 5312/10000, Train Loss: 35.81423221934926, Valid Loss: 40.468615214029946\n","Epoch: 5313/10000, Train Loss: 35.64895525845614, Valid Loss: 40.39202372233073\n","Epoch: 5314/10000, Train Loss: 35.898472872647375, Valid Loss: 40.28771082560221\n","Epoch: 5315/10000, Train Loss: 36.41032617742365, Valid Loss: 40.16655349731445\n","Epoch: 5316/10000, Train Loss: 35.91717459938743, Valid Loss: 40.323116302490234\n","Epoch: 5317/10000, Train Loss: 35.660566156560726, Valid Loss: 40.049546559651695\n","Epoch: 5318/10000, Train Loss: 35.96555709838867, Valid Loss: 40.206320444742836\n","Epoch: 5319/10000, Train Loss: 36.112185738303445, Valid Loss: 40.22375996907552\n","Epoch: 5320/10000, Train Loss: 35.792904420332476, Valid Loss: 40.183284759521484\n","Epoch: 5321/10000, Train Loss: 35.87826711481268, Valid Loss: 40.23452631632487\n","Epoch: 5322/10000, Train Loss: 35.9043249650435, Valid Loss: 40.35948944091797\n","Epoch: 5323/10000, Train Loss: 35.926173123446375, Valid Loss: 40.290000915527344\n","Epoch: 5324/10000, Train Loss: 35.895851135253906, Valid Loss: 40.311712900797524\n","Epoch: 5325/10000, Train Loss: 35.92651384527033, Valid Loss: 40.250343322753906\n","Epoch: 5326/10000, Train Loss: 35.39933221990412, Valid Loss: 40.25745646158854\n","Epoch: 5327/10000, Train Loss: 35.93616398898038, Valid Loss: 40.18704605102539\n","Epoch: 5328/10000, Train Loss: 35.9476731040261, Valid Loss: 40.15131505330404\n","Epoch: 5329/10000, Train Loss: 35.54788242686879, Valid Loss: 40.30019505818685\n","Epoch: 5330/10000, Train Loss: 35.651151483709164, Valid Loss: 40.111900329589844\n","Epoch: 5331/10000, Train Loss: 35.473572817715734, Valid Loss: 40.08617909749349\n","Epoch: 5332/10000, Train Loss: 35.95434431596236, Valid Loss: 40.259543100992836\n","Epoch: 5333/10000, Train Loss: 35.896116430109196, Valid Loss: 40.25047938028971\n","Epoch: 5334/10000, Train Loss: 35.89196049083363, Valid Loss: 40.05356470743815\n","Epoch: 5335/10000, Train Loss: 35.61567271839488, Valid Loss: 39.9303347269694\n","Epoch: 5336/10000, Train Loss: 35.37050559303977, Valid Loss: 39.973402659098305\n","Epoch: 5337/10000, Train Loss: 35.72240309281783, Valid Loss: 39.98309453328451\n","Epoch: 5338/10000, Train Loss: 35.778987884521484, Valid Loss: 40.21264394124349\n","Epoch: 5339/10000, Train Loss: 35.901132410222836, Valid Loss: 40.215936024983726\n","Epoch: 5340/10000, Train Loss: 35.768488450483844, Valid Loss: 40.2919807434082\n","Epoch: 5341/10000, Train Loss: 35.57284372503107, Valid Loss: 40.16003926595052\n","Epoch: 5342/10000, Train Loss: 36.032807090065695, Valid Loss: 40.07109451293945\n","Epoch: 5343/10000, Train Loss: 35.86752631447532, Valid Loss: 40.23385111490885\n","Epoch: 5344/10000, Train Loss: 35.48261989246715, Valid Loss: 40.1714973449707\n","Epoch: 5345/10000, Train Loss: 35.99514943903143, Valid Loss: 40.09376780192057\n","Epoch: 5346/10000, Train Loss: 35.5980470830744, Valid Loss: 40.243770599365234\n","Epoch: 5347/10000, Train Loss: 35.82915045998313, Valid Loss: 40.03243764241537\n","Epoch: 5348/10000, Train Loss: 35.7649040222168, Valid Loss: 40.21104049682617\n","Epoch: 5349/10000, Train Loss: 35.42046824368563, Valid Loss: 40.15615463256836\n","Epoch: 5350/10000, Train Loss: 35.89029971036044, Valid Loss: 40.05199686686198\n","Epoch: 5351/10000, Train Loss: 35.5574819391424, Valid Loss: 40.101975758870445\n","Epoch: 5352/10000, Train Loss: 35.47994388233531, Valid Loss: 40.06393686930338\n","Epoch: 5353/10000, Train Loss: 35.842711361971766, Valid Loss: 40.214239756266274\n","Epoch: 5354/10000, Train Loss: 35.695431449196555, Valid Loss: 40.08438237508138\n","Epoch: 5355/10000, Train Loss: 36.38608516346324, Valid Loss: 40.0954704284668\n","Epoch: 5356/10000, Train Loss: 35.503333351828836, Valid Loss: 40.01471710205078\n","Epoch: 5357/10000, Train Loss: 35.75145860151811, Valid Loss: 39.927066802978516\n","Epoch: 5358/10000, Train Loss: 35.876347975297406, Valid Loss: 39.8167355855306\n","Epoch: 5359/10000, Train Loss: 35.72600590098988, Valid Loss: 39.90955479939779\n","Epoch: 5360/10000, Train Loss: 35.57057293978605, Valid Loss: 39.883968353271484\n","Epoch: 5361/10000, Train Loss: 35.549584822221235, Valid Loss: 40.129556020100914\n","Epoch: 5362/10000, Train Loss: 35.81576364690607, Valid Loss: 40.21141560872396\n","Epoch: 5363/10000, Train Loss: 36.07002674449574, Valid Loss: 39.99597676595052\n","Epoch: 5364/10000, Train Loss: 35.53629684448242, Valid Loss: 40.01981735229492\n","Epoch: 5365/10000, Train Loss: 35.78187803788619, Valid Loss: 40.15187199910482\n","Epoch: 5366/10000, Train Loss: 35.448197624900125, Valid Loss: 40.123128255208336\n","Epoch: 5367/10000, Train Loss: 35.6065129366788, Valid Loss: 40.100643157958984\n","Epoch: 5368/10000, Train Loss: 35.77051474831321, Valid Loss: 40.08658091227213\n","Epoch: 5369/10000, Train Loss: 35.66596429998224, Valid Loss: 40.075243631998696\n","Epoch: 5370/10000, Train Loss: 36.082768180153586, Valid Loss: 39.834818522135414\n","Epoch: 5371/10000, Train Loss: 35.491691242564805, Valid Loss: 39.77169291178385\n","Epoch: 5372/10000, Train Loss: 35.64693763039329, Valid Loss: 40.0300178527832\n","Epoch: 5373/10000, Train Loss: 34.895563992587, Valid Loss: 39.99897384643555\n","Epoch: 5374/10000, Train Loss: 35.717471382834695, Valid Loss: 40.004940032958984\n","Epoch: 5375/10000, Train Loss: 35.51795023137873, Valid Loss: 39.9893684387207\n","Epoch: 5376/10000, Train Loss: 35.903091777454726, Valid Loss: 39.98644129435221\n","Epoch: 5377/10000, Train Loss: 36.04238232699308, Valid Loss: 40.022324879964195\n","Epoch: 5378/10000, Train Loss: 35.67870330810547, Valid Loss: 39.99756368001302\n","Epoch: 5379/10000, Train Loss: 35.427729173140094, Valid Loss: 39.980604807535805\n","Epoch: 5380/10000, Train Loss: 35.57109867442738, Valid Loss: 39.928635915120445\n","Epoch: 5381/10000, Train Loss: 36.08842676336115, Valid Loss: 40.03501892089844\n","Epoch: 5382/10000, Train Loss: 35.84624550559304, Valid Loss: 40.05308532714844\n","Epoch: 5383/10000, Train Loss: 35.57281286066229, Valid Loss: 39.89178593953451\n","Epoch: 5384/10000, Train Loss: 35.68964247270064, Valid Loss: 39.98799260457357\n","Epoch: 5385/10000, Train Loss: 35.1298942565918, Valid Loss: 39.927869160970054\n","Epoch: 5386/10000, Train Loss: 35.61544210260565, Valid Loss: 39.934460957845054\n","Epoch: 5387/10000, Train Loss: 35.4030876159668, Valid Loss: 39.80083465576172\n","Epoch: 5388/10000, Train Loss: 35.7566445090554, Valid Loss: 40.03356424967448\n","Epoch: 5389/10000, Train Loss: 35.8024076981978, Valid Loss: 40.03741963704427\n","Epoch: 5390/10000, Train Loss: 35.41050269386985, Valid Loss: 39.895989735921226\n","Epoch: 5391/10000, Train Loss: 35.537587599320844, Valid Loss: 40.00486501057943\n","Epoch: 5392/10000, Train Loss: 35.64908079667525, Valid Loss: 39.94559224446615\n","Epoch: 5393/10000, Train Loss: 35.643755826083094, Valid Loss: 39.98332722981771\n","Epoch: 5394/10000, Train Loss: 35.25235228105025, Valid Loss: 40.14341735839844\n","Epoch: 5395/10000, Train Loss: 35.39382969249379, Valid Loss: 40.155600229899086\n","Epoch: 5396/10000, Train Loss: 35.54116786609996, Valid Loss: 39.95842488606771\n","Epoch: 5397/10000, Train Loss: 36.13762456720526, Valid Loss: 39.87503433227539\n","Epoch: 5398/10000, Train Loss: 35.72939734025435, Valid Loss: 39.882606506347656\n","Epoch: 5399/10000, Train Loss: 35.81431059403853, Valid Loss: 39.956502278645836\n","Epoch: 5400/10000, Train Loss: 34.910179138183594, Valid Loss: 39.718153635660805\n","Epoch: 5401/10000, Train Loss: 35.520445736971766, Valid Loss: 39.709754943847656\n","Epoch: 5402/10000, Train Loss: 35.42930117520419, Valid Loss: 39.70848846435547\n","Epoch: 5403/10000, Train Loss: 35.385948181152344, Valid Loss: 39.70951716105143\n","Epoch: 5404/10000, Train Loss: 35.37181334062056, Valid Loss: 39.8873291015625\n","Epoch: 5405/10000, Train Loss: 35.41478139703924, Valid Loss: 39.889540354410805\n","Epoch: 5406/10000, Train Loss: 35.209355787797406, Valid Loss: 40.01007207234701\n","Epoch: 5407/10000, Train Loss: 35.47265139493075, Valid Loss: 39.87916056315104\n","Epoch: 5408/10000, Train Loss: 35.40054702758789, Valid Loss: 39.85313288370768\n","Epoch: 5409/10000, Train Loss: 35.51327965476296, Valid Loss: 39.82217661539713\n","Epoch: 5410/10000, Train Loss: 35.14985448663885, Valid Loss: 39.92585372924805\n","Epoch: 5411/10000, Train Loss: 35.38044565374201, Valid Loss: 39.866546630859375\n","Epoch: 5412/10000, Train Loss: 35.97325481068004, Valid Loss: 39.93182881673177\n","Epoch: 5413/10000, Train Loss: 35.71155062588778, Valid Loss: 39.9610481262207\n","Epoch: 5414/10000, Train Loss: 36.15154335715554, Valid Loss: 39.786041259765625\n","Epoch: 5415/10000, Train Loss: 35.91163392500444, Valid Loss: 39.75378163655599\n","Epoch: 5416/10000, Train Loss: 34.98739918795499, Valid Loss: 39.794602711995445\n","Epoch: 5417/10000, Train Loss: 35.622190648859196, Valid Loss: 39.78981272379557\n","Epoch: 5418/10000, Train Loss: 35.45986487648704, Valid Loss: 39.86109924316406\n","Epoch: 5419/10000, Train Loss: 35.68779893354936, Valid Loss: 39.877211252848305\n","Epoch: 5420/10000, Train Loss: 35.451694835316054, Valid Loss: 39.90883763631185\n","Epoch: 5421/10000, Train Loss: 35.26494806463068, Valid Loss: 39.906819661458336\n","Epoch: 5422/10000, Train Loss: 35.840018879283555, Valid Loss: 39.86650085449219\n","Epoch: 5423/10000, Train Loss: 35.39207042347301, Valid Loss: 39.9751942952474\n","Epoch: 5424/10000, Train Loss: 35.24225581776012, Valid Loss: 39.89905802408854\n","Epoch: 5425/10000, Train Loss: 35.23381319912997, Valid Loss: 39.89213943481445\n","Epoch: 5426/10000, Train Loss: 35.387494867498226, Valid Loss: 39.905738830566406\n","Epoch: 5427/10000, Train Loss: 35.34324958107688, Valid Loss: 39.799573262532554\n","Epoch: 5428/10000, Train Loss: 35.13836167075417, Valid Loss: 39.827927907307945\n","Epoch: 5429/10000, Train Loss: 35.772173794833094, Valid Loss: 39.987806955973305\n","Epoch: 5430/10000, Train Loss: 34.984664570201524, Valid Loss: 40.05031077067057\n","Epoch: 5431/10000, Train Loss: 35.09870425137606, Valid Loss: 39.72796630859375\n","Epoch: 5432/10000, Train Loss: 35.20455134998668, Valid Loss: 39.6182975769043\n","Epoch: 5433/10000, Train Loss: 35.85485770485618, Valid Loss: 39.74856440226237\n","Epoch: 5434/10000, Train Loss: 34.540232398293234, Valid Loss: 39.74531555175781\n","Epoch: 5435/10000, Train Loss: 35.44503888216886, Valid Loss: 39.94232177734375\n","Epoch: 5436/10000, Train Loss: 35.228916515003554, Valid Loss: 39.958489735921226\n","Epoch: 5437/10000, Train Loss: 35.677181243896484, Valid Loss: 39.80599721272787\n","Epoch: 5438/10000, Train Loss: 35.56078824129972, Valid Loss: 39.921610514322914\n","Epoch: 5439/10000, Train Loss: 34.96058966896751, Valid Loss: 39.60335795084635\n","Epoch: 5440/10000, Train Loss: 34.56627290899103, Valid Loss: 39.894551595052086\n","Epoch: 5441/10000, Train Loss: 35.003981676968664, Valid Loss: 39.78854115804037\n","Epoch: 5442/10000, Train Loss: 35.14354879205877, Valid Loss: 39.842367808024086\n","Epoch: 5443/10000, Train Loss: 35.42726794156161, Valid Loss: 39.69673283894857\n","Epoch: 5444/10000, Train Loss: 35.47782932628285, Valid Loss: 39.74505488077799\n","Epoch: 5445/10000, Train Loss: 35.20339653708718, Valid Loss: 39.57709630330404\n","Epoch: 5446/10000, Train Loss: 34.66336649114435, Valid Loss: 39.942623138427734\n","Epoch: 5447/10000, Train Loss: 35.18957935680043, Valid Loss: 39.864678700764976\n","Epoch: 5448/10000, Train Loss: 35.47212288596413, Valid Loss: 39.94607289632162\n","Epoch: 5449/10000, Train Loss: 35.646319996226914, Valid Loss: 39.89011764526367\n","Epoch: 5450/10000, Train Loss: 35.74792411110618, Valid Loss: 39.841513315836586\n","Epoch: 5451/10000, Train Loss: 35.35603159124201, Valid Loss: 39.75332387288412\n","Epoch: 5452/10000, Train Loss: 35.39039611816406, Valid Loss: 39.73576227823893\n","Epoch: 5453/10000, Train Loss: 34.815638455477625, Valid Loss: 39.87594223022461\n","Epoch: 5454/10000, Train Loss: 35.33477436412465, Valid Loss: 39.8992665608724\n","Epoch: 5455/10000, Train Loss: 35.60821463844993, Valid Loss: 39.854235331217446\n","Epoch: 5456/10000, Train Loss: 35.23719336769798, Valid Loss: 39.80067825317383\n","Epoch: 5457/10000, Train Loss: 35.610840884121984, Valid Loss: 39.67945353190104\n","Epoch: 5458/10000, Train Loss: 34.9397064555775, Valid Loss: 39.82447306315104\n","Epoch: 5459/10000, Train Loss: 35.538042935458094, Valid Loss: 39.7929318745931\n","Epoch: 5460/10000, Train Loss: 35.24660526622426, Valid Loss: 39.68841298421224\n","Epoch: 5461/10000, Train Loss: 35.459170601584695, Valid Loss: 39.60939915974935\n","Epoch: 5462/10000, Train Loss: 34.84722622958097, Valid Loss: 39.701141357421875\n","Epoch: 5463/10000, Train Loss: 35.202434366399594, Valid Loss: 39.49036153157552\n","Epoch: 5464/10000, Train Loss: 35.31122415715998, Valid Loss: 39.712608337402344\n","Epoch: 5465/10000, Train Loss: 35.82458010586825, Valid Loss: 39.55697886149088\n","Epoch: 5466/10000, Train Loss: 35.48106939142401, Valid Loss: 39.67949422200521\n","Epoch: 5467/10000, Train Loss: 35.28684581409801, Valid Loss: 39.683021545410156\n","Epoch: 5468/10000, Train Loss: 35.10814233259721, Valid Loss: 39.77306620279948\n","Epoch: 5469/10000, Train Loss: 35.20399336381392, Valid Loss: 39.82603963216146\n","Epoch: 5470/10000, Train Loss: 35.00142999128862, Valid Loss: 39.86950429280599\n","Epoch: 5471/10000, Train Loss: 35.31520947543058, Valid Loss: 39.80767313639323\n","Epoch: 5472/10000, Train Loss: 34.86776369268244, Valid Loss: 39.889993031819664\n","Epoch: 5473/10000, Train Loss: 35.39258852871981, Valid Loss: 39.91290283203125\n","Epoch: 5474/10000, Train Loss: 35.05278015136719, Valid Loss: 39.72406514485677\n","Epoch: 5475/10000, Train Loss: 35.25605461814187, Valid Loss: 39.82817713419596\n","Epoch: 5476/10000, Train Loss: 35.299624703147195, Valid Loss: 39.90814717610677\n","Epoch: 5477/10000, Train Loss: 35.21776632829146, Valid Loss: 39.795416514078774\n","Epoch: 5478/10000, Train Loss: 35.207748066295274, Valid Loss: 39.71038055419922\n","Epoch: 5479/10000, Train Loss: 35.471969257701524, Valid Loss: 39.652523040771484\n","Epoch: 5480/10000, Train Loss: 34.973580447110265, Valid Loss: 39.75289408365885\n","Epoch: 5481/10000, Train Loss: 35.222877502441406, Valid Loss: 39.5325927734375\n","Epoch: 5482/10000, Train Loss: 35.23486969687722, Valid Loss: 39.735399881998696\n","Epoch: 5483/10000, Train Loss: 35.10373427651145, Valid Loss: 39.60870869954427\n","Epoch: 5484/10000, Train Loss: 34.926396283236414, Valid Loss: 39.70889790852865\n","Epoch: 5485/10000, Train Loss: 35.10737852616744, Valid Loss: 39.68154652913412\n","Epoch: 5486/10000, Train Loss: 35.131169059059836, Valid Loss: 39.79317092895508\n","Epoch: 5487/10000, Train Loss: 35.05954083529386, Valid Loss: 39.74767049153646\n","Epoch: 5488/10000, Train Loss: 35.44477670842951, Valid Loss: 39.50211970011393\n","Epoch: 5489/10000, Train Loss: 35.74235708063299, Valid Loss: 39.583885192871094\n","Epoch: 5490/10000, Train Loss: 35.14385431463068, Valid Loss: 39.67340850830078\n","Epoch: 5491/10000, Train Loss: 34.83052028309215, Valid Loss: 39.653769175211586\n","Epoch: 5492/10000, Train Loss: 35.193804654208094, Valid Loss: 39.66898981730143\n","Epoch: 5493/10000, Train Loss: 35.194534648548476, Valid Loss: 39.69313939412435\n","Epoch: 5494/10000, Train Loss: 35.26110215620561, Valid Loss: 39.8073984781901\n","Epoch: 5495/10000, Train Loss: 35.52512324940074, Valid Loss: 39.63370259602865\n","Epoch: 5496/10000, Train Loss: 35.22421646118164, Valid Loss: 39.70370864868164\n","Epoch: 5497/10000, Train Loss: 35.431596929376774, Valid Loss: 39.75422795613607\n","Epoch: 5498/10000, Train Loss: 35.25685917247426, Valid Loss: 39.591084798177086\n","Epoch: 5499/10000, Train Loss: 35.17418740012429, Valid Loss: 39.508904774983726\n","Epoch: 5500/10000, Train Loss: 35.27083206176758, Valid Loss: 39.653313954671226\n","Epoch: 5501/10000, Train Loss: 35.54011917114258, Valid Loss: 39.55311838785807\n","Epoch: 5502/10000, Train Loss: 34.98158160122958, Valid Loss: 39.73707707722982\n","Epoch: 5503/10000, Train Loss: 35.21080433238637, Valid Loss: 39.58962758382162\n","Epoch: 5504/10000, Train Loss: 34.9182598807595, Valid Loss: 39.57892862955729\n","Epoch: 5505/10000, Train Loss: 34.82692441073331, Valid Loss: 39.46226247151693\n","Epoch: 5506/10000, Train Loss: 34.66932053999467, Valid Loss: 39.521742502848305\n","Epoch: 5507/10000, Train Loss: 35.059035387906164, Valid Loss: 39.597938537597656\n","Epoch: 5508/10000, Train Loss: 34.755416523326524, Valid Loss: 39.50575383504232\n","Epoch: 5509/10000, Train Loss: 35.2722317088734, Valid Loss: 39.67714818318685\n","Epoch: 5510/10000, Train Loss: 35.27961869673295, Valid Loss: 39.75977579752604\n","Epoch: 5511/10000, Train Loss: 34.92578281055797, Valid Loss: 39.60570398966471\n","Epoch: 5512/10000, Train Loss: 35.19299871271307, Valid Loss: 39.32550175984701\n","Epoch: 5513/10000, Train Loss: 34.753042221069336, Valid Loss: 39.67791875203451\n","Epoch: 5514/10000, Train Loss: 34.895543878728695, Valid Loss: 39.47767130533854\n","Epoch: 5515/10000, Train Loss: 35.03436868840998, Valid Loss: 39.763370513916016\n","Epoch: 5516/10000, Train Loss: 34.89373918013139, Valid Loss: 39.69692738850912\n","Epoch: 5517/10000, Train Loss: 35.51377625898881, Valid Loss: 39.472948710123696\n","Epoch: 5518/10000, Train Loss: 35.03202525052157, Valid Loss: 39.48566818237305\n","Epoch: 5519/10000, Train Loss: 34.92202030528676, Valid Loss: 39.581075032552086\n","Epoch: 5520/10000, Train Loss: 35.226031910289414, Valid Loss: 39.51091384887695\n","Epoch: 5521/10000, Train Loss: 34.80930241671476, Valid Loss: 39.7917849222819\n","Epoch: 5522/10000, Train Loss: 34.859068090265446, Valid Loss: 39.61025365193685\n","Epoch: 5523/10000, Train Loss: 34.97853539206765, Valid Loss: 39.81593577067057\n","Epoch: 5524/10000, Train Loss: 34.80362458662553, Valid Loss: 39.55077234903971\n","Epoch: 5525/10000, Train Loss: 35.233186201615766, Valid Loss: 39.3815803527832\n","Epoch: 5526/10000, Train Loss: 35.17822196266868, Valid Loss: 39.57291793823242\n","Epoch: 5527/10000, Train Loss: 34.616463747891515, Valid Loss: 39.69446818033854\n","Epoch: 5528/10000, Train Loss: 35.15478654341264, Valid Loss: 39.63162612915039\n","Epoch: 5529/10000, Train Loss: 34.255128687078304, Valid Loss: 39.771881103515625\n","Epoch: 5530/10000, Train Loss: 34.35644375194203, Valid Loss: 39.72622426350912\n","Epoch: 5531/10000, Train Loss: 35.308982849121094, Valid Loss: 39.43190892537435\n","Epoch: 5532/10000, Train Loss: 35.41602689569647, Valid Loss: 39.50114822387695\n","Epoch: 5533/10000, Train Loss: 34.92758612199263, Valid Loss: 39.6103146870931\n","Epoch: 5534/10000, Train Loss: 35.34812927246094, Valid Loss: 39.645739237467446\n","Epoch: 5535/10000, Train Loss: 35.027897574684836, Valid Loss: 39.71153895060221\n","Epoch: 5536/10000, Train Loss: 35.0366606278853, Valid Loss: 39.451778411865234\n","Epoch: 5537/10000, Train Loss: 35.01148709383878, Valid Loss: 39.48359680175781\n","Epoch: 5538/10000, Train Loss: 35.17830588600852, Valid Loss: 39.38677215576172\n","Epoch: 5539/10000, Train Loss: 34.66705686395819, Valid Loss: 39.45235824584961\n","Epoch: 5540/10000, Train Loss: 35.00547235662287, Valid Loss: 39.47463607788086\n","Epoch: 5541/10000, Train Loss: 34.96863486550071, Valid Loss: 39.44117101033529\n","Epoch: 5542/10000, Train Loss: 34.407834486527875, Valid Loss: 39.66588338216146\n","Epoch: 5543/10000, Train Loss: 35.20796862515536, Valid Loss: 39.49690628051758\n","Epoch: 5544/10000, Train Loss: 34.026613062078304, Valid Loss: 39.643795013427734\n","Epoch: 5545/10000, Train Loss: 34.85919258811257, Valid Loss: 39.53700637817383\n","Epoch: 5546/10000, Train Loss: 34.862091064453125, Valid Loss: 39.53929901123047\n","Epoch: 5547/10000, Train Loss: 35.385322917591445, Valid Loss: 39.64293416341146\n","Epoch: 5548/10000, Train Loss: 35.20049979469993, Valid Loss: 39.65188852945963\n","Epoch: 5549/10000, Train Loss: 34.8479531028054, Valid Loss: 39.641005198160805\n","Epoch: 5550/10000, Train Loss: 34.47264792702415, Valid Loss: 39.44214884440104\n","Epoch: 5551/10000, Train Loss: 34.50634280118075, Valid Loss: 39.245644887288414\n","Epoch: 5552/10000, Train Loss: 34.43315540660512, Valid Loss: 39.423954010009766\n","Epoch: 5553/10000, Train Loss: 34.59482747858221, Valid Loss: 39.463731129964195\n","Epoch: 5554/10000, Train Loss: 34.516504461115055, Valid Loss: 39.50150044759115\n","Epoch: 5555/10000, Train Loss: 34.98877091841264, Valid Loss: 39.60456212361654\n","Epoch: 5556/10000, Train Loss: 34.649134549227625, Valid Loss: 39.65328725179037\n","Epoch: 5557/10000, Train Loss: 34.63930130004883, Valid Loss: 39.65027872721354\n","Epoch: 5558/10000, Train Loss: 34.59746031327681, Valid Loss: 39.5837033589681\n","Epoch: 5559/10000, Train Loss: 34.776205409656875, Valid Loss: 39.53512318929037\n","Epoch: 5560/10000, Train Loss: 34.4561578577215, Valid Loss: 39.30770365397135\n","Epoch: 5561/10000, Train Loss: 34.67528221823952, Valid Loss: 39.42770004272461\n","Epoch: 5562/10000, Train Loss: 34.33794195001776, Valid Loss: 39.203992207845054\n","Epoch: 5563/10000, Train Loss: 34.433074257590555, Valid Loss: 39.42134094238281\n","Epoch: 5564/10000, Train Loss: 34.63198471069336, Valid Loss: 39.526711781819664\n","Epoch: 5565/10000, Train Loss: 34.5888838334517, Valid Loss: 39.462650299072266\n","Epoch: 5566/10000, Train Loss: 35.29203102805398, Valid Loss: 39.46759796142578\n","Epoch: 5567/10000, Train Loss: 34.8474929115989, Valid Loss: 39.601786295572914\n","Epoch: 5568/10000, Train Loss: 34.75735716386275, Valid Loss: 39.453722635904946\n","Epoch: 5569/10000, Train Loss: 34.575996745716445, Valid Loss: 39.47184371948242\n","Epoch: 5570/10000, Train Loss: 34.962929638949305, Valid Loss: 39.56623458862305\n","Epoch: 5571/10000, Train Loss: 34.664737007834695, Valid Loss: 39.42524719238281\n","Epoch: 5572/10000, Train Loss: 35.28843134099787, Valid Loss: 39.40211613972982\n","Epoch: 5573/10000, Train Loss: 35.017296530983664, Valid Loss: 39.388511657714844\n","Epoch: 5574/10000, Train Loss: 35.33329634232955, Valid Loss: 39.51676940917969\n","Epoch: 5575/10000, Train Loss: 35.19856921109286, Valid Loss: 39.44722112019857\n","Epoch: 5576/10000, Train Loss: 34.45991065285423, Valid Loss: 39.443826039632164\n","Epoch: 5577/10000, Train Loss: 34.27675940773704, Valid Loss: 39.50596618652344\n","Epoch: 5578/10000, Train Loss: 34.87049172141335, Valid Loss: 39.471516927083336\n","Epoch: 5579/10000, Train Loss: 34.81475483287465, Valid Loss: 39.42732620239258\n","Epoch: 5580/10000, Train Loss: 34.34379646994851, Valid Loss: 39.50059127807617\n","Epoch: 5581/10000, Train Loss: 34.429241700605914, Valid Loss: 39.48605728149414\n","Epoch: 5582/10000, Train Loss: 34.26566557450728, Valid Loss: 39.46756235758463\n","Epoch: 5583/10000, Train Loss: 34.87952631170099, Valid Loss: 39.50329081217448\n","Epoch: 5584/10000, Train Loss: 34.6743387742476, Valid Loss: 39.43716557820638\n","Epoch: 5585/10000, Train Loss: 34.56378798051314, Valid Loss: 39.35931523640951\n","Epoch: 5586/10000, Train Loss: 34.02227973937988, Valid Loss: 39.39844640096029\n","Epoch: 5587/10000, Train Loss: 34.945260134610265, Valid Loss: 39.50012969970703\n","Epoch: 5588/10000, Train Loss: 34.63601355119185, Valid Loss: 39.57233428955078\n","Epoch: 5589/10000, Train Loss: 34.31281159140847, Valid Loss: 39.48801930745443\n","Epoch: 5590/10000, Train Loss: 34.65516385165128, Valid Loss: 39.40429560343424\n","Epoch: 5591/10000, Train Loss: 34.925142808394, Valid Loss: 39.45035171508789\n","Epoch: 5592/10000, Train Loss: 34.455073443326086, Valid Loss: 39.50926208496094\n","Epoch: 5593/10000, Train Loss: 34.41037507490678, Valid Loss: 39.51875559488932\n","Epoch: 5594/10000, Train Loss: 34.66818549416282, Valid Loss: 39.4150276184082\n","Epoch: 5595/10000, Train Loss: 34.873037511652164, Valid Loss: 39.43154271443685\n","Epoch: 5596/10000, Train Loss: 34.92673110961914, Valid Loss: 39.436449686686196\n","Epoch: 5597/10000, Train Loss: 34.428657878528945, Valid Loss: 39.274346669514976\n","Epoch: 5598/10000, Train Loss: 34.908818678422406, Valid Loss: 39.342848459879555\n","Epoch: 5599/10000, Train Loss: 34.912639964710586, Valid Loss: 39.302696228027344\n","Epoch: 5600/10000, Train Loss: 35.04576735063033, Valid Loss: 39.392486572265625\n","Epoch: 5601/10000, Train Loss: 34.81909110329368, Valid Loss: 39.40696589152018\n","Epoch: 5602/10000, Train Loss: 34.274884484030984, Valid Loss: 39.349159240722656\n","Epoch: 5603/10000, Train Loss: 34.67427149685946, Valid Loss: 39.57030487060547\n","Epoch: 5604/10000, Train Loss: 34.8173301003196, Valid Loss: 39.3131103515625\n","Epoch: 5605/10000, Train Loss: 34.70952606201172, Valid Loss: 39.505261739095054\n","Epoch: 5606/10000, Train Loss: 35.003536224365234, Valid Loss: 39.417823791503906\n","Epoch: 5607/10000, Train Loss: 35.032030452381484, Valid Loss: 39.434794108072914\n","Epoch: 5608/10000, Train Loss: 34.66832212968306, Valid Loss: 39.29832458496094\n","Epoch: 5609/10000, Train Loss: 35.02136785333807, Valid Loss: 39.17820739746094\n","Epoch: 5610/10000, Train Loss: 34.640779148448594, Valid Loss: 39.225337982177734\n","Epoch: 5611/10000, Train Loss: 34.66440339521928, Valid Loss: 39.18001937866211\n","Epoch: 5612/10000, Train Loss: 34.40205678072843, Valid Loss: 39.100293477376304\n","Epoch: 5613/10000, Train Loss: 34.636272777210586, Valid Loss: 39.29905700683594\n","Epoch: 5614/10000, Train Loss: 34.344103899869054, Valid Loss: 39.272193908691406\n","Epoch: 5615/10000, Train Loss: 34.6198564009233, Valid Loss: 39.30834452311198\n","Epoch: 5616/10000, Train Loss: 34.775775562633164, Valid Loss: 39.3045768737793\n","Epoch: 5617/10000, Train Loss: 34.47451400756836, Valid Loss: 39.387343088785805\n","Epoch: 5618/10000, Train Loss: 34.83522588556463, Valid Loss: 39.19179026285807\n","Epoch: 5619/10000, Train Loss: 34.69636969132857, Valid Loss: 39.24395243326823\n","Epoch: 5620/10000, Train Loss: 34.54483326998624, Valid Loss: 39.303009033203125\n","Epoch: 5621/10000, Train Loss: 34.88869788429954, Valid Loss: 39.29992167154948\n","Epoch: 5622/10000, Train Loss: 34.40840738469904, Valid Loss: 38.99938837687174\n","Epoch: 5623/10000, Train Loss: 34.83314236727628, Valid Loss: 39.22050984700521\n","Epoch: 5624/10000, Train Loss: 34.00267722389915, Valid Loss: 39.331625620524086\n","Epoch: 5625/10000, Train Loss: 34.196226986971766, Valid Loss: 39.283102671305336\n","Epoch: 5626/10000, Train Loss: 34.58742141723633, Valid Loss: 39.26491673787435\n","Epoch: 5627/10000, Train Loss: 34.47629859230735, Valid Loss: 39.20874913533529\n","Epoch: 5628/10000, Train Loss: 34.357318357987836, Valid Loss: 39.33139673868815\n","Epoch: 5629/10000, Train Loss: 34.212431994351476, Valid Loss: 39.395093282063804\n","Epoch: 5630/10000, Train Loss: 34.62677591497248, Valid Loss: 39.396854400634766\n","Epoch: 5631/10000, Train Loss: 34.19981141523881, Valid Loss: 39.142197926839195\n","Epoch: 5632/10000, Train Loss: 34.322595769708805, Valid Loss: 39.14476521809896\n","Epoch: 5633/10000, Train Loss: 34.266943498091265, Valid Loss: 39.103224436442055\n","Epoch: 5634/10000, Train Loss: 34.87300283258612, Valid Loss: 39.1827278137207\n","Epoch: 5635/10000, Train Loss: 34.64889561046254, Valid Loss: 39.23614247639974\n","Epoch: 5636/10000, Train Loss: 34.65783882141113, Valid Loss: 39.31414794921875\n","Epoch: 5637/10000, Train Loss: 34.6233076615767, Valid Loss: 39.45275624593099\n","Epoch: 5638/10000, Train Loss: 34.353586890480734, Valid Loss: 39.23578898111979\n","Epoch: 5639/10000, Train Loss: 34.58736870505593, Valid Loss: 39.25996398925781\n","Epoch: 5640/10000, Train Loss: 34.729860825972125, Valid Loss: 39.36437861124674\n","Epoch: 5641/10000, Train Loss: 34.34543106772683, Valid Loss: 39.15063222249349\n","Epoch: 5642/10000, Train Loss: 34.907455097545274, Valid Loss: 39.226436614990234\n","Epoch: 5643/10000, Train Loss: 34.71110291914506, Valid Loss: 39.30886459350586\n","Epoch: 5644/10000, Train Loss: 34.49524827436967, Valid Loss: 39.17266082763672\n","Epoch: 5645/10000, Train Loss: 34.643254713578656, Valid Loss: 39.27836227416992\n","Epoch: 5646/10000, Train Loss: 34.06867928938432, Valid Loss: 39.24885686238607\n","Epoch: 5647/10000, Train Loss: 34.63708513433283, Valid Loss: 39.19241714477539\n","Epoch: 5648/10000, Train Loss: 34.171123678034, Valid Loss: 39.07655715942383\n","Epoch: 5649/10000, Train Loss: 35.02391607111151, Valid Loss: 39.008131663004555\n","Epoch: 5650/10000, Train Loss: 34.09494989568537, Valid Loss: 39.26118596394857\n","Epoch: 5651/10000, Train Loss: 34.46304598721591, Valid Loss: 39.3414675394694\n","Epoch: 5652/10000, Train Loss: 34.722321423617274, Valid Loss: 39.2917734781901\n","Epoch: 5653/10000, Train Loss: 35.00772198763761, Valid Loss: 39.35471725463867\n","Epoch: 5654/10000, Train Loss: 34.623853336681016, Valid Loss: 39.157840728759766\n","Epoch: 5655/10000, Train Loss: 34.88333806124601, Valid Loss: 39.29747645060221\n","Epoch: 5656/10000, Train Loss: 34.074266780506484, Valid Loss: 39.04571660359701\n","Epoch: 5657/10000, Train Loss: 34.800081426447086, Valid Loss: 38.974737803141274\n","Epoch: 5658/10000, Train Loss: 34.90711264176802, Valid Loss: 39.18106206258138\n","Epoch: 5659/10000, Train Loss: 34.52582133900035, Valid Loss: 39.15866216023763\n","Epoch: 5660/10000, Train Loss: 34.659242456609554, Valid Loss: 39.14134724934896\n","Epoch: 5661/10000, Train Loss: 34.053606726906516, Valid Loss: 39.04993438720703\n","Epoch: 5662/10000, Train Loss: 34.136044242165305, Valid Loss: 39.354531606038414\n","Epoch: 5663/10000, Train Loss: 34.39060349897905, Valid Loss: 39.1856435139974\n","Epoch: 5664/10000, Train Loss: 34.52507192438299, Valid Loss: 39.18281173706055\n","Epoch: 5665/10000, Train Loss: 34.22494975003329, Valid Loss: 39.24483871459961\n","Epoch: 5666/10000, Train Loss: 34.085963856090196, Valid Loss: 39.153603871663414\n","Epoch: 5667/10000, Train Loss: 34.47859365289862, Valid Loss: 39.19909795125326\n","Epoch: 5668/10000, Train Loss: 34.266293265602805, Valid Loss: 39.13378143310547\n","Epoch: 5669/10000, Train Loss: 35.029972076416016, Valid Loss: 39.20531972249349\n","Epoch: 5670/10000, Train Loss: 34.251013322310015, Valid Loss: 39.16224670410156\n","Epoch: 5671/10000, Train Loss: 34.420387441461735, Valid Loss: 39.23576736450195\n","Epoch: 5672/10000, Train Loss: 34.308306607333094, Valid Loss: 39.23826599121094\n","Epoch: 5673/10000, Train Loss: 34.21617438576438, Valid Loss: 39.19840876261393\n","Epoch: 5674/10000, Train Loss: 34.46805537830699, Valid Loss: 39.14923858642578\n","Epoch: 5675/10000, Train Loss: 34.98411802812056, Valid Loss: 39.15756607055664\n","Epoch: 5676/10000, Train Loss: 34.60513548417525, Valid Loss: 39.067169189453125\n","Epoch: 5677/10000, Train Loss: 34.30900955200195, Valid Loss: 39.02560170491537\n","Epoch: 5678/10000, Train Loss: 34.340672579678625, Valid Loss: 39.182631174723305\n","Epoch: 5679/10000, Train Loss: 34.58708607066762, Valid Loss: 39.136236826578774\n","Epoch: 5680/10000, Train Loss: 33.8717849037864, Valid Loss: 39.316454569498696\n","Epoch: 5681/10000, Train Loss: 34.29288031838157, Valid Loss: 39.08668899536133\n","Epoch: 5682/10000, Train Loss: 33.94534423134544, Valid Loss: 39.04668299357096\n","Epoch: 5683/10000, Train Loss: 34.50760078430176, Valid Loss: 39.07693227132162\n","Epoch: 5684/10000, Train Loss: 34.318594845858485, Valid Loss: 38.997816721598305\n","Epoch: 5685/10000, Train Loss: 34.41786505959251, Valid Loss: 39.08484013875326\n","Epoch: 5686/10000, Train Loss: 34.310301694003016, Valid Loss: 38.95463434855143\n","Epoch: 5687/10000, Train Loss: 34.21096749739213, Valid Loss: 39.069122314453125\n","Epoch: 5688/10000, Train Loss: 34.14437831531871, Valid Loss: 39.15948486328125\n","Epoch: 5689/10000, Train Loss: 34.83504208651456, Valid Loss: 39.16308466593424\n","Epoch: 5690/10000, Train Loss: 33.841995759443805, Valid Loss: 39.35916392008463\n","Epoch: 5691/10000, Train Loss: 34.24705696105957, Valid Loss: 39.14253362019857\n","Epoch: 5692/10000, Train Loss: 34.05442324551669, Valid Loss: 38.929064432779946\n","Epoch: 5693/10000, Train Loss: 34.4368123141202, Valid Loss: 39.038743336995445\n","Epoch: 5694/10000, Train Loss: 34.03608374162154, Valid Loss: 39.071537017822266\n","Epoch: 5695/10000, Train Loss: 34.30808431451971, Valid Loss: 39.0189094543457\n","Epoch: 5696/10000, Train Loss: 34.16906755620783, Valid Loss: 39.15528361002604\n","Epoch: 5697/10000, Train Loss: 33.95369096235795, Valid Loss: 39.2391357421875\n","Epoch: 5698/10000, Train Loss: 34.68093768033114, Valid Loss: 39.104777018229164\n","Epoch: 5699/10000, Train Loss: 34.39220983331854, Valid Loss: 39.07014083862305\n","Epoch: 5700/10000, Train Loss: 34.46634882146662, Valid Loss: 39.075547536214195\n","Epoch: 5701/10000, Train Loss: 34.41374969482422, Valid Loss: 39.02266057332357\n","Epoch: 5702/10000, Train Loss: 34.271169142289594, Valid Loss: 39.01637649536133\n","Epoch: 5703/10000, Train Loss: 34.36428937045011, Valid Loss: 39.09947077433268\n","Epoch: 5704/10000, Train Loss: 34.225798866965555, Valid Loss: 38.96462758382162\n","Epoch: 5705/10000, Train Loss: 34.77131895585494, Valid Loss: 39.12377802530924\n","Epoch: 5706/10000, Train Loss: 34.3428880518133, Valid Loss: 39.20826212565104\n","Epoch: 5707/10000, Train Loss: 34.072215513749555, Valid Loss: 39.22192128499349\n","Epoch: 5708/10000, Train Loss: 34.26167037270286, Valid Loss: 39.061500549316406\n","Epoch: 5709/10000, Train Loss: 34.32188831676137, Valid Loss: 39.333291371663414\n","Epoch: 5710/10000, Train Loss: 34.27873438054865, Valid Loss: 38.979017893473305\n","Epoch: 5711/10000, Train Loss: 34.25085657293146, Valid Loss: 39.001452128092446\n","Epoch: 5712/10000, Train Loss: 33.86191160028631, Valid Loss: 39.11617787679037\n","Epoch: 5713/10000, Train Loss: 34.454247214577414, Valid Loss: 39.0638542175293\n","Epoch: 5714/10000, Train Loss: 34.60553568059748, Valid Loss: 39.06811650594076\n","Epoch: 5715/10000, Train Loss: 34.3137241710316, Valid Loss: 38.969014485677086\n","Epoch: 5716/10000, Train Loss: 33.97942213578658, Valid Loss: 39.07391230265299\n","Epoch: 5717/10000, Train Loss: 34.00045117464933, Valid Loss: 39.09521357218424\n","Epoch: 5718/10000, Train Loss: 34.6236875707453, Valid Loss: 38.97445170084635\n","Epoch: 5719/10000, Train Loss: 34.958159013227984, Valid Loss: 39.21414311726888\n","Epoch: 5720/10000, Train Loss: 34.38713958046653, Valid Loss: 38.94957478841146\n","Epoch: 5721/10000, Train Loss: 34.59827839244496, Valid Loss: 39.07288614908854\n","Epoch: 5722/10000, Train Loss: 35.042416139082476, Valid Loss: 39.11322530110677\n","Epoch: 5723/10000, Train Loss: 34.396738572554156, Valid Loss: 39.264424641927086\n","Epoch: 5724/10000, Train Loss: 33.82350713556463, Valid Loss: 39.108543395996094\n","Epoch: 5725/10000, Train Loss: 34.45575297962535, Valid Loss: 39.04753494262695\n","Epoch: 5726/10000, Train Loss: 33.97676884044301, Valid Loss: 39.056959788004555\n","Epoch: 5727/10000, Train Loss: 33.98695304177024, Valid Loss: 38.9853146870931\n","Epoch: 5728/10000, Train Loss: 34.32203969088468, Valid Loss: 38.97054545084635\n","Epoch: 5729/10000, Train Loss: 34.11110375144265, Valid Loss: 38.96655019124349\n","Epoch: 5730/10000, Train Loss: 34.1110633503307, Valid Loss: 39.26243591308594\n","Epoch: 5731/10000, Train Loss: 34.1228720925071, Valid Loss: 38.95583724975586\n","Epoch: 5732/10000, Train Loss: 33.87085221030495, Valid Loss: 38.903647104899086\n","Epoch: 5733/10000, Train Loss: 33.97938121448863, Valid Loss: 38.862284342447914\n","Epoch: 5734/10000, Train Loss: 34.333384080366656, Valid Loss: 39.05031967163086\n","Epoch: 5735/10000, Train Loss: 33.96563131159002, Valid Loss: 38.86297607421875\n","Epoch: 5736/10000, Train Loss: 34.27571418068626, Valid Loss: 38.8810183207194\n","Epoch: 5737/10000, Train Loss: 33.76512145996094, Valid Loss: 38.922831217447914\n","Epoch: 5738/10000, Train Loss: 34.39662690596147, Valid Loss: 39.141719818115234\n","Epoch: 5739/10000, Train Loss: 33.92749231511896, Valid Loss: 39.103379567464195\n","Epoch: 5740/10000, Train Loss: 34.109473661942914, Valid Loss: 38.89264806111654\n","Epoch: 5741/10000, Train Loss: 34.445863550359554, Valid Loss: 38.96467717488607\n","Epoch: 5742/10000, Train Loss: 34.205364574085586, Valid Loss: 39.04051844278971\n","Epoch: 5743/10000, Train Loss: 34.131054097955875, Valid Loss: 39.03601964314779\n","Epoch: 5744/10000, Train Loss: 34.3400672565807, Valid Loss: 38.96670786539713\n","Epoch: 5745/10000, Train Loss: 33.955279957164414, Valid Loss: 38.94265874226888\n","Epoch: 5746/10000, Train Loss: 34.091571981256656, Valid Loss: 38.96276601155599\n","Epoch: 5747/10000, Train Loss: 34.164880925958805, Valid Loss: 38.92647806803385\n","Epoch: 5748/10000, Train Loss: 34.05474732138894, Valid Loss: 38.88388315836588\n","Epoch: 5749/10000, Train Loss: 34.174462751908735, Valid Loss: 38.76327641805013\n","Epoch: 5750/10000, Train Loss: 34.62038161537864, Valid Loss: 38.977577209472656\n","Epoch: 5751/10000, Train Loss: 33.801128907637164, Valid Loss: 38.94389979044596\n","Epoch: 5752/10000, Train Loss: 34.319183349609375, Valid Loss: 38.94431813557943\n","Epoch: 5753/10000, Train Loss: 33.7570726221258, Valid Loss: 39.11654281616211\n","Epoch: 5754/10000, Train Loss: 34.84761758284135, Valid Loss: 38.89248021443685\n","Epoch: 5755/10000, Train Loss: 33.89199846441095, Valid Loss: 39.00056584676107\n","Epoch: 5756/10000, Train Loss: 34.26744998585094, Valid Loss: 38.93796030680338\n","Epoch: 5757/10000, Train Loss: 34.08302861993963, Valid Loss: 38.99128977457682\n","Epoch: 5758/10000, Train Loss: 34.423549305308946, Valid Loss: 38.833291371663414\n","Epoch: 5759/10000, Train Loss: 34.02664409984242, Valid Loss: 39.01695251464844\n","Epoch: 5760/10000, Train Loss: 34.15435236150568, Valid Loss: 39.010056813557945\n","Epoch: 5761/10000, Train Loss: 34.17856805974787, Valid Loss: 38.93111673990885\n","Epoch: 5762/10000, Train Loss: 33.73596676913175, Valid Loss: 38.77728780110677\n","Epoch: 5763/10000, Train Loss: 34.16234935413707, Valid Loss: 38.79658508300781\n","Epoch: 5764/10000, Train Loss: 33.870804179798476, Valid Loss: 39.01678466796875\n","Epoch: 5765/10000, Train Loss: 33.64648229425604, Valid Loss: 38.78504943847656\n","Epoch: 5766/10000, Train Loss: 33.78064779801802, Valid Loss: 38.80590565999349\n","Epoch: 5767/10000, Train Loss: 34.02436655217951, Valid Loss: 38.9269765218099\n","Epoch: 5768/10000, Train Loss: 34.19180124456232, Valid Loss: 39.11386362711588\n","Epoch: 5769/10000, Train Loss: 33.892277804288, Valid Loss: 39.028968811035156\n","Epoch: 5770/10000, Train Loss: 34.48578955910423, Valid Loss: 38.937880198160805\n","Epoch: 5771/10000, Train Loss: 34.043453736738726, Valid Loss: 39.04232533772787\n","Epoch: 5772/10000, Train Loss: 33.925962621515446, Valid Loss: 39.06942876180013\n","Epoch: 5773/10000, Train Loss: 34.092084191062234, Valid Loss: 38.910265604654946\n","Epoch: 5774/10000, Train Loss: 34.31142997741699, Valid Loss: 38.83053461710612\n","Epoch: 5775/10000, Train Loss: 33.64387477527965, Valid Loss: 38.65290832519531\n","Epoch: 5776/10000, Train Loss: 33.74168950861151, Valid Loss: 38.948594411214195\n","Epoch: 5777/10000, Train Loss: 33.29740056124601, Valid Loss: 38.98837661743164\n","Epoch: 5778/10000, Train Loss: 33.95700385353782, Valid Loss: 38.98811467488607\n","Epoch: 5779/10000, Train Loss: 33.70399561795321, Valid Loss: 38.987738291422524\n","Epoch: 5780/10000, Train Loss: 34.04649491743608, Valid Loss: 38.870811462402344\n","Epoch: 5781/10000, Train Loss: 34.3646802035245, Valid Loss: 38.88129170735677\n","Epoch: 5782/10000, Train Loss: 34.163215983997695, Valid Loss: 38.76285044352213\n","Epoch: 5783/10000, Train Loss: 34.147336439652875, Valid Loss: 38.94131342569987\n","Epoch: 5784/10000, Train Loss: 33.8706748268821, Valid Loss: 38.93396250406901\n","Epoch: 5785/10000, Train Loss: 34.27009339766069, Valid Loss: 38.85757573445638\n","Epoch: 5786/10000, Train Loss: 33.97238263216886, Valid Loss: 38.945963541666664\n","Epoch: 5787/10000, Train Loss: 34.22188949584961, Valid Loss: 39.002020517985024\n","Epoch: 5788/10000, Train Loss: 33.91745168512518, Valid Loss: 38.773006439208984\n","Epoch: 5789/10000, Train Loss: 33.97117545387962, Valid Loss: 38.879809061686196\n","Epoch: 5790/10000, Train Loss: 33.54333565451882, Valid Loss: 39.02301279703776\n","Epoch: 5791/10000, Train Loss: 33.93832015991211, Valid Loss: 38.86785888671875\n","Epoch: 5792/10000, Train Loss: 33.69580632990057, Valid Loss: 38.87712732950846\n","Epoch: 5793/10000, Train Loss: 33.54757170243697, Valid Loss: 38.93584060668945\n","Epoch: 5794/10000, Train Loss: 33.93910841508345, Valid Loss: 38.830064137776695\n","Epoch: 5795/10000, Train Loss: 33.18522227894176, Valid Loss: 39.00273132324219\n","Epoch: 5796/10000, Train Loss: 33.60020862926137, Valid Loss: 38.79387283325195\n","Epoch: 5797/10000, Train Loss: 33.898557836359196, Valid Loss: 38.937931060791016\n","Epoch: 5798/10000, Train Loss: 33.720243800770156, Valid Loss: 38.70310084025065\n","Epoch: 5799/10000, Train Loss: 34.05036648837003, Valid Loss: 38.80286661783854\n","Epoch: 5800/10000, Train Loss: 33.45384909889915, Valid Loss: 38.79881159464518\n","Epoch: 5801/10000, Train Loss: 34.044329556551844, Valid Loss: 38.88882191975912\n","Epoch: 5802/10000, Train Loss: 34.144560900601476, Valid Loss: 38.75628662109375\n","Epoch: 5803/10000, Train Loss: 33.83435249328613, Valid Loss: 38.80088806152344\n","Epoch: 5804/10000, Train Loss: 33.90073516152122, Valid Loss: 38.77021153767904\n","Epoch: 5805/10000, Train Loss: 33.70726897499778, Valid Loss: 38.866214752197266\n","Epoch: 5806/10000, Train Loss: 33.89257257634943, Valid Loss: 38.719258626302086\n","Epoch: 5807/10000, Train Loss: 34.00892084295099, Valid Loss: 38.97108586629232\n","Epoch: 5808/10000, Train Loss: 34.098051417957656, Valid Loss: 38.73401387532552\n","Epoch: 5809/10000, Train Loss: 33.90929274125533, Valid Loss: 38.84479268391927\n","Epoch: 5810/10000, Train Loss: 33.97585036537864, Valid Loss: 38.69418462117513\n","Epoch: 5811/10000, Train Loss: 33.74456197565252, Valid Loss: 38.69537226359049\n","Epoch: 5812/10000, Train Loss: 33.82879066467285, Valid Loss: 38.90048090616862\n","Epoch: 5813/10000, Train Loss: 34.00010230324485, Valid Loss: 38.84532674153646\n","Epoch: 5814/10000, Train Loss: 34.44355947321112, Valid Loss: 38.79384231567383\n","Epoch: 5815/10000, Train Loss: 34.05611384998668, Valid Loss: 38.772945404052734\n","Epoch: 5816/10000, Train Loss: 33.6850832158869, Valid Loss: 38.81423314412435\n","Epoch: 5817/10000, Train Loss: 33.510710976340555, Valid Loss: 38.8380978902181\n","Epoch: 5818/10000, Train Loss: 33.87622555819425, Valid Loss: 38.668450673421226\n","Epoch: 5819/10000, Train Loss: 33.627808657559484, Valid Loss: 38.72800318400065\n","Epoch: 5820/10000, Train Loss: 33.84287157925692, Valid Loss: 38.80102030436198\n","Epoch: 5821/10000, Train Loss: 33.92858904058283, Valid Loss: 38.68710962931315\n","Epoch: 5822/10000, Train Loss: 33.733734824440695, Valid Loss: 38.82526652018229\n","Epoch: 5823/10000, Train Loss: 34.166099548339844, Valid Loss: 38.79466247558594\n","Epoch: 5824/10000, Train Loss: 33.96537954157049, Valid Loss: 38.86638387044271\n","Epoch: 5825/10000, Train Loss: 34.15592471036044, Valid Loss: 38.57536697387695\n","Epoch: 5826/10000, Train Loss: 33.8070630160245, Valid Loss: 38.64108149210612\n","Epoch: 5827/10000, Train Loss: 34.28898967396129, Valid Loss: 38.829786936442055\n","Epoch: 5828/10000, Train Loss: 33.79211564497514, Valid Loss: 38.99760945638021\n","Epoch: 5829/10000, Train Loss: 33.72155085476962, Valid Loss: 38.86232884724935\n","Epoch: 5830/10000, Train Loss: 33.643251245672054, Valid Loss: 38.78696060180664\n","Epoch: 5831/10000, Train Loss: 33.66420485756614, Valid Loss: 38.749986012776695\n","Epoch: 5832/10000, Train Loss: 33.54151084206321, Valid Loss: 38.77188364664713\n","Epoch: 5833/10000, Train Loss: 33.9680983803489, Valid Loss: 38.85928090413412\n","Epoch: 5834/10000, Train Loss: 34.68688305941495, Valid Loss: 38.7480214436849\n","Epoch: 5835/10000, Train Loss: 33.61440242420543, Valid Loss: 38.63934071858724\n","Epoch: 5836/10000, Train Loss: 34.0687422318892, Valid Loss: 38.83136494954427\n","Epoch: 5837/10000, Train Loss: 34.32522687045011, Valid Loss: 38.90516026814779\n","Epoch: 5838/10000, Train Loss: 34.00227286598899, Valid Loss: 39.06026840209961\n","Epoch: 5839/10000, Train Loss: 34.24146981672807, Valid Loss: 38.88120905558268\n","Epoch: 5840/10000, Train Loss: 33.8608003096147, Valid Loss: 38.90745162963867\n","Epoch: 5841/10000, Train Loss: 33.703083211725406, Valid Loss: 38.765069325764976\n","Epoch: 5842/10000, Train Loss: 34.235537962480024, Valid Loss: 38.78936767578125\n","Epoch: 5843/10000, Train Loss: 33.75167187777433, Valid Loss: 38.78772862752279\n","Epoch: 5844/10000, Train Loss: 33.431431857022375, Valid Loss: 38.79120381673177\n","Epoch: 5845/10000, Train Loss: 33.48191972212358, Valid Loss: 38.7184206644694\n","Epoch: 5846/10000, Train Loss: 33.36031636324796, Valid Loss: 38.76535161336263\n","Epoch: 5847/10000, Train Loss: 34.11211169849742, Valid Loss: 38.86491775512695\n","Epoch: 5848/10000, Train Loss: 33.850568077780984, Valid Loss: 38.97992833455404\n","Epoch: 5849/10000, Train Loss: 33.37761757590554, Valid Loss: 38.72153345743815\n","Epoch: 5850/10000, Train Loss: 33.61989003961737, Valid Loss: 38.842454274495445\n","Epoch: 5851/10000, Train Loss: 34.0358302376487, Valid Loss: 38.758602142333984\n","Epoch: 5852/10000, Train Loss: 33.70579112659801, Valid Loss: 38.861595153808594\n","Epoch: 5853/10000, Train Loss: 33.97335069829767, Valid Loss: 38.71015930175781\n","Epoch: 5854/10000, Train Loss: 33.32727414911444, Valid Loss: 38.79921849568685\n","Epoch: 5855/10000, Train Loss: 33.6688043420965, Valid Loss: 38.70480982462565\n","Epoch: 5856/10000, Train Loss: 33.49777030944824, Valid Loss: 38.79874801635742\n","Epoch: 5857/10000, Train Loss: 33.63859627463601, Valid Loss: 38.465492248535156\n","Epoch: 5858/10000, Train Loss: 34.245439529418945, Valid Loss: 38.57478332519531\n","Epoch: 5859/10000, Train Loss: 33.70085889642889, Valid Loss: 38.67306900024414\n","Epoch: 5860/10000, Train Loss: 33.373320666226476, Valid Loss: 38.54230626424154\n","Epoch: 5861/10000, Train Loss: 34.02363725142045, Valid Loss: 38.68765004475912\n","Epoch: 5862/10000, Train Loss: 33.281271327625625, Valid Loss: 38.667284647623696\n","Epoch: 5863/10000, Train Loss: 33.42182783647017, Valid Loss: 38.77012379964193\n","Epoch: 5864/10000, Train Loss: 33.08875777504661, Valid Loss: 38.808938344319664\n","Epoch: 5865/10000, Train Loss: 33.60218134793368, Valid Loss: 38.6661122639974\n","Epoch: 5866/10000, Train Loss: 33.607811494307086, Valid Loss: 38.61812973022461\n","Epoch: 5867/10000, Train Loss: 33.64614885503595, Valid Loss: 38.71969858805338\n","Epoch: 5868/10000, Train Loss: 34.26698303222656, Valid Loss: 38.661120096842446\n","Epoch: 5869/10000, Train Loss: 33.996308066628195, Valid Loss: 38.730272928873696\n","Epoch: 5870/10000, Train Loss: 34.21384031122381, Valid Loss: 38.75754928588867\n","Epoch: 5871/10000, Train Loss: 33.90173773332076, Valid Loss: 38.81303278605143\n","Epoch: 5872/10000, Train Loss: 33.1686410036954, Valid Loss: 38.762332916259766\n","Epoch: 5873/10000, Train Loss: 34.17584419250488, Valid Loss: 38.740336100260414\n","Epoch: 5874/10000, Train Loss: 34.0967604897239, Valid Loss: 38.60245132446289\n","Epoch: 5875/10000, Train Loss: 33.530465386130594, Valid Loss: 38.59951400756836\n","Epoch: 5876/10000, Train Loss: 33.67382621765137, Valid Loss: 38.59369913736979\n","Epoch: 5877/10000, Train Loss: 33.366830652410336, Valid Loss: 38.604485829671226\n","Epoch: 5878/10000, Train Loss: 33.537424087524414, Valid Loss: 38.67544428507487\n","Epoch: 5879/10000, Train Loss: 33.46331631053578, Valid Loss: 38.624454498291016\n","Epoch: 5880/10000, Train Loss: 33.513443513350055, Valid Loss: 38.62530008951823\n","Epoch: 5881/10000, Train Loss: 33.63786732066762, Valid Loss: 38.61264419555664\n","Epoch: 5882/10000, Train Loss: 33.87625156749379, Valid Loss: 38.64903767903646\n","Epoch: 5883/10000, Train Loss: 34.02418240633878, Valid Loss: 38.55141576131185\n","Epoch: 5884/10000, Train Loss: 33.38185136968439, Valid Loss: 38.59166463216146\n","Epoch: 5885/10000, Train Loss: 33.93663701144132, Valid Loss: 38.74291865030924\n","Epoch: 5886/10000, Train Loss: 33.36231023615057, Valid Loss: 38.59221903483073\n","Epoch: 5887/10000, Train Loss: 33.43736891313033, Valid Loss: 38.539747873942055\n","Epoch: 5888/10000, Train Loss: 34.465194181962445, Valid Loss: 38.870402018229164\n","Epoch: 5889/10000, Train Loss: 34.12385246970437, Valid Loss: 38.87191899617513\n","Epoch: 5890/10000, Train Loss: 33.70781360973012, Valid Loss: 38.765333811442055\n","Epoch: 5891/10000, Train Loss: 33.53957661715421, Valid Loss: 38.80051040649414\n","Epoch: 5892/10000, Train Loss: 33.58065119656649, Valid Loss: 38.81447092692057\n","Epoch: 5893/10000, Train Loss: 33.3670539855957, Valid Loss: 38.75190099080404\n","Epoch: 5894/10000, Train Loss: 33.67454008622603, Valid Loss: 38.70354080200195\n","Epoch: 5895/10000, Train Loss: 33.61671257019043, Valid Loss: 38.69573847452799\n","Epoch: 5896/10000, Train Loss: 33.72208300503817, Valid Loss: 38.85249582926432\n","Epoch: 5897/10000, Train Loss: 33.204604929143734, Valid Loss: 38.62701924641927\n","Epoch: 5898/10000, Train Loss: 33.806184248490766, Valid Loss: 38.49458694458008\n","Epoch: 5899/10000, Train Loss: 33.243800076571375, Valid Loss: 38.712660471598305\n","Epoch: 5900/10000, Train Loss: 33.67426300048828, Valid Loss: 38.57727177937826\n","Epoch: 5901/10000, Train Loss: 33.28091621398926, Valid Loss: 38.878622690836586\n","Epoch: 5902/10000, Train Loss: 33.642986644398086, Valid Loss: 38.58808263142904\n","Epoch: 5903/10000, Train Loss: 33.32455322959206, Valid Loss: 38.60181681315104\n","Epoch: 5904/10000, Train Loss: 33.68748647516424, Valid Loss: 38.47679011027018\n","Epoch: 5905/10000, Train Loss: 33.2854811928489, Valid Loss: 38.55222956339518\n","Epoch: 5906/10000, Train Loss: 33.84654235839844, Valid Loss: 38.66101964314779\n","Epoch: 5907/10000, Train Loss: 33.566424109719016, Valid Loss: 38.57251230875651\n","Epoch: 5908/10000, Train Loss: 33.66119610179555, Valid Loss: 38.686211903889976\n","Epoch: 5909/10000, Train Loss: 33.7053279876709, Valid Loss: 38.55000686645508\n","Epoch: 5910/10000, Train Loss: 33.714256286621094, Valid Loss: 38.59000015258789\n","Epoch: 5911/10000, Train Loss: 33.23066538030451, Valid Loss: 38.48954391479492\n","Epoch: 5912/10000, Train Loss: 33.47943739457564, Valid Loss: 38.5641721089681\n","Epoch: 5913/10000, Train Loss: 33.65501299771395, Valid Loss: 38.576131184895836\n","Epoch: 5914/10000, Train Loss: 33.406692851673476, Valid Loss: 38.60054143269857\n","Epoch: 5915/10000, Train Loss: 33.7465728412975, Valid Loss: 38.55067443847656\n","Epoch: 5916/10000, Train Loss: 33.90011631358754, Valid Loss: 38.688714345296226\n","Epoch: 5917/10000, Train Loss: 33.476798664439805, Valid Loss: 38.68322245279948\n","Epoch: 5918/10000, Train Loss: 33.500689419833094, Valid Loss: 38.62775675455729\n","Epoch: 5919/10000, Train Loss: 33.53955563631925, Valid Loss: 38.71296183268229\n","Epoch: 5920/10000, Train Loss: 33.257075396451086, Valid Loss: 38.580132802327476\n","Epoch: 5921/10000, Train Loss: 33.65290780500932, Valid Loss: 38.59063466389974\n","Epoch: 5922/10000, Train Loss: 34.169004613702946, Valid Loss: 38.52581024169922\n","Epoch: 5923/10000, Train Loss: 33.41312460465865, Valid Loss: 38.73042424519857\n","Epoch: 5924/10000, Train Loss: 33.5571082722057, Valid Loss: 38.86858622233073\n","Epoch: 5925/10000, Train Loss: 33.75313360040838, Valid Loss: 38.69179662068685\n","Epoch: 5926/10000, Train Loss: 33.25761691006747, Valid Loss: 38.74792989095052\n","Epoch: 5927/10000, Train Loss: 33.590023734352805, Valid Loss: 38.589680989583336\n","Epoch: 5928/10000, Train Loss: 33.6274528503418, Valid Loss: 38.64572270711263\n","Epoch: 5929/10000, Train Loss: 33.315596320412375, Valid Loss: 38.587223052978516\n","Epoch: 5930/10000, Train Loss: 33.76626690951261, Valid Loss: 38.705579121907554\n","Epoch: 5931/10000, Train Loss: 33.787594361738726, Valid Loss: 38.68865712483724\n","Epoch: 5932/10000, Train Loss: 33.33949175747958, Valid Loss: 38.6423454284668\n","Epoch: 5933/10000, Train Loss: 33.75166823647239, Valid Loss: 38.57652791341146\n","Epoch: 5934/10000, Train Loss: 33.37510386380282, Valid Loss: 38.58662668863932\n","Epoch: 5935/10000, Train Loss: 33.782076402144, Valid Loss: 38.50875473022461\n","Epoch: 5936/10000, Train Loss: 33.51043649153276, Valid Loss: 38.638258616129555\n","Epoch: 5937/10000, Train Loss: 34.149120504205875, Valid Loss: 38.715728759765625\n","Epoch: 5938/10000, Train Loss: 33.33796639875932, Valid Loss: 38.7961680094401\n","Epoch: 5939/10000, Train Loss: 33.865686590021305, Valid Loss: 38.79454676310221\n","Epoch: 5940/10000, Train Loss: 33.47967668013139, Valid Loss: 38.74296442667643\n","Epoch: 5941/10000, Train Loss: 33.6781699440696, Valid Loss: 38.61258188883463\n","Epoch: 5942/10000, Train Loss: 32.984892411665484, Valid Loss: 38.575826009114586\n","Epoch: 5943/10000, Train Loss: 33.474369916048914, Valid Loss: 38.549853006998696\n","Epoch: 5944/10000, Train Loss: 33.71213808926669, Valid Loss: 38.63970057169596\n","Epoch: 5945/10000, Train Loss: 33.08464084972035, Valid Loss: 38.81524531046549\n","Epoch: 5946/10000, Train Loss: 33.32680372758345, Valid Loss: 38.66909408569336\n","Epoch: 5947/10000, Train Loss: 33.71633390946822, Valid Loss: 38.70075352986654\n","Epoch: 5948/10000, Train Loss: 33.15043917569247, Valid Loss: 38.564474741617836\n","Epoch: 5949/10000, Train Loss: 33.866691242564805, Valid Loss: 38.56547419230143\n","Epoch: 5950/10000, Train Loss: 33.279335195367985, Valid Loss: 38.68554433186849\n","Epoch: 5951/10000, Train Loss: 33.66902108625932, Valid Loss: 38.557884216308594\n","Epoch: 5952/10000, Train Loss: 33.89257795160467, Valid Loss: 38.553504943847656\n","Epoch: 5953/10000, Train Loss: 34.11744863336737, Valid Loss: 38.491676330566406\n","Epoch: 5954/10000, Train Loss: 33.39420665394176, Valid Loss: 38.41198857625326\n","Epoch: 5955/10000, Train Loss: 33.7930323860862, Valid Loss: 38.50585810343424\n","Epoch: 5956/10000, Train Loss: 33.71328995444558, Valid Loss: 38.53431955973307\n","Epoch: 5957/10000, Train Loss: 33.43558138067072, Valid Loss: 38.50811767578125\n","Epoch: 5958/10000, Train Loss: 32.984176115556195, Valid Loss: 38.428113301595054\n","Epoch: 5959/10000, Train Loss: 33.89196655967019, Valid Loss: 38.5276985168457\n","Epoch: 5960/10000, Train Loss: 33.35356538945978, Valid Loss: 38.41317494710287\n","Epoch: 5961/10000, Train Loss: 33.531764637340196, Valid Loss: 38.66865539550781\n","Epoch: 5962/10000, Train Loss: 33.126157240434125, Valid Loss: 38.55028533935547\n","Epoch: 5963/10000, Train Loss: 33.27496216513894, Valid Loss: 38.48681640625\n","Epoch: 5964/10000, Train Loss: 33.156890002163976, Valid Loss: 38.641947428385414\n","Epoch: 5965/10000, Train Loss: 33.6491980119185, Valid Loss: 38.51750691731771\n","Epoch: 5966/10000, Train Loss: 33.05232897671786, Valid Loss: 38.487325032552086\n","Epoch: 5967/10000, Train Loss: 33.55689152804288, Valid Loss: 38.42495600382487\n","Epoch: 5968/10000, Train Loss: 33.10114947232333, Valid Loss: 38.49205780029297\n","Epoch: 5969/10000, Train Loss: 33.86603511463512, Valid Loss: 38.55846150716146\n","Epoch: 5970/10000, Train Loss: 33.221541144631125, Valid Loss: 38.57030359903971\n","Epoch: 5971/10000, Train Loss: 33.85754117098722, Valid Loss: 38.627899169921875\n","Epoch: 5972/10000, Train Loss: 33.248034563931554, Valid Loss: 38.628798166910805\n","Epoch: 5973/10000, Train Loss: 33.83037341724742, Valid Loss: 38.685872395833336\n","Epoch: 5974/10000, Train Loss: 33.496268012306906, Valid Loss: 38.54875946044922\n","Epoch: 5975/10000, Train Loss: 33.66002516313033, Valid Loss: 38.480115254720054\n","Epoch: 5976/10000, Train Loss: 33.84991177645597, Valid Loss: 38.62114969889323\n","Epoch: 5977/10000, Train Loss: 33.848927931352094, Valid Loss: 38.41839599609375\n","Epoch: 5978/10000, Train Loss: 33.34577196294611, Valid Loss: 38.64765294392904\n","Epoch: 5979/10000, Train Loss: 33.11737285960805, Valid Loss: 38.28050104777018\n","Epoch: 5980/10000, Train Loss: 33.01467462019487, Valid Loss: 38.140881856282554\n","Epoch: 5981/10000, Train Loss: 33.41968328302557, Valid Loss: 38.38771057128906\n","Epoch: 5982/10000, Train Loss: 33.207046855579726, Valid Loss: 38.25654093424479\n","Epoch: 5983/10000, Train Loss: 33.439977472478695, Valid Loss: 38.4950803120931\n","Epoch: 5984/10000, Train Loss: 32.48495101928711, Valid Loss: 38.62015914916992\n","Epoch: 5985/10000, Train Loss: 33.5012676932595, Valid Loss: 38.43858210245768\n","Epoch: 5986/10000, Train Loss: 33.315989927812055, Valid Loss: 38.441691080729164\n","Epoch: 5987/10000, Train Loss: 33.510794379494406, Valid Loss: 38.48820495605469\n","Epoch: 5988/10000, Train Loss: 33.28463554382324, Valid Loss: 38.635138193766274\n","Epoch: 5989/10000, Train Loss: 32.72723683443937, Valid Loss: 38.631306966145836\n","Epoch: 5990/10000, Train Loss: 33.34905988519842, Valid Loss: 38.62728627522787\n","Epoch: 5991/10000, Train Loss: 33.738581223921344, Valid Loss: 38.52407455444336\n","Epoch: 5992/10000, Train Loss: 33.55152476917613, Valid Loss: 38.35149129231771\n","Epoch: 5993/10000, Train Loss: 33.54990577697754, Valid Loss: 38.19982401529948\n","Epoch: 5994/10000, Train Loss: 33.83429648659446, Valid Loss: 38.40598805745443\n","Epoch: 5995/10000, Train Loss: 33.567086479880594, Valid Loss: 38.27802530924479\n","Epoch: 5996/10000, Train Loss: 33.29376931623979, Valid Loss: 38.25708516438802\n","Epoch: 5997/10000, Train Loss: 33.374710603193805, Valid Loss: 38.285935719807945\n","Epoch: 5998/10000, Train Loss: 32.95475075461648, Valid Loss: 38.40957387288412\n","Epoch: 5999/10000, Train Loss: 33.37800112637606, Valid Loss: 38.437374114990234\n","Epoch: 6000/10000, Train Loss: 33.103605617176406, Valid Loss: 38.4431266784668\n","Epoch: 6001/10000, Train Loss: 33.653363487937234, Valid Loss: 38.44693374633789\n","Epoch: 6002/10000, Train Loss: 33.0280595259233, Valid Loss: 38.37965647379557\n","Epoch: 6003/10000, Train Loss: 33.330107948996805, Valid Loss: 38.374062856038414\n","Epoch: 6004/10000, Train Loss: 33.401316209272906, Valid Loss: 38.46206029256185\n","Epoch: 6005/10000, Train Loss: 33.03437007557262, Valid Loss: 38.54359436035156\n","Epoch: 6006/10000, Train Loss: 33.37589159878817, Valid Loss: 38.186317443847656\n","Epoch: 6007/10000, Train Loss: 33.36980611627752, Valid Loss: 38.47502899169922\n","Epoch: 6008/10000, Train Loss: 33.22299072959206, Valid Loss: 38.43006261189779\n","Epoch: 6009/10000, Train Loss: 33.17254343899813, Valid Loss: 38.434008280436196\n","Epoch: 6010/10000, Train Loss: 33.07214650240812, Valid Loss: 38.49046834309896\n","Epoch: 6011/10000, Train Loss: 33.330548373135656, Valid Loss: 38.54866154988607\n","Epoch: 6012/10000, Train Loss: 33.31504873795943, Valid Loss: 38.47041447957357\n","Epoch: 6013/10000, Train Loss: 33.3726749420166, Valid Loss: 38.37070083618164\n","Epoch: 6014/10000, Train Loss: 32.95615144209428, Valid Loss: 38.4036610921224\n","Epoch: 6015/10000, Train Loss: 33.753813310102984, Valid Loss: 38.46031061808268\n","Epoch: 6016/10000, Train Loss: 33.215681769631125, Valid Loss: 38.50813674926758\n","Epoch: 6017/10000, Train Loss: 33.21561501242898, Valid Loss: 38.24563725789388\n","Epoch: 6018/10000, Train Loss: 32.99889876625755, Valid Loss: 38.13136672973633\n","Epoch: 6019/10000, Train Loss: 33.111134789206766, Valid Loss: 38.192307790120445\n","Epoch: 6020/10000, Train Loss: 33.51387561451305, Valid Loss: 38.455736796061196\n","Epoch: 6021/10000, Train Loss: 32.70083583484996, Valid Loss: 38.35727055867513\n","Epoch: 6022/10000, Train Loss: 33.01459711248224, Valid Loss: 38.488606770833336\n","Epoch: 6023/10000, Train Loss: 33.237471320412375, Valid Loss: 38.336448669433594\n","Epoch: 6024/10000, Train Loss: 33.01434620943937, Valid Loss: 38.38078053792318\n","Epoch: 6025/10000, Train Loss: 33.42772934653542, Valid Loss: 38.390716552734375\n","Epoch: 6026/10000, Train Loss: 33.29935802112926, Valid Loss: 38.301446278889976\n","Epoch: 6027/10000, Train Loss: 33.599390896883875, Valid Loss: 38.3696657816569\n","Epoch: 6028/10000, Train Loss: 33.309492111206055, Valid Loss: 38.330078125\n","Epoch: 6029/10000, Train Loss: 33.07818551497026, Valid Loss: 38.382266998291016\n","Epoch: 6030/10000, Train Loss: 33.14054159684615, Valid Loss: 38.506280263264976\n","Epoch: 6031/10000, Train Loss: 33.41351873224432, Valid Loss: 38.22632598876953\n","Epoch: 6032/10000, Train Loss: 33.01198976690119, Valid Loss: 38.468771616617836\n","Epoch: 6033/10000, Train Loss: 33.41494473544034, Valid Loss: 38.611611684163414\n","Epoch: 6034/10000, Train Loss: 32.85214042663574, Valid Loss: 38.759690602620445\n","Epoch: 6035/10000, Train Loss: 33.494204954667524, Valid Loss: 38.546329498291016\n","Epoch: 6036/10000, Train Loss: 32.97145878184926, Valid Loss: 38.440382639567055\n","Epoch: 6037/10000, Train Loss: 32.61969982494008, Valid Loss: 38.44046401977539\n","Epoch: 6038/10000, Train Loss: 33.31878800825639, Valid Loss: 38.28100713094076\n","Epoch: 6039/10000, Train Loss: 33.4765928441828, Valid Loss: 38.40072886149088\n","Epoch: 6040/10000, Train Loss: 32.76393058083274, Valid Loss: 38.18241882324219\n","Epoch: 6041/10000, Train Loss: 32.54889349503951, Valid Loss: 38.31775792439779\n","Epoch: 6042/10000, Train Loss: 32.92471903020685, Valid Loss: 38.34258524576823\n","Epoch: 6043/10000, Train Loss: 33.062940250743516, Valid Loss: 38.15408579508463\n","Epoch: 6044/10000, Train Loss: 33.27268201654608, Valid Loss: 38.09058634440104\n","Epoch: 6045/10000, Train Loss: 33.03342247009277, Valid Loss: 38.133941650390625\n","Epoch: 6046/10000, Train Loss: 33.515209371393375, Valid Loss: 38.352423350016274\n","Epoch: 6047/10000, Train Loss: 34.06791860407049, Valid Loss: 38.197339375813804\n","Epoch: 6048/10000, Train Loss: 33.35693550109863, Valid Loss: 38.21901321411133\n","Epoch: 6049/10000, Train Loss: 33.33822753212669, Valid Loss: 38.39431635538737\n","Epoch: 6050/10000, Train Loss: 33.31716520136053, Valid Loss: 38.43481318155924\n","Epoch: 6051/10000, Train Loss: 32.8054348338734, Valid Loss: 38.27200698852539\n","Epoch: 6052/10000, Train Loss: 33.053299470381305, Valid Loss: 38.260138193766274\n","Epoch: 6053/10000, Train Loss: 32.7617038380016, Valid Loss: 38.24148305257162\n","Epoch: 6054/10000, Train Loss: 32.957725524902344, Valid Loss: 38.390265146891274\n","Epoch: 6055/10000, Train Loss: 33.5450272993608, Valid Loss: 38.39348220825195\n","Epoch: 6056/10000, Train Loss: 33.74225217645819, Valid Loss: 38.625616709391274\n","Epoch: 6057/10000, Train Loss: 33.090111472389914, Valid Loss: 38.38566462198893\n","Epoch: 6058/10000, Train Loss: 33.390974044799805, Valid Loss: 38.32555898030599\n","Epoch: 6059/10000, Train Loss: 33.00579903342507, Valid Loss: 38.291028340657554\n","Epoch: 6060/10000, Train Loss: 33.542795701460406, Valid Loss: 38.23361078898112\n","Epoch: 6061/10000, Train Loss: 33.60341678966176, Valid Loss: 38.38435490926107\n","Epoch: 6062/10000, Train Loss: 33.42901177839799, Valid Loss: 38.4164187113444\n","Epoch: 6063/10000, Train Loss: 32.81412540782582, Valid Loss: 38.43690872192383\n","Epoch: 6064/10000, Train Loss: 33.19466902992942, Valid Loss: 38.34578069051107\n","Epoch: 6065/10000, Train Loss: 33.29218725724654, Valid Loss: 38.270888010660805\n","Epoch: 6066/10000, Train Loss: 33.37848524613814, Valid Loss: 38.371055603027344\n","Epoch: 6067/10000, Train Loss: 32.84507924860174, Valid Loss: 38.27800369262695\n","Epoch: 6068/10000, Train Loss: 33.31730807911266, Valid Loss: 38.219957987467446\n","Epoch: 6069/10000, Train Loss: 33.583152770996094, Valid Loss: 38.250176747639976\n","Epoch: 6070/10000, Train Loss: 32.62006378173828, Valid Loss: 38.25251007080078\n","Epoch: 6071/10000, Train Loss: 32.885163047096945, Valid Loss: 38.381980895996094\n","Epoch: 6072/10000, Train Loss: 32.31029371781783, Valid Loss: 38.26558303833008\n","Epoch: 6073/10000, Train Loss: 32.93277098915794, Valid Loss: 38.325459798177086\n","Epoch: 6074/10000, Train Loss: 32.694969003850765, Valid Loss: 38.27448399861654\n","Epoch: 6075/10000, Train Loss: 33.09030272743919, Valid Loss: 38.3654416402181\n","Epoch: 6076/10000, Train Loss: 32.62407233498313, Valid Loss: 38.32185363769531\n","Epoch: 6077/10000, Train Loss: 33.27541663429954, Valid Loss: 38.14858881632487\n","Epoch: 6078/10000, Train Loss: 33.12466309287331, Valid Loss: 38.111105600992836\n","Epoch: 6079/10000, Train Loss: 33.042137666182086, Valid Loss: 38.33794657389323\n","Epoch: 6080/10000, Train Loss: 32.90404146367853, Valid Loss: 38.40463002522787\n","Epoch: 6081/10000, Train Loss: 33.31306006691673, Valid Loss: 38.33333079020182\n","Epoch: 6082/10000, Train Loss: 33.07908803766424, Valid Loss: 38.286216735839844\n","Epoch: 6083/10000, Train Loss: 33.41730481928045, Valid Loss: 38.1458994547526\n","Epoch: 6084/10000, Train Loss: 33.5211330760609, Valid Loss: 38.21269226074219\n","Epoch: 6085/10000, Train Loss: 32.98297049782493, Valid Loss: 38.128379821777344\n","Epoch: 6086/10000, Train Loss: 33.29621887207031, Valid Loss: 38.30290730794271\n","Epoch: 6087/10000, Train Loss: 32.59190351312811, Valid Loss: 38.302878061930336\n","Epoch: 6088/10000, Train Loss: 33.11491671475497, Valid Loss: 38.305060068766274\n","Epoch: 6089/10000, Train Loss: 33.05647295171564, Valid Loss: 38.23520278930664\n","Epoch: 6090/10000, Train Loss: 33.70478474010121, Valid Loss: 38.255486806233726\n","Epoch: 6091/10000, Train Loss: 32.73696778037331, Valid Loss: 38.2773806254069\n","Epoch: 6092/10000, Train Loss: 33.1690805608576, Valid Loss: 38.32965215047201\n","Epoch: 6093/10000, Train Loss: 33.187917015769266, Valid Loss: 38.281490325927734\n","Epoch: 6094/10000, Train Loss: 32.85439595309171, Valid Loss: 38.184591929117836\n","Epoch: 6095/10000, Train Loss: 32.962645444003016, Valid Loss: 38.242819468180336\n","Epoch: 6096/10000, Train Loss: 32.487463691017844, Valid Loss: 38.3593495686849\n","Epoch: 6097/10000, Train Loss: 33.42410104924982, Valid Loss: 38.29303232828776\n","Epoch: 6098/10000, Train Loss: 32.65987430919301, Valid Loss: 38.29388427734375\n","Epoch: 6099/10000, Train Loss: 33.37437751076438, Valid Loss: 38.355813344319664\n","Epoch: 6100/10000, Train Loss: 33.176250631159, Valid Loss: 38.23013559977213\n","Epoch: 6101/10000, Train Loss: 32.947030154141515, Valid Loss: 38.26227569580078\n","Epoch: 6102/10000, Train Loss: 32.795381719415836, Valid Loss: 38.38041305541992\n","Epoch: 6103/10000, Train Loss: 33.26975839788263, Valid Loss: 38.18597920735677\n","Epoch: 6104/10000, Train Loss: 32.472463781183414, Valid Loss: 38.34427261352539\n","Epoch: 6105/10000, Train Loss: 33.22695732116699, Valid Loss: 38.211446126302086\n","Epoch: 6106/10000, Train Loss: 33.24830627441406, Valid Loss: 38.3166872660319\n","Epoch: 6107/10000, Train Loss: 33.04726791381836, Valid Loss: 38.32336298624674\n","Epoch: 6108/10000, Train Loss: 33.362028642134234, Valid Loss: 38.502875010172524\n","Epoch: 6109/10000, Train Loss: 32.66152433915572, Valid Loss: 38.12951914469401\n","Epoch: 6110/10000, Train Loss: 33.48902355540883, Valid Loss: 38.229498545328774\n","Epoch: 6111/10000, Train Loss: 33.269093773581766, Valid Loss: 38.26963806152344\n","Epoch: 6112/10000, Train Loss: 33.63904224742543, Valid Loss: 38.196067810058594\n","Epoch: 6113/10000, Train Loss: 33.60691521384499, Valid Loss: 38.11630376180013\n","Epoch: 6114/10000, Train Loss: 32.799922076138586, Valid Loss: 38.197837829589844\n","Epoch: 6115/10000, Train Loss: 32.96218976107511, Valid Loss: 38.31472396850586\n","Epoch: 6116/10000, Train Loss: 33.637812180952594, Valid Loss: 38.16826883951823\n","Epoch: 6117/10000, Train Loss: 32.72762784090909, Valid Loss: 38.28561782836914\n","Epoch: 6118/10000, Train Loss: 33.12770947543058, Valid Loss: 38.23909123738607\n","Epoch: 6119/10000, Train Loss: 33.09535876187411, Valid Loss: 38.062371571858726\n","Epoch: 6120/10000, Train Loss: 32.88009036671031, Valid Loss: 38.23802057902018\n","Epoch: 6121/10000, Train Loss: 33.51266670227051, Valid Loss: 38.28752517700195\n","Epoch: 6122/10000, Train Loss: 32.99312695589933, Valid Loss: 38.244772593180336\n","Epoch: 6123/10000, Train Loss: 32.933714086359196, Valid Loss: 38.17003885904948\n","Epoch: 6124/10000, Train Loss: 33.03849861838601, Valid Loss: 38.31278610229492\n","Epoch: 6125/10000, Train Loss: 32.8009898445823, Valid Loss: 38.388771057128906\n","Epoch: 6126/10000, Train Loss: 33.59813117980957, Valid Loss: 38.25123850504557\n","Epoch: 6127/10000, Train Loss: 33.57472402399237, Valid Loss: 38.17205683390299\n","Epoch: 6128/10000, Train Loss: 33.07394374500621, Valid Loss: 38.21307245890299\n","Epoch: 6129/10000, Train Loss: 32.925066687844016, Valid Loss: 38.12437438964844\n","Epoch: 6130/10000, Train Loss: 32.75182446566495, Valid Loss: 38.10366439819336\n","Epoch: 6131/10000, Train Loss: 32.40807411887429, Valid Loss: 38.23626200358073\n","Epoch: 6132/10000, Train Loss: 32.80578595941717, Valid Loss: 38.245829264322914\n","Epoch: 6133/10000, Train Loss: 33.19686022671786, Valid Loss: 38.24010213216146\n","Epoch: 6134/10000, Train Loss: 33.12719639864835, Valid Loss: 38.08147684733073\n","Epoch: 6135/10000, Train Loss: 33.42083168029785, Valid Loss: 38.1482187906901\n","Epoch: 6136/10000, Train Loss: 33.1059438532049, Valid Loss: 38.40546671549479\n","Epoch: 6137/10000, Train Loss: 32.94269561767578, Valid Loss: 38.12329610188802\n","Epoch: 6138/10000, Train Loss: 32.14558913490989, Valid Loss: 38.163160959879555\n","Epoch: 6139/10000, Train Loss: 32.447419079867274, Valid Loss: 38.081156412760414\n","Epoch: 6140/10000, Train Loss: 32.9903541911732, Valid Loss: 38.24470138549805\n","Epoch: 6141/10000, Train Loss: 33.05201096968217, Valid Loss: 38.07902399698893\n","Epoch: 6142/10000, Train Loss: 32.970810803500086, Valid Loss: 38.24653879801432\n","Epoch: 6143/10000, Train Loss: 33.1099251833829, Valid Loss: 38.32508977254232\n","Epoch: 6144/10000, Train Loss: 33.46521481600675, Valid Loss: 38.12997690836588\n","Epoch: 6145/10000, Train Loss: 33.04343761097301, Valid Loss: 38.13339869181315\n","Epoch: 6146/10000, Train Loss: 32.7724890275435, Valid Loss: 38.162208557128906\n","Epoch: 6147/10000, Train Loss: 32.69003642689098, Valid Loss: 38.20141728719076\n","Epoch: 6148/10000, Train Loss: 32.95395556363192, Valid Loss: 38.2683359781901\n","Epoch: 6149/10000, Train Loss: 32.834482886574484, Valid Loss: 38.11219151814779\n","Epoch: 6150/10000, Train Loss: 33.19786262512207, Valid Loss: 38.07844034830729\n","Epoch: 6151/10000, Train Loss: 32.79869790510698, Valid Loss: 38.18722407023112\n","Epoch: 6152/10000, Train Loss: 33.367911252108485, Valid Loss: 38.344896952311196\n","Epoch: 6153/10000, Train Loss: 33.22963107715953, Valid Loss: 38.2264149983724\n","Epoch: 6154/10000, Train Loss: 32.9951945218173, Valid Loss: 38.34022521972656\n","Epoch: 6155/10000, Train Loss: 33.053571527654476, Valid Loss: 38.121621449788414\n","Epoch: 6156/10000, Train Loss: 33.261715455488726, Valid Loss: 38.15771993001302\n","Epoch: 6157/10000, Train Loss: 32.75891876220703, Valid Loss: 38.23488998413086\n","Epoch: 6158/10000, Train Loss: 33.19460782137784, Valid Loss: 38.215203603108726\n","Epoch: 6159/10000, Train Loss: 32.86203575134277, Valid Loss: 38.23793411254883\n","Epoch: 6160/10000, Train Loss: 33.2180026661266, Valid Loss: 38.22370910644531\n","Epoch: 6161/10000, Train Loss: 32.55101498690519, Valid Loss: 38.16657257080078\n","Epoch: 6162/10000, Train Loss: 33.61468159068715, Valid Loss: 38.004679361979164\n","Epoch: 6163/10000, Train Loss: 32.64974021911621, Valid Loss: 38.173380533854164\n","Epoch: 6164/10000, Train Loss: 32.88785362243652, Valid Loss: 38.19474665323893\n","Epoch: 6165/10000, Train Loss: 32.78636082735929, Valid Loss: 38.09026590983073\n","Epoch: 6166/10000, Train Loss: 32.84128952026367, Valid Loss: 38.325581868489586\n","Epoch: 6167/10000, Train Loss: 32.891035079956055, Valid Loss: 38.39970397949219\n","Epoch: 6168/10000, Train Loss: 32.93722343444824, Valid Loss: 38.200687408447266\n","Epoch: 6169/10000, Train Loss: 32.6780983317982, Valid Loss: 38.13356145222982\n","Epoch: 6170/10000, Train Loss: 32.8909161307595, Valid Loss: 38.12652842203776\n","Epoch: 6171/10000, Train Loss: 32.955157193270594, Valid Loss: 38.19316864013672\n","Epoch: 6172/10000, Train Loss: 33.275389584628016, Valid Loss: 38.12502415974935\n","Epoch: 6173/10000, Train Loss: 33.047988024624914, Valid Loss: 37.98658116658529\n","Epoch: 6174/10000, Train Loss: 32.44370599226518, Valid Loss: 37.921087900797524\n","Epoch: 6175/10000, Train Loss: 33.198878201571375, Valid Loss: 38.02379862467448\n","Epoch: 6176/10000, Train Loss: 32.752134496515446, Valid Loss: 38.0599733988444\n","Epoch: 6177/10000, Train Loss: 32.92477919838645, Valid Loss: 38.12955856323242\n","Epoch: 6178/10000, Train Loss: 32.30478269403631, Valid Loss: 38.192718505859375\n","Epoch: 6179/10000, Train Loss: 32.431781248612836, Valid Loss: 38.338236490885414\n","Epoch: 6180/10000, Train Loss: 33.33718820051713, Valid Loss: 38.31483586629232\n","Epoch: 6181/10000, Train Loss: 32.650938207452946, Valid Loss: 38.1430778503418\n","Epoch: 6182/10000, Train Loss: 32.5443281693892, Valid Loss: 38.4791514078776\n","Epoch: 6183/10000, Train Loss: 33.05698585510254, Valid Loss: 38.202388763427734\n","Epoch: 6184/10000, Train Loss: 32.99055428938432, Valid Loss: 38.20505396525065\n","Epoch: 6185/10000, Train Loss: 32.18556594848633, Valid Loss: 38.13438161214193\n","Epoch: 6186/10000, Train Loss: 33.03604507446289, Valid Loss: 38.22338104248047\n","Epoch: 6187/10000, Train Loss: 32.36981391906738, Valid Loss: 38.128316243489586\n","Epoch: 6188/10000, Train Loss: 33.15696837685325, Valid Loss: 38.07435607910156\n","Epoch: 6189/10000, Train Loss: 32.881724791093305, Valid Loss: 38.09336725870768\n","Epoch: 6190/10000, Train Loss: 32.82978664744984, Valid Loss: 38.14507802327474\n","Epoch: 6191/10000, Train Loss: 32.195131128484554, Valid Loss: 38.276344299316406\n","Epoch: 6192/10000, Train Loss: 32.47587966918945, Valid Loss: 38.10963821411133\n","Epoch: 6193/10000, Train Loss: 32.29369406266646, Valid Loss: 37.98960749308268\n","Epoch: 6194/10000, Train Loss: 32.81607489152388, Valid Loss: 38.23447799682617\n","Epoch: 6195/10000, Train Loss: 32.5201192335649, Valid Loss: 38.013458251953125\n","Epoch: 6196/10000, Train Loss: 33.03378053144975, Valid Loss: 37.993682861328125\n","Epoch: 6197/10000, Train Loss: 32.70610358498313, Valid Loss: 38.04739252726237\n","Epoch: 6198/10000, Train Loss: 32.53327612443404, Valid Loss: 38.193904876708984\n","Epoch: 6199/10000, Train Loss: 33.004440481012516, Valid Loss: 38.15457280476888\n","Epoch: 6200/10000, Train Loss: 33.0690000707453, Valid Loss: 38.18265914916992\n","Epoch: 6201/10000, Train Loss: 33.09872488542037, Valid Loss: 38.087158203125\n","Epoch: 6202/10000, Train Loss: 32.62517235495827, Valid Loss: 38.13212203979492\n","Epoch: 6203/10000, Train Loss: 32.75198797746138, Valid Loss: 38.03751881917318\n","Epoch: 6204/10000, Train Loss: 32.40742856805975, Valid Loss: 37.96780141194662\n","Epoch: 6205/10000, Train Loss: 32.32033001292836, Valid Loss: 38.07779312133789\n","Epoch: 6206/10000, Train Loss: 32.99004554748535, Valid Loss: 38.13653437296549\n","Epoch: 6207/10000, Train Loss: 32.33647866682573, Valid Loss: 38.177666982014976\n","Epoch: 6208/10000, Train Loss: 32.57468102195046, Valid Loss: 38.139689127604164\n","Epoch: 6209/10000, Train Loss: 32.39616671475497, Valid Loss: 38.086602528889976\n","Epoch: 6210/10000, Train Loss: 32.79208772832697, Valid Loss: 38.00862248738607\n","Epoch: 6211/10000, Train Loss: 33.08992385864258, Valid Loss: 37.922314961751304\n","Epoch: 6212/10000, Train Loss: 33.06944430958141, Valid Loss: 38.023643493652344\n","Epoch: 6213/10000, Train Loss: 32.84295845031738, Valid Loss: 38.10704549153646\n","Epoch: 6214/10000, Train Loss: 32.41484121842818, Valid Loss: 38.06666056315104\n","Epoch: 6215/10000, Train Loss: 32.71759761463512, Valid Loss: 38.15898005167643\n","Epoch: 6216/10000, Train Loss: 32.386308670043945, Valid Loss: 38.19964472452799\n","Epoch: 6217/10000, Train Loss: 33.31598108465021, Valid Loss: 38.04505284627279\n","Epoch: 6218/10000, Train Loss: 32.71236783807928, Valid Loss: 38.21239344278971\n","Epoch: 6219/10000, Train Loss: 32.92817479913885, Valid Loss: 38.12234369913737\n","Epoch: 6220/10000, Train Loss: 32.7821457602761, Valid Loss: 38.072041829427086\n","Epoch: 6221/10000, Train Loss: 32.52075334028764, Valid Loss: 38.012368520100914\n","Epoch: 6222/10000, Train Loss: 32.82335021279075, Valid Loss: 38.01640319824219\n","Epoch: 6223/10000, Train Loss: 32.29263340343129, Valid Loss: 37.89058176676432\n","Epoch: 6224/10000, Train Loss: 32.60519912026145, Valid Loss: 38.05421829223633\n","Epoch: 6225/10000, Train Loss: 32.51587746360085, Valid Loss: 38.0638058980306\n","Epoch: 6226/10000, Train Loss: 32.856121410023086, Valid Loss: 38.29932657877604\n","Epoch: 6227/10000, Train Loss: 32.94413896040483, Valid Loss: 38.10433451334635\n","Epoch: 6228/10000, Train Loss: 32.8735878684304, Valid Loss: 38.14125061035156\n","Epoch: 6229/10000, Train Loss: 32.35179606350985, Valid Loss: 38.085951487223305\n","Epoch: 6230/10000, Train Loss: 32.88967496698553, Valid Loss: 38.14726765950521\n","Epoch: 6231/10000, Train Loss: 32.84364145452326, Valid Loss: 38.098008473714195\n","Epoch: 6232/10000, Train Loss: 32.51089442859996, Valid Loss: 38.12593332926432\n","Epoch: 6233/10000, Train Loss: 32.59121045199308, Valid Loss: 38.29021962483724\n","Epoch: 6234/10000, Train Loss: 32.61143909801137, Valid Loss: 38.29113515218099\n","Epoch: 6235/10000, Train Loss: 33.2930346402255, Valid Loss: 38.16593551635742\n","Epoch: 6236/10000, Train Loss: 32.8580190485174, Valid Loss: 38.033807118733726\n","Epoch: 6237/10000, Train Loss: 32.44426675276323, Valid Loss: 38.04784393310547\n","Epoch: 6238/10000, Train Loss: 32.641057101163, Valid Loss: 37.86499786376953\n","Epoch: 6239/10000, Train Loss: 32.66805631464178, Valid Loss: 37.96511586507162\n","Epoch: 6240/10000, Train Loss: 33.33922576904297, Valid Loss: 38.12738164265951\n","Epoch: 6241/10000, Train Loss: 32.352987636219375, Valid Loss: 38.14037068684896\n","Epoch: 6242/10000, Train Loss: 32.791128852150656, Valid Loss: 38.0000368754069\n","Epoch: 6243/10000, Train Loss: 32.82185918634588, Valid Loss: 38.110182444254555\n","Epoch: 6244/10000, Train Loss: 32.550314296375625, Valid Loss: 38.07567596435547\n","Epoch: 6245/10000, Train Loss: 33.02149148420854, Valid Loss: 37.922925313313804\n","Epoch: 6246/10000, Train Loss: 32.75057948719371, Valid Loss: 38.10220845540365\n","Epoch: 6247/10000, Train Loss: 32.54073090986772, Valid Loss: 38.140865325927734\n","Epoch: 6248/10000, Train Loss: 32.670649615201086, Valid Loss: 38.038796742757164\n","Epoch: 6249/10000, Train Loss: 32.55807130986994, Valid Loss: 37.953741709391274\n","Epoch: 6250/10000, Train Loss: 33.23492414301092, Valid Loss: 37.98871103922526\n","Epoch: 6251/10000, Train Loss: 32.79124624078924, Valid Loss: 38.040819803873696\n","Epoch: 6252/10000, Train Loss: 32.30160245028409, Valid Loss: 38.173519134521484\n","Epoch: 6253/10000, Train Loss: 32.63465326482599, Valid Loss: 37.87267557779948\n","Epoch: 6254/10000, Train Loss: 33.11401922052557, Valid Loss: 38.03064982096354\n","Epoch: 6255/10000, Train Loss: 33.203927820379086, Valid Loss: 38.11394755045573\n","Epoch: 6256/10000, Train Loss: 32.81003639914773, Valid Loss: 38.13943608601888\n","Epoch: 6257/10000, Train Loss: 31.96300575949929, Valid Loss: 38.11358388264974\n","Epoch: 6258/10000, Train Loss: 32.36733696677468, Valid Loss: 38.0544548034668\n","Epoch: 6259/10000, Train Loss: 32.603925704956055, Valid Loss: 38.08331298828125\n","Epoch: 6260/10000, Train Loss: 32.38976790688255, Valid Loss: 38.032772064208984\n","Epoch: 6261/10000, Train Loss: 32.764902114868164, Valid Loss: 37.92382558186849\n","Epoch: 6262/10000, Train Loss: 32.59892255609686, Valid Loss: 37.98755645751953\n","Epoch: 6263/10000, Train Loss: 32.196276057850234, Valid Loss: 37.868247985839844\n","Epoch: 6264/10000, Train Loss: 32.66051136363637, Valid Loss: 37.91302617390951\n","Epoch: 6265/10000, Train Loss: 33.357378179376774, Valid Loss: 38.03190994262695\n","Epoch: 6266/10000, Train Loss: 32.03027898615057, Valid Loss: 38.06040700276693\n","Epoch: 6267/10000, Train Loss: 33.13494110107422, Valid Loss: 38.144657135009766\n","Epoch: 6268/10000, Train Loss: 33.00024500760165, Valid Loss: 38.06115849812826\n","Epoch: 6269/10000, Train Loss: 32.505083951083094, Valid Loss: 38.00280253092448\n","Epoch: 6270/10000, Train Loss: 32.29839810458097, Valid Loss: 38.00710805257162\n","Epoch: 6271/10000, Train Loss: 32.791067123413086, Valid Loss: 38.05354309082031\n","Epoch: 6272/10000, Train Loss: 32.737262899225406, Valid Loss: 38.03604380289713\n","Epoch: 6273/10000, Train Loss: 32.396590839732774, Valid Loss: 38.07577133178711\n","Epoch: 6274/10000, Train Loss: 32.49710377779874, Valid Loss: 38.032110850016274\n","Epoch: 6275/10000, Train Loss: 32.58224834095348, Valid Loss: 37.97001520792643\n","Epoch: 6276/10000, Train Loss: 32.818133787675336, Valid Loss: 37.88663228352865\n","Epoch: 6277/10000, Train Loss: 33.30827522277832, Valid Loss: 38.08740997314453\n","Epoch: 6278/10000, Train Loss: 32.189146215265446, Valid Loss: 38.05494181315104\n","Epoch: 6279/10000, Train Loss: 32.825950449163265, Valid Loss: 37.990395863850914\n","Epoch: 6280/10000, Train Loss: 32.53854266079989, Valid Loss: 37.90435791015625\n","Epoch: 6281/10000, Train Loss: 32.285069552334875, Valid Loss: 37.92253494262695\n","Epoch: 6282/10000, Train Loss: 33.12141349098899, Valid Loss: 37.89658864339193\n","Epoch: 6283/10000, Train Loss: 32.24671693281694, Valid Loss: 37.93066151936849\n","Epoch: 6284/10000, Train Loss: 32.912243062799625, Valid Loss: 38.04145812988281\n","Epoch: 6285/10000, Train Loss: 33.20607376098633, Valid Loss: 37.8312021891276\n","Epoch: 6286/10000, Train Loss: 32.82029151916504, Valid Loss: 37.8037109375\n","Epoch: 6287/10000, Train Loss: 32.95880889892578, Valid Loss: 37.7159169514974\n","Epoch: 6288/10000, Train Loss: 32.247018640691586, Valid Loss: 37.89733378092448\n","Epoch: 6289/10000, Train Loss: 32.65765970403498, Valid Loss: 37.864420572916664\n","Epoch: 6290/10000, Train Loss: 32.118859724564985, Valid Loss: 37.834129333496094\n","Epoch: 6291/10000, Train Loss: 32.495656967163086, Valid Loss: 37.92130661010742\n","Epoch: 6292/10000, Train Loss: 32.87460899353027, Valid Loss: 37.939614613850914\n","Epoch: 6293/10000, Train Loss: 32.15108906139027, Valid Loss: 38.08440272013346\n","Epoch: 6294/10000, Train Loss: 31.967812624844637, Valid Loss: 38.14577865600586\n","Epoch: 6295/10000, Train Loss: 32.268523476340555, Valid Loss: 38.06813939412435\n","Epoch: 6296/10000, Train Loss: 32.42455777254972, Valid Loss: 38.04804484049479\n","Epoch: 6297/10000, Train Loss: 33.02088460055265, Valid Loss: 37.944952646891274\n","Epoch: 6298/10000, Train Loss: 32.911657159978695, Valid Loss: 37.97995630900065\n","Epoch: 6299/10000, Train Loss: 32.2240930037065, Valid Loss: 38.045204162597656\n","Epoch: 6300/10000, Train Loss: 32.82379878651012, Valid Loss: 38.08661397298177\n","Epoch: 6301/10000, Train Loss: 32.69282150268555, Valid Loss: 38.019954681396484\n","Epoch: 6302/10000, Train Loss: 32.18244795365767, Valid Loss: 38.12132263183594\n","Epoch: 6303/10000, Train Loss: 32.45551300048828, Valid Loss: 37.94917424519857\n","Epoch: 6304/10000, Train Loss: 31.946921608664773, Valid Loss: 37.920684814453125\n","Epoch: 6305/10000, Train Loss: 32.644698576493695, Valid Loss: 37.99505742390951\n","Epoch: 6306/10000, Train Loss: 32.85068633339622, Valid Loss: 37.885440826416016\n","Epoch: 6307/10000, Train Loss: 32.517905321988195, Valid Loss: 37.833090464274086\n","Epoch: 6308/10000, Train Loss: 32.895151831886984, Valid Loss: 37.84726079305013\n","Epoch: 6309/10000, Train Loss: 32.38508831370961, Valid Loss: 38.001242319742836\n","Epoch: 6310/10000, Train Loss: 32.48223738236861, Valid Loss: 38.025098164876304\n","Epoch: 6311/10000, Train Loss: 32.29336998679421, Valid Loss: 38.03645706176758\n","Epoch: 6312/10000, Train Loss: 32.621557755903765, Valid Loss: 37.999847412109375\n","Epoch: 6313/10000, Train Loss: 32.460274956443094, Valid Loss: 37.87051900227865\n","Epoch: 6314/10000, Train Loss: 32.99503361095082, Valid Loss: 37.944600423177086\n","Epoch: 6315/10000, Train Loss: 32.834016973322086, Valid Loss: 37.876478830973305\n","Epoch: 6316/10000, Train Loss: 32.34965688532049, Valid Loss: 38.019935607910156\n","Epoch: 6317/10000, Train Loss: 32.720066417347304, Valid Loss: 38.00233586629232\n","Epoch: 6318/10000, Train Loss: 31.802338340065695, Valid Loss: 38.00845464070638\n","Epoch: 6319/10000, Train Loss: 32.47695940191095, Valid Loss: 37.94569396972656\n","Epoch: 6320/10000, Train Loss: 32.01767487959428, Valid Loss: 37.798641204833984\n","Epoch: 6321/10000, Train Loss: 32.57832180369984, Valid Loss: 37.85153452555338\n","Epoch: 6322/10000, Train Loss: 32.00806721774015, Valid Loss: 37.723724365234375\n","Epoch: 6323/10000, Train Loss: 32.407374988902696, Valid Loss: 37.82000986735026\n","Epoch: 6324/10000, Train Loss: 32.466477307406336, Valid Loss: 37.905104319254555\n","Epoch: 6325/10000, Train Loss: 32.51717758178711, Valid Loss: 37.842184702555336\n","Epoch: 6326/10000, Train Loss: 32.2256329276345, Valid Loss: 38.14780807495117\n","Epoch: 6327/10000, Train Loss: 32.68272746693004, Valid Loss: 38.00291188557943\n","Epoch: 6328/10000, Train Loss: 32.103594519875266, Valid Loss: 37.77949778238932\n","Epoch: 6329/10000, Train Loss: 32.357803171331234, Valid Loss: 37.83747863769531\n","Epoch: 6330/10000, Train Loss: 32.082360527732156, Valid Loss: 37.849161783854164\n","Epoch: 6331/10000, Train Loss: 32.90302484685724, Valid Loss: 37.80128479003906\n","Epoch: 6332/10000, Train Loss: 32.525915666060015, Valid Loss: 37.82854207356771\n","Epoch: 6333/10000, Train Loss: 32.48087987032804, Valid Loss: 37.83942794799805\n","Epoch: 6334/10000, Train Loss: 32.71994764154608, Valid Loss: 37.83590571085612\n","Epoch: 6335/10000, Train Loss: 32.269993175159804, Valid Loss: 37.626380920410156\n","Epoch: 6336/10000, Train Loss: 32.576433355158024, Valid Loss: 37.703905741373696\n","Epoch: 6337/10000, Train Loss: 32.50562026283958, Valid Loss: 37.79636255900065\n","Epoch: 6338/10000, Train Loss: 32.81583473899148, Valid Loss: 37.82702128092448\n","Epoch: 6339/10000, Train Loss: 32.28255861455744, Valid Loss: 37.66599782307943\n","Epoch: 6340/10000, Train Loss: 31.823284322565254, Valid Loss: 37.827500661214195\n","Epoch: 6341/10000, Train Loss: 32.47859660061923, Valid Loss: 37.82961908976237\n","Epoch: 6342/10000, Train Loss: 32.85551036487926, Valid Loss: 37.87970733642578\n","Epoch: 6343/10000, Train Loss: 32.76896771517667, Valid Loss: 37.833474477132164\n","Epoch: 6344/10000, Train Loss: 32.29378995028409, Valid Loss: 37.872336069742836\n","Epoch: 6345/10000, Train Loss: 32.503780364990234, Valid Loss: 37.92217508951823\n","Epoch: 6346/10000, Train Loss: 32.12132731350985, Valid Loss: 37.90330251057943\n","Epoch: 6347/10000, Train Loss: 32.2944427837025, Valid Loss: 37.917823791503906\n","Epoch: 6348/10000, Train Loss: 32.508256218650125, Valid Loss: 37.897257486979164\n","Epoch: 6349/10000, Train Loss: 32.607486204667524, Valid Loss: 37.86291376749674\n","Epoch: 6350/10000, Train Loss: 32.0397742878307, Valid Loss: 37.91242472330729\n","Epoch: 6351/10000, Train Loss: 32.3304294239391, Valid Loss: 37.819637298583984\n","Epoch: 6352/10000, Train Loss: 32.927621147849344, Valid Loss: 37.75940068562826\n","Epoch: 6353/10000, Train Loss: 32.50810311057351, Valid Loss: 37.814109802246094\n","Epoch: 6354/10000, Train Loss: 32.41315980391069, Valid Loss: 37.93927256266276\n","Epoch: 6355/10000, Train Loss: 32.78280604969371, Valid Loss: 38.08854548136393\n","Epoch: 6356/10000, Train Loss: 31.56429030678489, Valid Loss: 37.907423655192055\n","Epoch: 6357/10000, Train Loss: 32.36131737448952, Valid Loss: 38.002325693766274\n","Epoch: 6358/10000, Train Loss: 32.35167538036, Valid Loss: 37.950852711995445\n","Epoch: 6359/10000, Train Loss: 32.49150622974742, Valid Loss: 37.97330983479818\n","Epoch: 6360/10000, Train Loss: 32.198761679909445, Valid Loss: 37.97705332438151\n","Epoch: 6361/10000, Train Loss: 31.770082126964223, Valid Loss: 37.911242167154946\n","Epoch: 6362/10000, Train Loss: 32.087682550603695, Valid Loss: 38.07152811686198\n","Epoch: 6363/10000, Train Loss: 32.18948953801935, Valid Loss: 37.86612065633138\n","Epoch: 6364/10000, Train Loss: 32.58559660478072, Valid Loss: 37.724853515625\n","Epoch: 6365/10000, Train Loss: 32.933579358187586, Valid Loss: 37.85322189331055\n","Epoch: 6366/10000, Train Loss: 31.926761800592597, Valid Loss: 37.831189473470054\n","Epoch: 6367/10000, Train Loss: 32.47568321228027, Valid Loss: 37.90303421020508\n","Epoch: 6368/10000, Train Loss: 32.09467818520286, Valid Loss: 38.0540402730306\n","Epoch: 6369/10000, Train Loss: 32.606681476939805, Valid Loss: 37.75413258870443\n","Epoch: 6370/10000, Train Loss: 32.44351716475053, Valid Loss: 37.79034169514974\n","Epoch: 6371/10000, Train Loss: 32.72517221624201, Valid Loss: 37.511557261149086\n","Epoch: 6372/10000, Train Loss: 32.592371853915125, Valid Loss: 37.63042449951172\n","Epoch: 6373/10000, Train Loss: 32.78612639687278, Valid Loss: 37.64465840657552\n","Epoch: 6374/10000, Train Loss: 32.12504976445978, Valid Loss: 37.73534266153971\n","Epoch: 6375/10000, Train Loss: 32.18863972750577, Valid Loss: 37.867539723714195\n","Epoch: 6376/10000, Train Loss: 32.639927950772375, Valid Loss: 37.90027745564779\n","Epoch: 6377/10000, Train Loss: 32.732931483875625, Valid Loss: 37.90649668375651\n","Epoch: 6378/10000, Train Loss: 32.27422887628729, Valid Loss: 37.84119160970052\n","Epoch: 6379/10000, Train Loss: 32.73536127263849, Valid Loss: 37.89633305867513\n","Epoch: 6380/10000, Train Loss: 32.83736437017267, Valid Loss: 37.7564951578776\n","Epoch: 6381/10000, Train Loss: 32.97401497580788, Valid Loss: 37.7569834391276\n","Epoch: 6382/10000, Train Loss: 31.901492378928445, Valid Loss: 37.789005279541016\n","Epoch: 6383/10000, Train Loss: 32.331077402288265, Valid Loss: 38.009237925211586\n","Epoch: 6384/10000, Train Loss: 32.363354596224696, Valid Loss: 37.865376790364586\n","Epoch: 6385/10000, Train Loss: 32.19647823680531, Valid Loss: 37.90562184651693\n","Epoch: 6386/10000, Train Loss: 32.73209710554643, Valid Loss: 38.036607106526695\n","Epoch: 6387/10000, Train Loss: 32.614025289362125, Valid Loss: 37.857245127360024\n","Epoch: 6388/10000, Train Loss: 32.42239015752619, Valid Loss: 37.91391118367513\n","Epoch: 6389/10000, Train Loss: 32.89404036782005, Valid Loss: 37.93039576212565\n","Epoch: 6390/10000, Train Loss: 32.57559741627086, Valid Loss: 37.901990254720054\n","Epoch: 6391/10000, Train Loss: 32.91219225796786, Valid Loss: 37.91979853312174\n","Epoch: 6392/10000, Train Loss: 32.650250001387164, Valid Loss: 38.016466776529946\n","Epoch: 6393/10000, Train Loss: 31.810938228260387, Valid Loss: 37.89275868733724\n","Epoch: 6394/10000, Train Loss: 32.078039862892844, Valid Loss: 37.84063593546549\n","Epoch: 6395/10000, Train Loss: 32.77424170754173, Valid Loss: 37.914475758870445\n","Epoch: 6396/10000, Train Loss: 32.07083962180398, Valid Loss: 37.89466349283854\n","Epoch: 6397/10000, Train Loss: 32.50817749717019, Valid Loss: 37.63221867879232\n","Epoch: 6398/10000, Train Loss: 32.70002261075106, Valid Loss: 37.91941833496094\n","Epoch: 6399/10000, Train Loss: 32.54993802850897, Valid Loss: 37.86684799194336\n","Epoch: 6400/10000, Train Loss: 31.83700942993164, Valid Loss: 37.87652715047201\n","Epoch: 6401/10000, Train Loss: 32.65289029208097, Valid Loss: 37.769100189208984\n","Epoch: 6402/10000, Train Loss: 32.06859640641646, Valid Loss: 37.729573567708336\n","Epoch: 6403/10000, Train Loss: 32.013479406183414, Valid Loss: 37.74510192871094\n","Epoch: 6404/10000, Train Loss: 32.20560715415261, Valid Loss: 37.90112050374349\n","Epoch: 6405/10000, Train Loss: 33.12199609929865, Valid Loss: 37.99692153930664\n","Epoch: 6406/10000, Train Loss: 31.968557010997426, Valid Loss: 37.82218551635742\n","Epoch: 6407/10000, Train Loss: 32.45170853354714, Valid Loss: 37.734503428141274\n","Epoch: 6408/10000, Train Loss: 32.01218448985707, Valid Loss: 37.7208506266276\n","Epoch: 6409/10000, Train Loss: 32.00888495011763, Valid Loss: 37.75501505533854\n","Epoch: 6410/10000, Train Loss: 32.050335450605914, Valid Loss: 37.75373077392578\n","Epoch: 6411/10000, Train Loss: 32.67284722761674, Valid Loss: 37.855210622151695\n","Epoch: 6412/10000, Train Loss: 32.299647938121446, Valid Loss: 37.63549931844076\n","Epoch: 6413/10000, Train Loss: 32.89288936961781, Valid Loss: 37.86663055419922\n","Epoch: 6414/10000, Train Loss: 32.031690250743516, Valid Loss: 37.888468424479164\n","Epoch: 6415/10000, Train Loss: 31.926937103271484, Valid Loss: 37.81908289591471\n","Epoch: 6416/10000, Train Loss: 32.89556295221502, Valid Loss: 37.928304036458336\n","Epoch: 6417/10000, Train Loss: 32.14554405212402, Valid Loss: 37.74843088785807\n","Epoch: 6418/10000, Train Loss: 32.7224367315119, Valid Loss: 37.89501953125\n","Epoch: 6419/10000, Train Loss: 31.795041864568535, Valid Loss: 37.874891916910805\n","Epoch: 6420/10000, Train Loss: 32.254775827581234, Valid Loss: 37.78260167439779\n","Epoch: 6421/10000, Train Loss: 31.963547793301668, Valid Loss: 37.6726188659668\n","Epoch: 6422/10000, Train Loss: 32.327525572343305, Valid Loss: 37.769204457600914\n","Epoch: 6423/10000, Train Loss: 32.31651618263938, Valid Loss: 37.913936614990234\n","Epoch: 6424/10000, Train Loss: 31.890641645951703, Valid Loss: 37.843823750813804\n","Epoch: 6425/10000, Train Loss: 32.04940050298517, Valid Loss: 37.882363637288414\n","Epoch: 6426/10000, Train Loss: 32.73007028753107, Valid Loss: 37.88030115763346\n","Epoch: 6427/10000, Train Loss: 32.75325254960494, Valid Loss: 37.65049362182617\n","Epoch: 6428/10000, Train Loss: 32.345612959428266, Valid Loss: 37.56205622355143\n","Epoch: 6429/10000, Train Loss: 31.826753442937676, Valid Loss: 37.66183217366537\n","Epoch: 6430/10000, Train Loss: 32.4778336611661, Valid Loss: 37.90542475382487\n","Epoch: 6431/10000, Train Loss: 32.43101622841575, Valid Loss: 37.793471018473305\n","Epoch: 6432/10000, Train Loss: 32.688240398060195, Valid Loss: 37.63243103027344\n","Epoch: 6433/10000, Train Loss: 32.45488392223012, Valid Loss: 37.72016270955404\n","Epoch: 6434/10000, Train Loss: 31.961890480735086, Valid Loss: 37.676780700683594\n","Epoch: 6435/10000, Train Loss: 32.557700243863195, Valid Loss: 37.85835647583008\n","Epoch: 6436/10000, Train Loss: 32.52619032426314, Valid Loss: 37.903106689453125\n","Epoch: 6437/10000, Train Loss: 32.392446691339664, Valid Loss: 37.715003967285156\n","Epoch: 6438/10000, Train Loss: 33.161677620627664, Valid Loss: 37.813035329182945\n","Epoch: 6439/10000, Train Loss: 32.900853937322445, Valid Loss: 37.704345703125\n","Epoch: 6440/10000, Train Loss: 31.933047034523703, Valid Loss: 37.67756017049154\n","Epoch: 6441/10000, Train Loss: 31.987369537353516, Valid Loss: 37.80789057413737\n","Epoch: 6442/10000, Train Loss: 32.30368076671254, Valid Loss: 37.83832550048828\n","Epoch: 6443/10000, Train Loss: 32.876374157992274, Valid Loss: 37.990787506103516\n","Epoch: 6444/10000, Train Loss: 32.21875728260387, Valid Loss: 37.84158452351888\n","Epoch: 6445/10000, Train Loss: 32.24635054848411, Valid Loss: 37.65189743041992\n","Epoch: 6446/10000, Train Loss: 31.938900167291816, Valid Loss: 37.736090342203774\n","Epoch: 6447/10000, Train Loss: 32.310508728027344, Valid Loss: 37.82330830891927\n","Epoch: 6448/10000, Train Loss: 32.04379532553933, Valid Loss: 37.8692626953125\n","Epoch: 6449/10000, Train Loss: 32.65483890880238, Valid Loss: 37.783888498942055\n","Epoch: 6450/10000, Train Loss: 31.7629938992587, Valid Loss: 37.67357635498047\n","Epoch: 6451/10000, Train Loss: 31.666351144964043, Valid Loss: 37.776632944742836\n","Epoch: 6452/10000, Train Loss: 32.099084160544656, Valid Loss: 37.672812143961586\n","Epoch: 6453/10000, Train Loss: 32.52681922912598, Valid Loss: 37.66024398803711\n","Epoch: 6454/10000, Train Loss: 32.0547700361772, Valid Loss: 37.77514902750651\n","Epoch: 6455/10000, Train Loss: 31.718327955766156, Valid Loss: 37.86959457397461\n","Epoch: 6456/10000, Train Loss: 31.848622408780184, Valid Loss: 37.82263946533203\n","Epoch: 6457/10000, Train Loss: 32.73147877779874, Valid Loss: 37.78977966308594\n","Epoch: 6458/10000, Train Loss: 32.578534906560726, Valid Loss: 37.815853118896484\n","Epoch: 6459/10000, Train Loss: 32.16235646334562, Valid Loss: 37.883628845214844\n","Epoch: 6460/10000, Train Loss: 32.682735269719906, Valid Loss: 37.73413594563802\n","Epoch: 6461/10000, Train Loss: 32.256775942715734, Valid Loss: 37.73422622680664\n","Epoch: 6462/10000, Train Loss: 32.242116234519266, Valid Loss: 37.65358352661133\n","Epoch: 6463/10000, Train Loss: 32.16223578019576, Valid Loss: 37.584765116373696\n","Epoch: 6464/10000, Train Loss: 32.50249949368563, Valid Loss: 37.776650746663414\n","Epoch: 6465/10000, Train Loss: 32.49977562644265, Valid Loss: 37.69106928507487\n","Epoch: 6466/10000, Train Loss: 32.9030796397816, Valid Loss: 37.690537770589195\n","Epoch: 6467/10000, Train Loss: 32.092514905062586, Valid Loss: 37.600104014078774\n","Epoch: 6468/10000, Train Loss: 32.78049729087136, Valid Loss: 37.65143966674805\n","Epoch: 6469/10000, Train Loss: 32.62323899702592, Valid Loss: 37.72454706827799\n","Epoch: 6470/10000, Train Loss: 31.828736565329812, Valid Loss: 37.71611404418945\n","Epoch: 6471/10000, Train Loss: 31.903113625266336, Valid Loss: 37.625606536865234\n","얼리 스토핑: 100 에포크 동안 검증 손실이 향상되지 않음. 에포크 6471에서 훈련 중단.\n"]}],"source":["print(\"Training Start: MLM\")\n","model_MLM = train(train_MLM_loader, valid_MLM_loader, model_MLM, criterion, optimizer_MLM, epochs=CFG['EPOCHS'])\n","\n","print(\"Training Start: HLM\")\n","model_HLM = train(train_HLM_loader, valid_HLM_loader, model_HLM, criterion, optimizer_HLM, epochs=CFG['EPOCHS'])"]},{"cell_type":"code","execution_count":null,"id":"0fa8976d","metadata":{"id":"0fa8976d"},"outputs":[],"source":["torch.save(model_MLM.state_dict(), '/content/drive/MyDrive/Colab Notebooks/AIDrug_Competition/models/OnlyMorganFingerprint_DNN_Model_MLM_1.pth')  # 모델 객체의 state_dict 저장\n","torch.save(model_HLM.state_dict(), '/content/drive/MyDrive/Colab Notebooks/AIDrug_Competition/models/OnlyMorganFingerprint_DNN_Model_HLM_1.pth')"]},{"cell_type":"code","execution_count":null,"id":"1e894642","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692892512666,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"1e894642","outputId":"8fd51d35-a147-4922-c6c5-5b1f4cc8d5d9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":133}],"source":["model_MLM.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/AIDrug_Competition/models/OnlyMorganFingerprint_DNN_Model_MLM_1.pth'))\n","model_HLM.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/AIDrug_Competition/models/OnlyMorganFingerprint_DNN_Model_HLM_1.pth'))"]},{"cell_type":"code","execution_count":null,"id":"AiGfdAGsemIp","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1692892527744,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"AiGfdAGsemIp","outputId":"51050ca0-872c-4055-d09f-987db226de11"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           id                                             SMILES  AlogP  \\\n","0    TEST_000            CC(C)Nc1ccnc(N2CCN(Cc3cccs3)C(CCO)C2)n1  2.641   \n","1    TEST_001     COc1cc(=O)n(-c2ccccc2)cc1C(=O)N1CCC2(CC1)OCCO2  0.585   \n","2    TEST_002  Cc1cccc(NC(=N)/N=c2\\nc(O)c(Cc3ccccc3)c(C)[nH]2)c1  4.276   \n","3    TEST_003         O=C(c1nc2ncccn2n1)N1CCCn2cc(-c3ccccc3)nc21  1.795   \n","4    TEST_004       CCN1CCN(C(=O)c2cc3c(=O)n4cc(C)ccc4nc3n2C)CC1  1.219   \n","..        ...                                                ...    ...   \n","478  TEST_478                  CCc1noc(CC)c1CC(=O)NCC1(CC)CCCCC1  4.207   \n","479  TEST_479     CC(=O)N1CCC2(CC1)OC(=O)C(C)=C2C(=O)N1CCN(C)CC1 -0.608   \n","480  TEST_480      CC(C)NC(=O)CN1C(=O)c2ccccc2N2C(=O)c3ccccc3C12  1.792   \n","481  TEST_481              Cn1cc(Br)c(=O)c(NC(=O)c2ccc(O)cc2F)c1  0.790   \n","482  TEST_482                       CC(C)C(CCN1CCN(C)CC1)c1ccco1  2.782   \n","\n","     Molecular_Weight  Num_H_Acceptors  Num_H_Donors  Num_RotatableBonds  \\\n","0             361.505                4             2                   7   \n","1             370.399                5             0                   3   \n","2             347.414                4             4                   5   \n","3             345.358                5             0                   2   \n","4             353.418                4             0                   2   \n","..                ...              ...           ...                 ...   \n","478           306.443                2             1                   7   \n","479           335.398                5             0                   1   \n","480           349.383                3             1                   3   \n","481           341.132                3             2                   2   \n","482           250.380                2             0                   5   \n","\n","      LogD  Molecular_PolarSurfaceArea     logP  num_rotatable_bonds  \\\n","0    2.635                       92.76  2.43160                    7   \n","1    0.585                       68.31  1.82520                    3   \n","2    4.290                       92.86  3.27051                    3   \n","3    1.795                       81.21  2.03830                    2   \n","4    0.169                       61.15  1.27232                    2   \n","..     ...                         ...      ...                  ...   \n","478  4.207                       55.13  3.81860                    7   \n","479 -1.736                       70.16  0.01480                    1   \n","480  1.792                       69.72  2.32600                    3   \n","481  0.423                       69.64  2.24480                    2   \n","482  0.606                       19.62  2.65670                    5   \n","\n","     num_heteroatoms  num_hydrogen_acceptors  num_hydrogen_donors  \\\n","0                  7                       7                    2   \n","1                  7                       6                    0   \n","2                  6                       3                    4   \n","3                  8                       7                    0   \n","4                  7                       6                    0   \n","..               ...                     ...                  ...   \n","478                4                       3                    1   \n","479                7                       5                    0   \n","480                6                       3                    1   \n","481                7                       4                    2   \n","482                3                       3                    0   \n","\n","                                    morgan_fingerprint  aromatic_rings   tpsa  \n","0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               3  64.52  \n","1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               4  70.00  \n","2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               3  97.15  \n","3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               5  81.21  \n","4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               4  62.85  \n","..                                                 ...             ...    ...  \n","478  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               2  55.13  \n","479  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...               3  70.16  \n","480  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...               4  69.72  \n","481  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               2  71.33  \n","482  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...               2  19.62  \n","\n","[483 rows x 17 columns]"],"text/html":["\n","  <div id=\"df-36aad866-f144-4708-ac84-bd5f08e45373\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>SMILES</th>\n","      <th>AlogP</th>\n","      <th>Molecular_Weight</th>\n","      <th>Num_H_Acceptors</th>\n","      <th>Num_H_Donors</th>\n","      <th>Num_RotatableBonds</th>\n","      <th>LogD</th>\n","      <th>Molecular_PolarSurfaceArea</th>\n","      <th>logP</th>\n","      <th>num_rotatable_bonds</th>\n","      <th>num_heteroatoms</th>\n","      <th>num_hydrogen_acceptors</th>\n","      <th>num_hydrogen_donors</th>\n","      <th>morgan_fingerprint</th>\n","      <th>aromatic_rings</th>\n","      <th>tpsa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_000</td>\n","      <td>CC(C)Nc1ccnc(N2CCN(Cc3cccs3)C(CCO)C2)n1</td>\n","      <td>2.641</td>\n","      <td>361.505</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>2.635</td>\n","      <td>92.76</td>\n","      <td>2.43160</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>3</td>\n","      <td>64.52</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_001</td>\n","      <td>COc1cc(=O)n(-c2ccccc2)cc1C(=O)N1CCC2(CC1)OCCO2</td>\n","      <td>0.585</td>\n","      <td>370.399</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0.585</td>\n","      <td>68.31</td>\n","      <td>1.82520</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>4</td>\n","      <td>70.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_002</td>\n","      <td>Cc1cccc(NC(=N)/N=c2\\nc(O)c(Cc3ccccc3)c(C)[nH]2)c1</td>\n","      <td>4.276</td>\n","      <td>347.414</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>4.290</td>\n","      <td>92.86</td>\n","      <td>3.27051</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>3</td>\n","      <td>97.15</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_003</td>\n","      <td>O=C(c1nc2ncccn2n1)N1CCCn2cc(-c3ccccc3)nc21</td>\n","      <td>1.795</td>\n","      <td>345.358</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1.795</td>\n","      <td>81.21</td>\n","      <td>2.03830</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>5</td>\n","      <td>81.21</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_004</td>\n","      <td>CCN1CCN(C(=O)c2cc3c(=O)n4cc(C)ccc4nc3n2C)CC1</td>\n","      <td>1.219</td>\n","      <td>353.418</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.169</td>\n","      <td>61.15</td>\n","      <td>1.27232</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>4</td>\n","      <td>62.85</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>478</th>\n","      <td>TEST_478</td>\n","      <td>CCc1noc(CC)c1CC(=O)NCC1(CC)CCCCC1</td>\n","      <td>4.207</td>\n","      <td>306.443</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>4.207</td>\n","      <td>55.13</td>\n","      <td>3.81860</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>2</td>\n","      <td>55.13</td>\n","    </tr>\n","    <tr>\n","      <th>479</th>\n","      <td>TEST_479</td>\n","      <td>CC(=O)N1CCC2(CC1)OC(=O)C(C)=C2C(=O)N1CCN(C)CC1</td>\n","      <td>-0.608</td>\n","      <td>335.398</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1.736</td>\n","      <td>70.16</td>\n","      <td>0.01480</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...</td>\n","      <td>3</td>\n","      <td>70.16</td>\n","    </tr>\n","    <tr>\n","      <th>480</th>\n","      <td>TEST_480</td>\n","      <td>CC(C)NC(=O)CN1C(=O)c2ccccc2N2C(=O)c3ccccc3C12</td>\n","      <td>1.792</td>\n","      <td>349.383</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1.792</td>\n","      <td>69.72</td>\n","      <td>2.32600</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>4</td>\n","      <td>69.72</td>\n","    </tr>\n","    <tr>\n","      <th>481</th>\n","      <td>TEST_481</td>\n","      <td>Cn1cc(Br)c(=O)c(NC(=O)c2ccc(O)cc2F)c1</td>\n","      <td>0.790</td>\n","      <td>341.132</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0.423</td>\n","      <td>69.64</td>\n","      <td>2.24480</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>2</td>\n","      <td>71.33</td>\n","    </tr>\n","    <tr>\n","      <th>482</th>\n","      <td>TEST_482</td>\n","      <td>CC(C)C(CCN1CCN(C)CC1)c1ccco1</td>\n","      <td>2.782</td>\n","      <td>250.380</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0.606</td>\n","      <td>19.62</td>\n","      <td>2.65670</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...</td>\n","      <td>2</td>\n","      <td>19.62</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>483 rows × 17 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36aad866-f144-4708-ac84-bd5f08e45373')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-36aad866-f144-4708-ac84-bd5f08e45373 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-36aad866-f144-4708-ac84-bd5f08e45373');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-35c05a76-1bdc-4da3-88b6-c405d536aa2b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35c05a76-1bdc-4da3-88b6-c405d536aa2b')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-35c05a76-1bdc-4da3-88b6-c405d536aa2b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":134}],"source":["test"]},{"cell_type":"code","execution_count":null,"id":"f8054263","metadata":{"id":"f8054263"},"outputs":[],"source":["test_MLM = CustomDataset(test, target_col=None, transform=transform, is_test=True)\n","test_HLM = CustomDataset(test, target_col=None, transform=transform, is_test=True)\n","\n","test_MLM_loader = DataLoader(dataset=test_MLM,\n","                             batch_size=CFG['BATCH_SIZE'],\n","                             shuffle=False)\n","\n","test_HLM_loader = DataLoader(dataset=test_HLM,\n","                             batch_size=CFG['BATCH_SIZE'],\n","                             shuffle=False)"]},{"cell_type":"code","execution_count":null,"id":"5c7701c7","metadata":{"id":"5c7701c7"},"outputs":[],"source":["def inference(test_loader, model):\n","    model.eval()\n","    preds = []\n","\n","    with torch.no_grad():\n","        for inputs in test_loader:\n","            output = model(inputs)\n","            preds.extend(output.cpu().numpy().flatten().tolist())\n","\n","    return preds"]},{"cell_type":"code","execution_count":null,"id":"5c713f79","metadata":{"id":"5c713f79"},"outputs":[],"source":["predictions_MLM = inference(test_MLM_loader, model_MLM)\n","predictions_HLM = inference(test_HLM_loader, model_HLM)"]},{"cell_type":"code","execution_count":null,"id":"30663a84","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":382,"status":"ok","timestamp":1692892543986,"user":{"displayName":"임송재","userId":"10220915962739075092"},"user_tz":-540},"id":"30663a84","outputId":"45d2465e-3924-4296-cb49-1238a34d4569"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           id        MLM        HLM\n","0    TEST_000   3.822335  21.804558\n","1    TEST_001  47.050713  68.755203\n","2    TEST_002   0.854543  54.599537\n","3    TEST_003  43.706779  68.065514\n","4    TEST_004  28.180763  73.006874\n","..        ...        ...        ...\n","478  TEST_478   0.627385  17.521633\n","479  TEST_479  61.585651  72.669800\n","480  TEST_480  44.810120  67.538567\n","481  TEST_481  50.462112  70.152504\n","482  TEST_482  28.982891  67.889992\n","\n","[483 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-adbd7ba3-f4d7-4b66-833a-696e3aeae791\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>MLM</th>\n","      <th>HLM</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TEST_000</td>\n","      <td>3.822335</td>\n","      <td>21.804558</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TEST_001</td>\n","      <td>47.050713</td>\n","      <td>68.755203</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TEST_002</td>\n","      <td>0.854543</td>\n","      <td>54.599537</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TEST_003</td>\n","      <td>43.706779</td>\n","      <td>68.065514</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TEST_004</td>\n","      <td>28.180763</td>\n","      <td>73.006874</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>478</th>\n","      <td>TEST_478</td>\n","      <td>0.627385</td>\n","      <td>17.521633</td>\n","    </tr>\n","    <tr>\n","      <th>479</th>\n","      <td>TEST_479</td>\n","      <td>61.585651</td>\n","      <td>72.669800</td>\n","    </tr>\n","    <tr>\n","      <th>480</th>\n","      <td>TEST_480</td>\n","      <td>44.810120</td>\n","      <td>67.538567</td>\n","    </tr>\n","    <tr>\n","      <th>481</th>\n","      <td>TEST_481</td>\n","      <td>50.462112</td>\n","      <td>70.152504</td>\n","    </tr>\n","    <tr>\n","      <th>482</th>\n","      <td>TEST_482</td>\n","      <td>28.982891</td>\n","      <td>67.889992</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>483 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adbd7ba3-f4d7-4b66-833a-696e3aeae791')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-adbd7ba3-f4d7-4b66-833a-696e3aeae791 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-adbd7ba3-f4d7-4b66-833a-696e3aeae791');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-21a9eefa-b305-4981-a46c-4a544108dfa0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21a9eefa-b305-4981-a46c-4a544108dfa0')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-21a9eefa-b305-4981-a46c-4a544108dfa0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":138}],"source":["submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AIDrug_Competition/data/sample_submission.csv')\n","\n","submission['MLM'] = predictions_MLM\n","submission['HLM'] = predictions_HLM\n","submission"]},{"cell_type":"code","execution_count":null,"id":"2415c221","metadata":{"id":"2415c221"},"outputs":[],"source":["submission.to_csv('/content/drive/MyDrive/Colab Notebooks/AIDrug_Competition/submissions/OnlyMorganFingerprint_DNN_Model_1_submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"aJpMgK_OdxXR","metadata":{"id":"aJpMgK_OdxXR"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}